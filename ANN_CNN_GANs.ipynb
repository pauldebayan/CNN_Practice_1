{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import onnx\n",
    "import onnxscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Problem Statement</th>\n",
    "        <th>Hidden Layer</th>\n",
    "        <th>Output Layer</th>\n",
    "        <th>Loss Function</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Regression</td>\n",
    "        <td>ReLU</td>\n",
    "        <td>Linear</td>\n",
    "        <td>MSE/MAE/Kuber</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Binary Classification</td>\n",
    "        <td>ReLU</td>\n",
    "        <td>Sigmoid</td>\n",
    "        <td>Binary Cross Entropy</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Multiclass Classification</td>\n",
    "        <td>ReLU</td>\n",
    "        <td>Softmax</td>\n",
    "        <td>Categorical/Sparse Cross Entropy</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randint(1, 100, (100,)) #min, max, size\n",
    "x2 = torch.randint(1, 100, (100,))\n",
    "\n",
    "y = (2*x2+5*x1) # we need to find this formula\n",
    "#y = [(torch.square(y))*111 for y in y] \n",
    "\n",
    "data = {'Feature 1': x1, 'Feature 2': x2, 'Label': y}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc[#Rows, #Columns], loc is label-based\n",
    "#iloc[:, index], iloc is integer-based\n",
    "\n",
    "#print(df.loc[0]) # Gives the entire row\n",
    "\n",
    "#Fetch row as well as columns\n",
    "# print(df.loc[0:5, \"Feature 2\"])\n",
    "\n",
    "print(f\" Feature 1: {df.iloc[0, 0]}\")\n",
    "print(f\" Feature 2: {df.iloc[0, 1]}\")\n",
    "\n",
    "# Train, Validate, Test split\n",
    "\n",
    "# train_data = df.iloc[0:60, :]\n",
    "# # print(train_data)\n",
    "# validate_data = df.iloc[60:80, :]\n",
    "# test_data = df.iloc[80:100, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = torch.tensor(dataframe.iloc[:, :-1].values, dtype=torch.float32)  # All columns except the last one\n",
    "        self.labels = torch.tensor(dataframe.iloc[:, -1].values, dtype=torch.float32)  # Last column as labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "dataset = DataFrameDataset(df, transform=transform)\n",
    "\n",
    "train_set, valid_set, test_set = torch.utils.data.random_split(dataset, [0.6, 0.2, 0.2])\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_check = iter(train_dataloader)\n",
    "\n",
    "first_value = next(iter_check)\n",
    "\n",
    "print(first_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialized weights and biases\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change hyperparameters only for Validation dataset\n",
    "\n",
    "learning_rate = 1e-3\n",
    "#batch_size = 2\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    size = len(train_data)\n",
    "    #print(size)\n",
    "\n",
    "    accumulate_loss = 0\n",
    "    for i in range(size): \n",
    "        \n",
    "        feature1 = torch.tensor(train_data.iloc[i, 0]).float()\n",
    "        feature2 = torch.tensor(train_data.iloc[i, 1]).float()\n",
    "        y = torch.tensor(train_data.iloc[i, 2]).float()\n",
    "\n",
    "        X = torch.stack([feature1, feature2], dim=0) #nn.Sequential... nn.Linear(2, 10),\n",
    "\n",
    "        pred = model(X)\n",
    "        # print(type(pred))\n",
    "        # print(type(y))\n",
    "        loss = loss_fn(pred, y)\n",
    "    \n",
    "        # Backpropagation\n",
    "        loss.backward() # Find Gradients\n",
    "        optimizer.step() # Update weights\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    \n",
    "        accumulate_loss += loss.item()\n",
    "\n",
    "    return accumulate_loss/size\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_loop():\n",
    "    size = len(validate_data)\n",
    "\n",
    "    accumulate_loss = 0\n",
    "    for i in range(size): \n",
    "        \n",
    "        feature1 = torch.tensor(validate_data.iloc[i, 0]).float()\n",
    "        feature2 = torch.tensor(validate_data.iloc[i, 1]).float()\n",
    "        y = torch.tensor(validate_data.iloc[i, 2]).float()\n",
    "\n",
    "        X = torch.stack([feature1, feature2], dim=0)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "    \n",
    "        accumulate_loss += loss.item()\n",
    "\n",
    "    return accumulate_loss/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x+1 for x in range(epochs)]\n",
    "\n",
    "trainLossArr = []\n",
    "validateLossArr = []\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_loop()\n",
    "    trainLossArr.append(train_loss)\n",
    "\n",
    "    # Validate\n",
    "    validate_loss = validate_loop()\n",
    "    validateLossArr.append(validate_loss)\n",
    "\n",
    "    print(f\"Epoch {i+1} - Training Loss: {train_loss}, Validation Loss: {validate_loss}\")\n",
    " \n",
    "# print(x)\n",
    "# print(trainLossArr)\n",
    "plt.plot(x, trainLossArr, 'b', label=\"Train\")\n",
    "plt.plot(x, validateLossArr, 'g', label=\"Valid\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')\n",
    "model.load_state_dict(torch.load('model.pt', weights_only=True))\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(test_data)\n",
    "\n",
    "correct = 0\n",
    "for i in range(size): \n",
    "    \n",
    "    feature1 = torch.tensor(test_data.iloc[i, 0]).float()\n",
    "    feature2 = torch.tensor(test_data.iloc[i, 1]).float()\n",
    "    y = torch.tensor(test_data.iloc[i, 2]).float()\n",
    "\n",
    "    X = torch.stack([feature1, feature2], dim=0)\n",
    "\n",
    "    pred = model(X)\n",
    "\n",
    "    if pred.squeeze().int() == y:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct/size*100\n",
    "\n",
    "print(f\"Accracy: {accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Testing\n",
    "\n",
    "x1 = torch.tensor(10, dtype=torch.float)\n",
    "x2 = torch.tensor(20, dtype=torch.float)\n",
    "\n",
    "print(x1)\n",
    "print(x2)\n",
    "\n",
    "X = torch.stack([x1, x2], dim=0)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "pred = model(X)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.youtube.com/watch?v=l8_fZPHasdo\">How we see color - RGB</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RGB Image Channels - 3<br/>\n",
    "Grayscale Image Channels - 1\n",
    "\n",
    "CNN Working:\n",
    "\n",
    "![CNN](images/CNN.jpg)\n",
    "\n",
    "![Image_Filter_FeatureMaps_ConvolutionLayer](images/Convolution_Layer.jpg)\n",
    "\n",
    "![Flattening](images/Flattening.jpg)\n",
    "![Flattening](images/Flattening2NN.jpg)\n",
    "\n",
    "![Filter_Applied_to_Iamge](images/FilterApplied2Image.jpg)\n",
    "![Visualizing1](images/Visualizing1.jpg)\n",
    "![Visualizing2](images/Visualizing2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since a pixel can have values from 0 to 255 \n",
    "# We create a 50x50 image and draw a Circle and a Straight line\n",
    "\n",
    "gen_img = torch.ones([50, 50])*255\n",
    "\n",
    "# Straight Line\n",
    "for i in range(50):\n",
    "    for j in range(50):\n",
    "        if i == j:\n",
    "            gen_img[i][j] = 0\n",
    "\n",
    "# Circle\n",
    "radius = torch.tensor(15)\n",
    "center = 25\n",
    "\n",
    "for i in range(90):\n",
    "    # x = r * cos(θ)\n",
    "    # y = r * sin(θ)\n",
    "\n",
    "    tensor_i = torch.tensor(i)\n",
    "    x = radius * torch.cos(tensor_i)\n",
    "    y = radius * torch.sin(tensor_i)\n",
    "\n",
    "    x = x.int()\n",
    "    y = y.int()\n",
    "\n",
    "    gen_img[x+radius][y-radius] = 0\n",
    "\n",
    "print(gen_img)\n",
    "print(gen_img.shape)\n",
    "plt.imshow(gen_img, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "# Since it is a image it can also be downloaded\n",
    "torchvision.utils.save_image(gen_img, './images/gen_img.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YCbCr and RGB\n",
    "<a href=\"https://www.youtube.com/watch?v=3dET-EoIMM8\">YCbCr and RGB<a/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting R G B individually from a image \n",
    "rgb_img = read_image('./images/RGB.jpg')\n",
    "\n",
    "#red, green, blue = rgb_img # Can also be accessed with index no. - rgb_img[1]\n",
    "#axs[i].imshow(red)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(6, 4))\n",
    "\n",
    "rgb_list = ['Red', 'Green', 'Blue']\n",
    "\n",
    "for i in range(len(rgb_list)):\n",
    "    axs[i].imshow(rgb_img[i]) # Getting the 3 channels separately\n",
    "    axs[i].set_title(rgb_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_image('./images/turtle.jpg')\n",
    "\n",
    "print(f\"Before grayscle: {img.shape}\") # [3, 50, 50], Here 3 is channel\n",
    "print(img.type) # Its a Tensor type\n",
    "\n",
    "# RGB to Grayscale\n",
    "img = torchvision.transforms.functional.rgb_to_grayscale(img, 1)\n",
    "print(f\"After grayscle: {img.shape}\") # [3, 50, 50] -> [1, 50, 50]\n",
    "\n",
    "img = img.squeeze() # Removes channel - [1, W, H] -> [W, H], all input of size 1 removed\n",
    "\n",
    "print(f\"Image shape after squeezing: {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img)\n",
    "#torchvision.utils.save_image(img, 'fp.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN from PyTorch Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset from PyTorch Documentation\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # transforms.ToTensor(), \n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), \n",
    "    # transforms.Grayscale()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(img_dir = 'img_dir', \n",
    "                             annotations_file = 'labels.csv', \n",
    "                             transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = torch.utils.data.random_split(dataset, [0.6, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.imshow(img) cannot display image if it is [3, H, W] we use img.permute(1, 2, 0) to make it [H, W, 3] for displaying<br/>\n",
    "<a href=\"https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.imshow.html\">(M, N, 3)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].permute(1, 2, 0)\n",
    "label = train_labels[0]\n",
    "\n",
    "print(img.shape)\n",
    "#print(img)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #afterFlattenInputNeurons = 900\n",
    "\n",
    "        # Image Shape - torch.Size([50, 50, 3])\n",
    "        # Convolution Layer 1 (sees 50x50x3 image tensor)\n",
    "        self.conv1 = nn.Conv2d(3, 100, 3, padding = 1) # 3 is Channel, 25 is output filtered image, 3 is filter size\n",
    "        \n",
    "        #After adding Maxpooling - dimensionality of the image will decrease\n",
    "        # Formula: output_size = (input_size - filter_size + 1) / stride\n",
    "        \n",
    "        # Convolution Layer 2 (sees 25x25x25 image tensor), Here the last 25 is that mentioned in 2nd parameter of conv1\n",
    "        self.conv2 = nn.Conv2d(100, 50, 3, padding = 1)\n",
    "        # Convolution Layer 3 (sees 12x12x50 image tensor)\n",
    "        self.conv3 = nn.Conv2d(50, 25, 3, padding = 1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2) #(filter/kernel size, stride)\n",
    "\n",
    "        self.activ = nn.ReLU()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(900, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pool(self.activ(self.conv1(x)))\n",
    "        x = self.pool(self.activ(self.conv2(x)))\n",
    "        x = self.pool(self.activ(self.conv3(x)))\n",
    "        \n",
    "        # Comment below code to get x output shape from convolution\n",
    "        # Flattening\n",
    "        x = x.view(-1, 900)\n",
    "        # Avoid overfitting\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY TO GET LINEAR LAYER INPUT\n",
    "\n",
    "dataIter = iter(train_dataloader)\n",
    "# Get first item\n",
    "img, label = next(dataIter)\n",
    "\n",
    "# print(img.shape)\n",
    "\n",
    "#afterFlattenInputNeurons\n",
    "print(\"Dimension to be put in the first Linear layer\", model.forward(img.float()).shape)\n",
    "#Dimension to be put in the first Linear layer torch.Size([1, 20, 6, 6]) - 1x20x6x6 = 720\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change hyperparameters only for Validation dataset\n",
    "\n",
    "learning_rate = 1e-3\n",
    "#batch_size = 2\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# PyTorch's Cross Entrpy Function applies a Softmax function to the output layer\n",
    "# So we do not mention Softmax activation function to the output layer \n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    size = len(train_dataloader)\n",
    "    accumulate_loss = 0\n",
    "    \n",
    "    for img, label in train_dataloader: \n",
    "        # print(img)\n",
    "        # print(label)\n",
    "\n",
    "        pred = model(img.float())\n",
    "        loss = loss_fn(pred, label)\n",
    "    \n",
    "        # Backpropagation\n",
    "        loss.backward() # Find Gradients\n",
    "        optimizer.step() # Update weights\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        accumulate_loss += loss.item()\n",
    "        #train_loss = loss.item()\n",
    "\n",
    "        \n",
    "    return accumulate_loss/size\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop():\n",
    "    size = len(valid_dataloader)\n",
    "    accumulate_loss = 0\n",
    "    \n",
    "    for img, label in valid_dataloader: \n",
    "\n",
    "        pred = model(img.float())\n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        accumulate_loss += loss.item()\n",
    "        #train_loss = loss.item()\n",
    "\n",
    "        \n",
    "    return accumulate_loss/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x+1 for x in range(epochs)]\n",
    "\n",
    "trainLossArr = []\n",
    "validLossArr = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_loop()\n",
    "    trainLossArr.append(train_loss)\n",
    "\n",
    "    # Valid\n",
    "    valid_loss = train_loop()\n",
    "    validLossArr.append(valid_loss)\n",
    "\n",
    "    print(f\"Epoch {i+1} - Training Loss: {train_loss}, Validation Loss: {valid_loss}\")\n",
    " \n",
    "\n",
    "plt.plot(x, trainLossArr, 'b', label=\"Train\")\n",
    "plt.plot(x, validLossArr, 'g', label=\"Valid\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for img, label in test_dataloader:\n",
    "\n",
    "    pred = model(img.float())\n",
    "\n",
    "    if torch.argmax(pred) == label.squeeze():\n",
    "        correct += 1\n",
    "accuracy = correct/len(test_dataloader)*100\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://pytorch.org/tutorials/beginner/onnx/export_simple_model_to_onnx_tutorial.html\">PyTorch to ONNX</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load('model.pt', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataIter = iter(train_dataloader)\n",
    "# Get first item\n",
    "img, label = next(dataIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onnx_program = torch.onnx.export(model, img.float(), \"deploy/dolphin_or_shark.onnx\", opset_version=9)\n",
    "#onnx_program.save(\"deploy/dolphin_or_shark.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.jsdelivr.com/package/npm/onnxjs\">ONNXJS</a><br/>\n",
    "<a href=\"https://github.com/microsoft/onnxjs/blob/master/docs/operators.md\">Supported ONNX Operators</a><br/>\n",
    "<a href=\"https://learn.microsoft.com/en-us/windows/ai/windows-ml/tutorials/pytorch-convert-model\">torch.onnx.export parameters</a>\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=Vs730jsRgO8\">PyTorch ONNX Js Youtube</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cdn.jsdelivr.net/npm/onnxjs@0.1.8/dist/onnx.min.js -P deploy/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 10, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 2)\n",
    "\n",
    "        self.activ = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(2100, 800),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(800,400),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(400, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(self.activ(self.conv1(x)))\n",
    "        x = self.pool(self.activ(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        #print(x.shape)\n",
    "        x = self.linear_stack(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N - Height or Width<br/>\n",
    "Conv2d - (N - K + 1)/S<br/>\n",
    "CnvTranspose2d - (N - 1)*S + K<br/>\n",
    "Latent_space(noise): P = H x W, a = 4(simple image) or 8(complex)<br/>\n",
    "noise = 4 * sqrt(P), choose in power of 2 nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genearator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.gen_sequence = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 512, 2, stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=4),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 3, 4, stride=4),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(1, 128, 1, 2)\n",
    "        #print(f'x.view(-1, 8, 8) shape: {x}')\n",
    "\n",
    "        x = self.gen_sequence(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (conv1): Conv2d(3, 10, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (activ): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=2100, out_features=800, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=800, out_features=400, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=400, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Genearator(\n",
      "  (gen_sequence): Sequential(\n",
      "    (0): ConvTranspose2d(128, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): ConvTranspose2d(256, 3, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator = Genearator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "print(discriminator)\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 256 elements not 512",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m, in \u001b[0;36mGenearator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:176\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/functional.py:2512\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2510\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 256 elements not 512"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(1, 256)\n",
    "img = generator(noise)\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 256 elements not 512",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFake image shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m, in \u001b[0;36mGenearator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:176\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/PytorchEnv/lib/python3.8/site-packages/torch/nn/functional.py:2512\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2510\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 256 elements not 512"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(1, 256)\n",
    "img = generator(noise)\n",
    "plt.imshow(img.squeeze().detach().permute(1, 2, 0))\n",
    "\n",
    "print(f\"Fake image shape: {img.shape}\")\n",
    "print(discriminator(img).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1068):\n",
    "#     c_l = [106, 108, 264, 279, 334, 404, 445, 495, 530, 531, 551, 627, 700, 769]\n",
    "#     if (i+1) in c_l:\n",
    "#         continue\n",
    "#     img = read_image(f'./spectacle_dataset/specs{(i+1)}.jpg')\n",
    "\n",
    "#     print(img.shape)\n",
    "#     if(img.shape[0] == 1):\n",
    "#         print(f'{i+1}: {img.shape[0]}')\n",
    "\n",
    "#img = torch.rand(3, 32, 64)\n",
    "# img = img.permute(1, 2, 0)\n",
    "# img = img.float()\n",
    "#pred = discriminator(img.float())\n",
    "\n",
    "#print(pred.squeeze())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Images - set dataloader\n",
    "class SpectDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Grayscale()\n",
    "    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), \n",
    "])\n",
    "\n",
    "dataset = SpectDataset(img_dir = 'spectacle_dataset', \n",
    "                             annotations_file = 'labels.csv', \n",
    "                             transform = transform)\n",
    "\n",
    "batch_size = 6\n",
    "dl = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000000\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 32, 64])\n",
      "tensor(0.5029, grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for real_img, real_label in dl:\n",
    "   print(real_img.shape)\n",
    "   ld = discriminator(real_img)\n",
    "   print(ld.mean().squeeze())\n",
    "   counter += 1\n",
    "   if(counter == 1):\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1: Discriminator Loss: 0.685650646686554, Generator Loss: 0.6899800300598145\n",
      "Epoch1: Discriminator Loss: 0.6817834377288818, Generator Loss: 0.7144002914428711\n",
      "Epoch1: Discriminator Loss: 0.6663370132446289, Generator Loss: 0.7280245423316956\n",
      "Epoch1: Discriminator Loss: 0.6514579057693481, Generator Loss: 0.7350496649742126\n",
      "Epoch1: Discriminator Loss: 0.6270266175270081, Generator Loss: 0.7804325819015503\n",
      "Epoch1: Discriminator Loss: 0.6073403358459473, Generator Loss: 0.7946197986602783\n",
      "Epoch1: Discriminator Loss: 0.5855939388275146, Generator Loss: 0.835972011089325\n",
      "Epoch1: Discriminator Loss: 0.5811452269554138, Generator Loss: 0.8928714394569397\n",
      "Epoch1: Discriminator Loss: 0.5489485263824463, Generator Loss: 0.921822726726532\n",
      "Epoch1: Discriminator Loss: 0.5307189226150513, Generator Loss: 0.9944218993186951\n",
      "Epoch1: Discriminator Loss: 0.4903944730758667, Generator Loss: 1.021151065826416\n",
      "Epoch1: Discriminator Loss: 0.4888148009777069, Generator Loss: 1.051101565361023\n",
      "Epoch1: Discriminator Loss: 0.4692017436027527, Generator Loss: 1.13113534450531\n",
      "Epoch1: Discriminator Loss: 0.4345264434814453, Generator Loss: 1.2291536331176758\n",
      "Epoch1: Discriminator Loss: 0.4209493398666382, Generator Loss: 1.2110663652420044\n",
      "Epoch1: Discriminator Loss: 0.3977852463722229, Generator Loss: 1.3427479267120361\n",
      "Epoch1: Discriminator Loss: 0.3471686840057373, Generator Loss: 1.4818649291992188\n",
      "Epoch1: Discriminator Loss: 0.32884928584098816, Generator Loss: 1.3897448778152466\n",
      "Epoch1: Discriminator Loss: 0.30456778407096863, Generator Loss: 1.5464885234832764\n",
      "Epoch1: Discriminator Loss: 0.28535783290863037, Generator Loss: 1.6365327835083008\n",
      "Epoch1: Discriminator Loss: 0.2634228765964508, Generator Loss: 1.5744152069091797\n",
      "Epoch1: Discriminator Loss: 0.23566654324531555, Generator Loss: 1.8699787855148315\n",
      "Epoch1: Discriminator Loss: 0.20834681391716003, Generator Loss: 1.9454113245010376\n",
      "Epoch1: Discriminator Loss: 0.21259641647338867, Generator Loss: 1.9559152126312256\n",
      "Epoch1: Discriminator Loss: 0.16327223181724548, Generator Loss: 2.138158082962036\n",
      "Epoch1: Discriminator Loss: 0.16248023509979248, Generator Loss: 2.1557867527008057\n",
      "Epoch1: Discriminator Loss: 0.1429426223039627, Generator Loss: 2.2599353790283203\n",
      "Epoch1: Discriminator Loss: 0.125349760055542, Generator Loss: 2.374734401702881\n",
      "Epoch1: Discriminator Loss: 0.10567864775657654, Generator Loss: 2.5809707641601562\n",
      "Epoch1: Discriminator Loss: 0.1078469306230545, Generator Loss: 2.3849310874938965\n",
      "Epoch1: Discriminator Loss: 0.09801054000854492, Generator Loss: 2.745094060897827\n",
      "Epoch1: Discriminator Loss: 0.09414931386709213, Generator Loss: 2.7312283515930176\n",
      "Epoch1: Discriminator Loss: 0.06708496809005737, Generator Loss: 3.0269885063171387\n",
      "Epoch1: Discriminator Loss: 0.06498712301254272, Generator Loss: 2.868607521057129\n",
      "Epoch1: Discriminator Loss: 0.07449261844158173, Generator Loss: 2.782924175262451\n",
      "Epoch1: Discriminator Loss: 0.05675125867128372, Generator Loss: 3.0455386638641357\n",
      "Epoch1: Discriminator Loss: 0.04674645513296127, Generator Loss: 2.9667840003967285\n",
      "Epoch1: Discriminator Loss: 0.0532146580517292, Generator Loss: 3.300654649734497\n",
      "Epoch1: Discriminator Loss: 0.053749844431877136, Generator Loss: 3.0364010334014893\n",
      "Epoch1: Discriminator Loss: 0.052042026072740555, Generator Loss: 3.84179425239563\n",
      "Epoch1: Discriminator Loss: 0.02819337137043476, Generator Loss: 3.5074751377105713\n",
      "Epoch1: Discriminator Loss: 0.0383572056889534, Generator Loss: 3.5521979331970215\n",
      "Epoch1: Discriminator Loss: 0.04009515792131424, Generator Loss: 3.485109806060791\n",
      "Epoch1: Discriminator Loss: 0.03847947344183922, Generator Loss: 3.286810874938965\n",
      "Epoch1: Discriminator Loss: 0.0316447913646698, Generator Loss: 3.041553497314453\n",
      "Epoch1: Discriminator Loss: 0.03358795866370201, Generator Loss: 3.4726173877716064\n",
      "Epoch1: Discriminator Loss: 0.033527594059705734, Generator Loss: 3.8862383365631104\n",
      "Epoch1: Discriminator Loss: 0.032736845314502716, Generator Loss: 3.186570167541504\n",
      "Epoch1: Discriminator Loss: 0.028578488156199455, Generator Loss: 3.517519950866699\n",
      "Epoch1: Discriminator Loss: 0.03472084924578667, Generator Loss: 3.6890318393707275\n",
      "Epoch1: Discriminator Loss: 0.039000365883111954, Generator Loss: 2.5314393043518066\n",
      "Epoch1: Discriminator Loss: 0.03788965195417404, Generator Loss: 3.627558708190918\n",
      "Epoch1: Discriminator Loss: 0.037812039256095886, Generator Loss: 3.591376304626465\n",
      "Epoch1: Discriminator Loss: 0.029494091868400574, Generator Loss: 3.339829444885254\n",
      "Epoch1: Discriminator Loss: 0.03231823444366455, Generator Loss: 4.122223377227783\n",
      "Epoch1: Discriminator Loss: 0.04842934384942055, Generator Loss: 3.5240933895111084\n",
      "Epoch1: Discriminator Loss: 0.045755017548799515, Generator Loss: 3.1909432411193848\n",
      "Epoch1: Discriminator Loss: 0.03734235465526581, Generator Loss: 3.711010694503784\n",
      "Epoch1: Discriminator Loss: 0.03165522217750549, Generator Loss: 3.4186208248138428\n",
      "Epoch1: Discriminator Loss: 0.055082663893699646, Generator Loss: 3.904265880584717\n",
      "Epoch1: Discriminator Loss: 0.040719032287597656, Generator Loss: 3.824154853820801\n",
      "Epoch1: Discriminator Loss: 0.03592102229595184, Generator Loss: 3.859691619873047\n",
      "Epoch1: Discriminator Loss: 0.040396351367235184, Generator Loss: 4.03251838684082\n",
      "Epoch1: Discriminator Loss: 0.029626209288835526, Generator Loss: 3.4838881492614746\n",
      "Epoch1: Discriminator Loss: 0.041464969515800476, Generator Loss: 2.912140130996704\n",
      "Epoch1: Discriminator Loss: 0.0712624043226242, Generator Loss: 3.2433152198791504\n",
      "Epoch1: Discriminator Loss: 0.05233019217848778, Generator Loss: 3.3379030227661133\n",
      "Epoch1: Discriminator Loss: 0.05848803371191025, Generator Loss: 2.721562623977661\n",
      "Epoch1: Discriminator Loss: 0.06184343993663788, Generator Loss: 3.9550602436065674\n",
      "Epoch1: Discriminator Loss: 0.06825806200504303, Generator Loss: 4.451818943023682\n",
      "Epoch1: Discriminator Loss: 0.10180474817752838, Generator Loss: 4.678221702575684\n",
      "Epoch1: Discriminator Loss: 0.05127512663602829, Generator Loss: 4.748339653015137\n",
      "Epoch1: Discriminator Loss: 0.058545589447021484, Generator Loss: 3.3421576023101807\n",
      "Epoch1: Discriminator Loss: 0.117363341152668, Generator Loss: 2.7588117122650146\n",
      "Epoch1: Discriminator Loss: 0.039172641932964325, Generator Loss: 3.197474479675293\n",
      "Epoch1: Discriminator Loss: 0.05491423234343529, Generator Loss: 2.780806064605713\n",
      "Epoch1: Discriminator Loss: 0.03161260485649109, Generator Loss: 3.659700393676758\n",
      "Epoch1: Discriminator Loss: 0.044477678835392, Generator Loss: 2.414793014526367\n",
      "Epoch1: Discriminator Loss: 0.04968855530023575, Generator Loss: 2.8554012775421143\n",
      "Epoch1: Discriminator Loss: 0.06927681714296341, Generator Loss: 4.464064598083496\n",
      "Epoch1: Discriminator Loss: 0.08090409636497498, Generator Loss: 3.1742806434631348\n",
      "Epoch1: Discriminator Loss: 0.0823560431599617, Generator Loss: 2.0680665969848633\n",
      "Epoch1: Discriminator Loss: 0.03118034079670906, Generator Loss: 3.1130623817443848\n",
      "Epoch1: Discriminator Loss: 0.09940752387046814, Generator Loss: 1.834860920906067\n",
      "Epoch1: Discriminator Loss: 0.0727001503109932, Generator Loss: 3.206019401550293\n",
      "Epoch1: Discriminator Loss: 0.05061478167772293, Generator Loss: 3.115833282470703\n",
      "Epoch1: Discriminator Loss: 0.04511929303407669, Generator Loss: 3.014603853225708\n",
      "Epoch1: Discriminator Loss: 0.0851791724562645, Generator Loss: 3.936556339263916\n",
      "Epoch1: Discriminator Loss: 0.11693091690540314, Generator Loss: 4.352847099304199\n",
      "Epoch1: Discriminator Loss: 0.04518548771739006, Generator Loss: 3.6200361251831055\n",
      "Epoch1: Discriminator Loss: 0.08540327847003937, Generator Loss: 2.1617789268493652\n",
      "Epoch1: Discriminator Loss: 0.15487006306648254, Generator Loss: 3.809122323989868\n",
      "Epoch1: Discriminator Loss: 0.06251543015241623, Generator Loss: 3.306063175201416\n",
      "Epoch1: Discriminator Loss: 0.15521368384361267, Generator Loss: 2.815451145172119\n",
      "Epoch1: Discriminator Loss: 0.07163263112306595, Generator Loss: 4.35343074798584\n",
      "Epoch1: Discriminator Loss: 0.23105981945991516, Generator Loss: 5.511625289916992\n",
      "Epoch1: Discriminator Loss: 0.10777266323566437, Generator Loss: 3.277134895324707\n",
      "Epoch1: Discriminator Loss: 0.06580080091953278, Generator Loss: 2.243138313293457\n",
      "Epoch1: Discriminator Loss: 0.10452385246753693, Generator Loss: 2.0239098072052\n",
      "Epoch1: Discriminator Loss: 0.1311701387166977, Generator Loss: 3.1858901977539062\n",
      "Epoch1: Discriminator Loss: 0.09332169592380524, Generator Loss: 3.681915760040283\n",
      "Epoch1: Discriminator Loss: 0.10037028789520264, Generator Loss: 4.635298728942871\n",
      "Epoch1: Discriminator Loss: 0.0751955658197403, Generator Loss: 2.173762559890747\n",
      "Epoch1: Discriminator Loss: 0.10266164690256119, Generator Loss: 3.537940263748169\n",
      "Epoch1: Discriminator Loss: 0.0958147943019867, Generator Loss: 4.326755523681641\n",
      "Epoch1: Discriminator Loss: 0.08889894187450409, Generator Loss: 2.3066511154174805\n",
      "Epoch1: Discriminator Loss: 0.07576041668653488, Generator Loss: 2.099390745162964\n",
      "Epoch1: Discriminator Loss: 0.15902143716812134, Generator Loss: 1.6118699312210083\n",
      "Epoch1: Discriminator Loss: 0.21831637620925903, Generator Loss: 1.9875648021697998\n",
      "Epoch1: Discriminator Loss: 0.09777525067329407, Generator Loss: 3.0962846279144287\n",
      "Epoch1: Discriminator Loss: 0.20178645849227905, Generator Loss: 3.5353610515594482\n",
      "Epoch1: Discriminator Loss: 0.25707733631134033, Generator Loss: 4.023409366607666\n",
      "Epoch1: Discriminator Loss: 0.16332347691059113, Generator Loss: 3.1735799312591553\n",
      "Epoch1: Discriminator Loss: 0.22683750092983246, Generator Loss: 1.6647474765777588\n",
      "Epoch1: Discriminator Loss: 0.28629186749458313, Generator Loss: 0.658309817314148\n",
      "Epoch1: Discriminator Loss: 0.33294838666915894, Generator Loss: 1.521582841873169\n",
      "Epoch1: Discriminator Loss: 0.04208220914006233, Generator Loss: 2.0768728256225586\n",
      "Epoch1: Discriminator Loss: 0.10481195151805878, Generator Loss: 4.370203495025635\n",
      "Epoch1: Discriminator Loss: 0.2207617163658142, Generator Loss: 4.961817264556885\n",
      "Epoch1: Discriminator Loss: 0.3276912271976471, Generator Loss: 4.979848861694336\n",
      "Epoch1: Discriminator Loss: 0.3352406919002533, Generator Loss: 4.549415111541748\n",
      "Epoch1: Discriminator Loss: 0.2873896658420563, Generator Loss: 3.7939321994781494\n",
      "Epoch1: Discriminator Loss: 0.10714317858219147, Generator Loss: 2.7996420860290527\n",
      "Epoch1: Discriminator Loss: 0.22478678822517395, Generator Loss: 1.2755259275436401\n",
      "Epoch1: Discriminator Loss: 0.41187795996665955, Generator Loss: 1.3502471446990967\n",
      "Epoch1: Discriminator Loss: 0.3286289572715759, Generator Loss: 1.312307357788086\n",
      "Epoch1: Discriminator Loss: 0.09675656259059906, Generator Loss: 2.404303789138794\n",
      "Epoch1: Discriminator Loss: 0.10442354530096054, Generator Loss: 2.052690267562866\n",
      "Epoch1: Discriminator Loss: 0.18510296940803528, Generator Loss: 3.705692768096924\n",
      "Epoch1: Discriminator Loss: 0.3507957458496094, Generator Loss: 3.779508352279663\n",
      "Epoch1: Discriminator Loss: 0.24379833042621613, Generator Loss: 3.0050086975097656\n",
      "Epoch1: Discriminator Loss: 0.30746060609817505, Generator Loss: 3.2732324600219727\n",
      "Epoch1: Discriminator Loss: 0.25079742074012756, Generator Loss: 2.8434605598449707\n",
      "Epoch1: Discriminator Loss: 0.3332892060279846, Generator Loss: 3.4130496978759766\n",
      "Epoch1: Discriminator Loss: 0.08926037698984146, Generator Loss: 1.92483651638031\n",
      "Epoch1: Discriminator Loss: 0.22651146352291107, Generator Loss: 0.7747162580490112\n",
      "Epoch1: Discriminator Loss: 0.8823783993721008, Generator Loss: 0.26336726546287537\n",
      "Epoch1: Discriminator Loss: 0.2198396921157837, Generator Loss: 1.8215875625610352\n",
      "Epoch1: Discriminator Loss: 0.0878375694155693, Generator Loss: 2.1351990699768066\n",
      "Epoch1: Discriminator Loss: 0.2472151517868042, Generator Loss: 2.369638442993164\n",
      "Epoch1: Discriminator Loss: 0.23793143033981323, Generator Loss: 4.252198219299316\n",
      "Epoch1: Discriminator Loss: 0.22081676125526428, Generator Loss: 4.013493537902832\n",
      "Epoch1: Discriminator Loss: 0.4077032804489136, Generator Loss: 3.1844115257263184\n",
      "Epoch1: Discriminator Loss: 0.25546613335609436, Generator Loss: 4.193118095397949\n",
      "Epoch1: Discriminator Loss: 0.2330455183982849, Generator Loss: 4.1121344566345215\n",
      "Epoch1: Discriminator Loss: 0.2478327602148056, Generator Loss: 3.4878571033477783\n",
      "Epoch1: Discriminator Loss: 0.11848460137844086, Generator Loss: 1.7742292881011963\n",
      "Epoch1: Discriminator Loss: 0.18047432601451874, Generator Loss: 2.022184133529663\n",
      "Epoch1: Discriminator Loss: 0.2032606154680252, Generator Loss: 1.1129438877105713\n",
      "Epoch1: Discriminator Loss: 0.2108220010995865, Generator Loss: 0.383187472820282\n",
      "Epoch1: Discriminator Loss: 0.22971053421497345, Generator Loss: 1.5079164505004883\n",
      "Epoch1: Discriminator Loss: 0.11853146553039551, Generator Loss: 1.4782031774520874\n",
      "Epoch1: Discriminator Loss: 0.20419101417064667, Generator Loss: 0.6426730751991272\n",
      "Epoch1: Discriminator Loss: 0.10186107456684113, Generator Loss: 2.2997121810913086\n",
      "Epoch1: Discriminator Loss: 0.08956153690814972, Generator Loss: 2.8046770095825195\n",
      "Epoch1: Discriminator Loss: 0.17993204295635223, Generator Loss: 3.6225478649139404\n",
      "Epoch1: Discriminator Loss: 0.28341224789619446, Generator Loss: 2.7950682640075684\n",
      "Epoch1: Discriminator Loss: 0.20473527908325195, Generator Loss: 3.233198881149292\n",
      "Epoch1: Discriminator Loss: 0.16641797125339508, Generator Loss: 2.5927789211273193\n",
      "Epoch1: Discriminator Loss: 0.12568995356559753, Generator Loss: 3.060443162918091\n",
      "Epoch1: Discriminator Loss: 0.14482049643993378, Generator Loss: 2.0035576820373535\n",
      "Epoch1: Discriminator Loss: 0.3508247137069702, Generator Loss: 1.480768084526062\n",
      "Epoch1: Discriminator Loss: 0.20783263444900513, Generator Loss: 2.328538179397583\n",
      "Epoch1: Discriminator Loss: 0.12739771604537964, Generator Loss: 1.4274702072143555\n",
      "Epoch1: Discriminator Loss: 0.19424541294574738, Generator Loss: 3.5213046073913574\n",
      "Epoch1: Discriminator Loss: 0.3019918203353882, Generator Loss: 2.964970350265503\n",
      "Epoch1: Discriminator Loss: 0.09621931612491608, Generator Loss: 2.8946282863616943\n",
      "Epoch1: Discriminator Loss: 0.3394097685813904, Generator Loss: 3.902090072631836\n",
      "Epoch1: Discriminator Loss: 0.2657895088195801, Generator Loss: 4.563360214233398\n",
      "Epoch1: Discriminator Loss: 0.21340250968933105, Generator Loss: 4.4569315910339355\n",
      "Epoch1: Discriminator Loss: 0.1460404396057129, Generator Loss: 3.9195022583007812\n",
      "Epoch1: Discriminator Loss: 0.2755599021911621, Generator Loss: 4.051468849182129\n",
      "Epoch1: Discriminator Loss: 0.09638718515634537, Generator Loss: 4.536325931549072\n",
      "Epoch1: Discriminator Loss: 0.10660184919834137, Generator Loss: 3.1938557624816895\n",
      "Epoch1: Discriminator Loss: 0.13761813938617706, Generator Loss: 3.8764877319335938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1: Discriminator Loss: 0.04442697390913963, Generator Loss: 1.658191442489624\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch2: Discriminator Loss: 0.2625807523727417, Generator Loss: 1.6505464315414429\n",
      "Epoch2: Discriminator Loss: 0.05669908970594406, Generator Loss: 1.776660680770874\n",
      "Epoch2: Discriminator Loss: 0.266191303730011, Generator Loss: 2.4363181591033936\n",
      "Epoch2: Discriminator Loss: 0.18196125328540802, Generator Loss: 2.451122283935547\n",
      "Epoch2: Discriminator Loss: 0.19264617562294006, Generator Loss: 2.6968259811401367\n",
      "Epoch2: Discriminator Loss: 0.21509432792663574, Generator Loss: 3.6386051177978516\n",
      "Epoch2: Discriminator Loss: 0.15463119745254517, Generator Loss: 3.8746368885040283\n",
      "Epoch2: Discriminator Loss: 0.14407317340373993, Generator Loss: 3.5750019550323486\n",
      "Epoch2: Discriminator Loss: 0.3198671042919159, Generator Loss: 3.8713266849517822\n",
      "Epoch2: Discriminator Loss: 0.1392626315355301, Generator Loss: 2.7197611331939697\n",
      "Epoch2: Discriminator Loss: 0.079063780605793, Generator Loss: 3.243096351623535\n",
      "Epoch2: Discriminator Loss: 0.09955596923828125, Generator Loss: 3.2999610900878906\n",
      "Epoch2: Discriminator Loss: 0.2923595905303955, Generator Loss: 1.2832555770874023\n",
      "Epoch2: Discriminator Loss: 0.1237030178308487, Generator Loss: 1.608704686164856\n",
      "Epoch2: Discriminator Loss: 0.19159141182899475, Generator Loss: 1.9007549285888672\n",
      "Epoch2: Discriminator Loss: 0.21482214331626892, Generator Loss: 2.0315613746643066\n",
      "Epoch2: Discriminator Loss: 0.22663579881191254, Generator Loss: 1.7584816217422485\n",
      "Epoch2: Discriminator Loss: 0.04851830378174782, Generator Loss: 2.8191964626312256\n",
      "Epoch2: Discriminator Loss: 0.23507730662822723, Generator Loss: 2.116029977798462\n",
      "Epoch2: Discriminator Loss: 0.16951540112495422, Generator Loss: 3.564685106277466\n",
      "Epoch2: Discriminator Loss: 0.018833333626389503, Generator Loss: 4.129461288452148\n",
      "Epoch2: Discriminator Loss: 0.22284968197345734, Generator Loss: 4.135660648345947\n",
      "Epoch2: Discriminator Loss: 0.10730906575918198, Generator Loss: 3.084376811981201\n",
      "Epoch2: Discriminator Loss: 0.10778232663869858, Generator Loss: 2.8677868843078613\n",
      "Epoch2: Discriminator Loss: 0.2584283947944641, Generator Loss: 2.3942508697509766\n",
      "Epoch2: Discriminator Loss: 0.21301189064979553, Generator Loss: 1.9253129959106445\n",
      "Epoch2: Discriminator Loss: 0.09411872923374176, Generator Loss: 3.0483014583587646\n",
      "Epoch2: Discriminator Loss: 0.0184489656239748, Generator Loss: 2.5231270790100098\n",
      "Epoch2: Discriminator Loss: 0.08671239018440247, Generator Loss: 2.3773932456970215\n",
      "Epoch2: Discriminator Loss: 0.07170120626688004, Generator Loss: 2.5840771198272705\n",
      "Epoch2: Discriminator Loss: 0.5047199130058289, Generator Loss: 1.995788335800171\n",
      "Epoch2: Discriminator Loss: 0.03269810974597931, Generator Loss: 2.3882012367248535\n",
      "Epoch2: Discriminator Loss: 0.09884341806173325, Generator Loss: 2.5882816314697266\n",
      "Epoch2: Discriminator Loss: 0.15829351544380188, Generator Loss: 2.769674777984619\n",
      "Epoch2: Discriminator Loss: 0.22130528092384338, Generator Loss: 4.341855049133301\n",
      "Epoch2: Discriminator Loss: 0.15003176033496857, Generator Loss: 4.995091915130615\n",
      "Epoch2: Discriminator Loss: 0.18104206025600433, Generator Loss: 4.879018783569336\n",
      "Epoch2: Discriminator Loss: 0.06007254123687744, Generator Loss: 4.032543659210205\n",
      "Epoch2: Discriminator Loss: 0.1565256416797638, Generator Loss: 4.414980411529541\n",
      "Epoch2: Discriminator Loss: 0.14030703902244568, Generator Loss: 4.460994243621826\n",
      "Epoch2: Discriminator Loss: 0.11901228874921799, Generator Loss: 4.0107645988464355\n",
      "Epoch2: Discriminator Loss: 0.13033641874790192, Generator Loss: 3.822598934173584\n",
      "Epoch2: Discriminator Loss: 0.10321246087551117, Generator Loss: 2.326599597930908\n",
      "Epoch2: Discriminator Loss: 0.07515321671962738, Generator Loss: 3.172912120819092\n",
      "Epoch2: Discriminator Loss: 0.12328456342220306, Generator Loss: 3.3300857543945312\n",
      "Epoch2: Discriminator Loss: 0.06975347548723221, Generator Loss: 2.6374218463897705\n",
      "Epoch2: Discriminator Loss: 0.0863954946398735, Generator Loss: 2.348033905029297\n",
      "Epoch2: Discriminator Loss: 0.13258284330368042, Generator Loss: 2.2596888542175293\n",
      "Epoch2: Discriminator Loss: 0.10195960849523544, Generator Loss: 2.312760829925537\n",
      "Epoch2: Discriminator Loss: 0.019968530163168907, Generator Loss: 2.973217010498047\n",
      "Epoch2: Discriminator Loss: 0.10461649298667908, Generator Loss: 2.1984102725982666\n",
      "Epoch2: Discriminator Loss: 0.029424386098980904, Generator Loss: 2.026823043823242\n",
      "Epoch2: Discriminator Loss: 0.06505519151687622, Generator Loss: 2.605259418487549\n",
      "Epoch2: Discriminator Loss: 0.0851769894361496, Generator Loss: 2.808218479156494\n",
      "Epoch2: Discriminator Loss: 0.05176215618848801, Generator Loss: 3.381315231323242\n",
      "Epoch2: Discriminator Loss: 0.048920340836048126, Generator Loss: 3.0390470027923584\n",
      "Epoch2: Discriminator Loss: 0.026777280494570732, Generator Loss: 3.4113144874572754\n",
      "Epoch2: Discriminator Loss: 0.07609765231609344, Generator Loss: 2.753974676132202\n",
      "Epoch2: Discriminator Loss: 0.053657159209251404, Generator Loss: 1.4811071157455444\n",
      "Epoch2: Discriminator Loss: 0.053130775690078735, Generator Loss: 3.8646857738494873\n",
      "Epoch2: Discriminator Loss: 0.09267072379589081, Generator Loss: 3.070746898651123\n",
      "Epoch2: Discriminator Loss: 0.09685978293418884, Generator Loss: 3.958895683288574\n",
      "Epoch2: Discriminator Loss: 0.008359863422811031, Generator Loss: 3.9502015113830566\n",
      "Epoch2: Discriminator Loss: 0.09202049672603607, Generator Loss: 4.966180801391602\n",
      "Epoch2: Discriminator Loss: 0.07499988377094269, Generator Loss: 4.262118816375732\n",
      "Epoch2: Discriminator Loss: 0.047254085540771484, Generator Loss: 4.390838146209717\n",
      "Epoch2: Discriminator Loss: 0.09457813948392868, Generator Loss: 4.635855674743652\n",
      "Epoch2: Discriminator Loss: 0.10086259245872498, Generator Loss: 4.591183662414551\n",
      "Epoch2: Discriminator Loss: 0.0805659070611, Generator Loss: 3.8014307022094727\n",
      "Epoch2: Discriminator Loss: 0.020368320867419243, Generator Loss: 4.763004302978516\n",
      "Epoch2: Discriminator Loss: 0.14512570202350616, Generator Loss: 4.721325397491455\n",
      "Epoch2: Discriminator Loss: 0.01861000806093216, Generator Loss: 4.011551380157471\n",
      "Epoch2: Discriminator Loss: 0.058256931602954865, Generator Loss: 4.9979658126831055\n",
      "Epoch2: Discriminator Loss: 0.17997193336486816, Generator Loss: 2.8435144424438477\n",
      "Epoch2: Discriminator Loss: 0.08275578916072845, Generator Loss: 2.8882334232330322\n",
      "Epoch2: Discriminator Loss: 0.042417511343955994, Generator Loss: 2.149723768234253\n",
      "Epoch2: Discriminator Loss: 0.015719057992100716, Generator Loss: 1.7834844589233398\n",
      "Epoch2: Discriminator Loss: 0.07237514108419418, Generator Loss: 2.1701486110687256\n",
      "Epoch2: Discriminator Loss: 0.03306443989276886, Generator Loss: 2.5401523113250732\n",
      "Epoch2: Discriminator Loss: 0.10451406985521317, Generator Loss: 1.6377805471420288\n",
      "Epoch2: Discriminator Loss: 0.15512828528881073, Generator Loss: 3.3192479610443115\n",
      "Epoch2: Discriminator Loss: 0.03228243067860603, Generator Loss: 2.4858903884887695\n",
      "Epoch2: Discriminator Loss: 0.11395107209682465, Generator Loss: 2.4800684452056885\n",
      "Epoch2: Discriminator Loss: 0.07335865497589111, Generator Loss: 3.886972427368164\n",
      "Epoch2: Discriminator Loss: 0.01432022638618946, Generator Loss: 3.827676296234131\n",
      "Epoch2: Discriminator Loss: 0.07658492773771286, Generator Loss: 4.264204502105713\n",
      "Epoch2: Discriminator Loss: 0.0339481383562088, Generator Loss: 4.2797322273254395\n",
      "Epoch2: Discriminator Loss: 0.09655385464429855, Generator Loss: 2.928929328918457\n",
      "Epoch2: Discriminator Loss: 0.006104986183345318, Generator Loss: 6.048521518707275\n",
      "Epoch2: Discriminator Loss: 0.03490159288048744, Generator Loss: 3.4151744842529297\n",
      "Epoch2: Discriminator Loss: 0.1310015767812729, Generator Loss: 4.8826003074646\n",
      "Epoch2: Discriminator Loss: 0.025529110804200172, Generator Loss: 3.058722496032715\n",
      "Epoch2: Discriminator Loss: 0.016621431335806847, Generator Loss: 3.669816493988037\n",
      "Epoch2: Discriminator Loss: 0.033656805753707886, Generator Loss: 4.547847270965576\n",
      "Epoch2: Discriminator Loss: 0.05949615687131882, Generator Loss: 3.260899543762207\n",
      "Epoch2: Discriminator Loss: 0.06259886175394058, Generator Loss: 3.5789220333099365\n",
      "Epoch2: Discriminator Loss: 0.02800809219479561, Generator Loss: 2.823406219482422\n",
      "Epoch2: Discriminator Loss: 0.2263493835926056, Generator Loss: 3.763134002685547\n",
      "Epoch2: Discriminator Loss: 0.01722773164510727, Generator Loss: 3.888157367706299\n",
      "Epoch2: Discriminator Loss: 0.08869438618421555, Generator Loss: 3.971848249435425\n",
      "Epoch2: Discriminator Loss: 0.02079438418149948, Generator Loss: 1.6463536024093628\n",
      "Epoch2: Discriminator Loss: 0.11271919310092926, Generator Loss: 2.7353451251983643\n",
      "Epoch2: Discriminator Loss: 0.0633586123585701, Generator Loss: 1.7986818552017212\n",
      "Epoch2: Discriminator Loss: 0.029659878462553024, Generator Loss: 2.65217661857605\n",
      "Epoch2: Discriminator Loss: 0.014732876792550087, Generator Loss: 5.289848804473877\n",
      "Epoch2: Discriminator Loss: 0.03231292963027954, Generator Loss: 3.626725673675537\n",
      "Epoch2: Discriminator Loss: 0.03789672628045082, Generator Loss: 4.0122971534729\n",
      "Epoch2: Discriminator Loss: 0.024555815383791924, Generator Loss: 4.642361640930176\n",
      "Epoch2: Discriminator Loss: 0.10822098702192307, Generator Loss: 3.7591195106506348\n",
      "Epoch2: Discriminator Loss: 0.09535153210163116, Generator Loss: 5.5459771156311035\n",
      "Epoch2: Discriminator Loss: 0.0019674962386488914, Generator Loss: 4.447144985198975\n",
      "Epoch2: Discriminator Loss: 0.021662095561623573, Generator Loss: 4.280364513397217\n",
      "Epoch2: Discriminator Loss: 0.00209235493093729, Generator Loss: 4.8779616355896\n",
      "Epoch2: Discriminator Loss: 0.08732123672962189, Generator Loss: 3.211479902267456\n",
      "Epoch2: Discriminator Loss: 0.03949448838829994, Generator Loss: 4.356844425201416\n",
      "Epoch2: Discriminator Loss: 0.06964520364999771, Generator Loss: 3.8773202896118164\n",
      "Epoch2: Discriminator Loss: 0.03008335828781128, Generator Loss: 4.509405612945557\n",
      "Epoch2: Discriminator Loss: 0.08352869004011154, Generator Loss: 4.9554338455200195\n",
      "Epoch2: Discriminator Loss: 0.14407169818878174, Generator Loss: 3.6788957118988037\n",
      "Epoch2: Discriminator Loss: 0.11857227981090546, Generator Loss: 2.457780122756958\n",
      "Epoch2: Discriminator Loss: 0.006450175307691097, Generator Loss: 5.079129219055176\n",
      "Epoch2: Discriminator Loss: 0.10334236919879913, Generator Loss: 4.953339576721191\n",
      "Epoch2: Discriminator Loss: 0.008204343728721142, Generator Loss: 3.8042311668395996\n",
      "Epoch2: Discriminator Loss: 0.16543333232402802, Generator Loss: 3.663536548614502\n",
      "Epoch2: Discriminator Loss: 0.08192547410726547, Generator Loss: 5.818253993988037\n",
      "Epoch2: Discriminator Loss: 0.07841048389673233, Generator Loss: 3.7389795780181885\n",
      "Epoch2: Discriminator Loss: 0.10468338429927826, Generator Loss: 4.056440353393555\n",
      "Epoch2: Discriminator Loss: 0.022049525752663612, Generator Loss: 5.113535404205322\n",
      "Epoch2: Discriminator Loss: 0.19439776241779327, Generator Loss: 5.532392501831055\n",
      "Epoch2: Discriminator Loss: 0.1134897992014885, Generator Loss: 4.780646324157715\n",
      "Epoch2: Discriminator Loss: 0.0825466513633728, Generator Loss: 3.337446451187134\n",
      "Epoch2: Discriminator Loss: 0.015113893896341324, Generator Loss: 3.961174726486206\n",
      "Epoch2: Discriminator Loss: 0.02656393311917782, Generator Loss: 3.4238407611846924\n",
      "Epoch2: Discriminator Loss: 0.028854619711637497, Generator Loss: 2.4198648929595947\n",
      "Epoch2: Discriminator Loss: 0.1286298930644989, Generator Loss: 1.6084754467010498\n",
      "Epoch2: Discriminator Loss: 0.02175096422433853, Generator Loss: 2.5638434886932373\n",
      "Epoch2: Discriminator Loss: 0.021694079041481018, Generator Loss: 3.7885496616363525\n",
      "Epoch2: Discriminator Loss: 0.0633813664317131, Generator Loss: 1.2313692569732666\n",
      "Epoch2: Discriminator Loss: 0.023797787725925446, Generator Loss: 3.3128745555877686\n",
      "Epoch2: Discriminator Loss: 0.05784950032830238, Generator Loss: 2.8018646240234375\n",
      "Epoch2: Discriminator Loss: 0.01796870492398739, Generator Loss: 3.602241277694702\n",
      "Epoch2: Discriminator Loss: 0.004989877343177795, Generator Loss: 4.473948001861572\n",
      "Epoch2: Discriminator Loss: 0.0986202210187912, Generator Loss: 5.868478298187256\n",
      "Epoch2: Discriminator Loss: 0.06893956661224365, Generator Loss: 5.263056755065918\n",
      "Epoch2: Discriminator Loss: 0.022055938839912415, Generator Loss: 5.085268974304199\n",
      "Epoch2: Discriminator Loss: 0.003969538025557995, Generator Loss: 4.615364074707031\n",
      "Epoch2: Discriminator Loss: 0.042859382927417755, Generator Loss: 4.641674518585205\n",
      "Epoch2: Discriminator Loss: 0.039543166756629944, Generator Loss: 4.994442462921143\n",
      "Epoch2: Discriminator Loss: 0.020499177277088165, Generator Loss: 5.028428554534912\n",
      "Epoch2: Discriminator Loss: 0.04891937971115112, Generator Loss: 5.656607627868652\n",
      "Epoch2: Discriminator Loss: 0.046963971108198166, Generator Loss: 3.957486629486084\n",
      "Epoch2: Discriminator Loss: 0.05438641086220741, Generator Loss: 3.275848627090454\n",
      "Epoch2: Discriminator Loss: 0.006991363596171141, Generator Loss: 4.927437782287598\n",
      "Epoch2: Discriminator Loss: 0.027591045945882797, Generator Loss: 3.853327989578247\n",
      "Epoch2: Discriminator Loss: 0.06087864190340042, Generator Loss: 4.2983269691467285\n",
      "Epoch2: Discriminator Loss: 0.003336085472255945, Generator Loss: 4.3577375411987305\n",
      "Epoch2: Discriminator Loss: 0.05067453160881996, Generator Loss: 2.5756912231445312\n",
      "Epoch2: Discriminator Loss: 0.007971898652613163, Generator Loss: 2.4950339794158936\n",
      "Epoch2: Discriminator Loss: 0.0051673767156898975, Generator Loss: 5.371527671813965\n",
      "Epoch2: Discriminator Loss: 0.016726240515708923, Generator Loss: 3.7823760509490967\n",
      "Epoch2: Discriminator Loss: 0.015394860878586769, Generator Loss: 3.6850175857543945\n",
      "Epoch2: Discriminator Loss: 0.042601440101861954, Generator Loss: 6.521993160247803\n",
      "Epoch2: Discriminator Loss: 0.046236760914325714, Generator Loss: 3.838115930557251\n",
      "Epoch2: Discriminator Loss: 0.06217600777745247, Generator Loss: 2.572786331176758\n",
      "Epoch2: Discriminator Loss: 0.003479521255940199, Generator Loss: 3.4475762844085693\n",
      "Epoch2: Discriminator Loss: 0.0027064005844295025, Generator Loss: 5.950368881225586\n",
      "Epoch2: Discriminator Loss: 0.02391134575009346, Generator Loss: 6.369719982147217\n",
      "Epoch2: Discriminator Loss: 0.05750580132007599, Generator Loss: 3.0939841270446777\n",
      "Epoch2: Discriminator Loss: 0.08253882825374603, Generator Loss: 6.388908863067627\n",
      "Epoch2: Discriminator Loss: 0.0035788374952971935, Generator Loss: 4.443669319152832\n",
      "Epoch2: Discriminator Loss: 0.044847521930933, Generator Loss: 6.866015434265137\n",
      "Epoch2: Discriminator Loss: 0.006333373486995697, Generator Loss: 5.996181011199951\n",
      "Epoch2: Discriminator Loss: 0.0010596133070066571, Generator Loss: 6.240268230438232\n",
      "Epoch2: Discriminator Loss: 0.24501100182533264, Generator Loss: 5.328502655029297\n",
      "Epoch2: Discriminator Loss: 0.061785776168107986, Generator Loss: 6.145176410675049\n",
      "Epoch2: Discriminator Loss: 0.23549534380435944, Generator Loss: 5.502544403076172\n",
      "Epoch3: Discriminator Loss: 0.015317071229219437, Generator Loss: 5.037519931793213\n",
      "Epoch3: Discriminator Loss: 0.0059182546101510525, Generator Loss: 4.431272029876709\n",
      "Epoch3: Discriminator Loss: 0.003868711180984974, Generator Loss: 4.41323709487915\n",
      "Epoch3: Discriminator Loss: 0.10424190759658813, Generator Loss: 4.365792274475098\n",
      "Epoch3: Discriminator Loss: 0.059106361120939255, Generator Loss: 4.6701884269714355\n",
      "Epoch3: Discriminator Loss: 0.05256689712405205, Generator Loss: 3.6421022415161133\n",
      "Epoch3: Discriminator Loss: 0.05004524067044258, Generator Loss: 2.429624080657959\n",
      "Epoch3: Discriminator Loss: 0.045334599912166595, Generator Loss: 2.999730110168457\n",
      "Epoch3: Discriminator Loss: 0.13884398341178894, Generator Loss: 1.939388394355774\n",
      "Epoch3: Discriminator Loss: 0.07690121978521347, Generator Loss: 3.2681312561035156\n",
      "Epoch3: Discriminator Loss: 0.016279950737953186, Generator Loss: 2.119562864303589\n",
      "Epoch3: Discriminator Loss: 0.028920603916049004, Generator Loss: 4.205174446105957\n",
      "Epoch3: Discriminator Loss: 0.00953370425850153, Generator Loss: 2.869534969329834\n",
      "Epoch3: Discriminator Loss: 0.002199070993810892, Generator Loss: 3.894681930541992\n",
      "Epoch3: Discriminator Loss: 0.0075159394182264805, Generator Loss: 6.030858993530273\n",
      "Epoch3: Discriminator Loss: 0.058537788689136505, Generator Loss: 3.8239586353302\n",
      "Epoch3: Discriminator Loss: 0.008804937824606895, Generator Loss: 6.020367622375488\n",
      "Epoch3: Discriminator Loss: 0.002735232003033161, Generator Loss: 6.308405876159668\n",
      "Epoch3: Discriminator Loss: 0.002500132191926241, Generator Loss: 4.737431049346924\n",
      "Epoch3: Discriminator Loss: 0.025794461369514465, Generator Loss: 3.2003626823425293\n",
      "Epoch3: Discriminator Loss: 0.04581182822585106, Generator Loss: 5.366655349731445\n",
      "Epoch3: Discriminator Loss: 0.01826777681708336, Generator Loss: 6.4982218742370605\n",
      "Epoch3: Discriminator Loss: 0.1766870766878128, Generator Loss: 4.984430313110352\n",
      "Epoch3: Discriminator Loss: 0.002012451644986868, Generator Loss: 5.921865463256836\n",
      "Epoch3: Discriminator Loss: 0.0015440615825355053, Generator Loss: 6.1575703620910645\n",
      "Epoch3: Discriminator Loss: 0.10692869126796722, Generator Loss: 4.670386791229248\n",
      "Epoch3: Discriminator Loss: 0.04875098168849945, Generator Loss: 6.2420501708984375\n",
      "Epoch3: Discriminator Loss: 0.11965291947126389, Generator Loss: 3.5911002159118652\n",
      "Epoch3: Discriminator Loss: 0.001407006522640586, Generator Loss: 4.038078784942627\n",
      "Epoch3: Discriminator Loss: 0.003916178364306688, Generator Loss: 3.415665626525879\n",
      "Epoch3: Discriminator Loss: 0.006908858194947243, Generator Loss: 3.9165945053100586\n",
      "Epoch3: Discriminator Loss: 0.06542044878005981, Generator Loss: 5.875234127044678\n",
      "Epoch3: Discriminator Loss: 0.04177973419427872, Generator Loss: 4.420441150665283\n",
      "Epoch3: Discriminator Loss: 0.029338212683796883, Generator Loss: 2.9424355030059814\n",
      "Epoch3: Discriminator Loss: 0.0024339682422578335, Generator Loss: 5.027856349945068\n",
      "Epoch3: Discriminator Loss: 0.01910809427499771, Generator Loss: 3.858062505722046\n",
      "Epoch3: Discriminator Loss: 0.0019014899153262377, Generator Loss: 4.661608695983887\n",
      "Epoch3: Discriminator Loss: 0.0031635237392038107, Generator Loss: 6.698339939117432\n",
      "Epoch3: Discriminator Loss: 0.0274853203445673, Generator Loss: 4.878716945648193\n",
      "Epoch3: Discriminator Loss: 0.0018584812059998512, Generator Loss: 5.669676780700684\n",
      "Epoch3: Discriminator Loss: 0.13897757232189178, Generator Loss: 2.273796319961548\n",
      "Epoch3: Discriminator Loss: 0.046833448112010956, Generator Loss: 6.853723049163818\n",
      "Epoch3: Discriminator Loss: 0.0022209545131772757, Generator Loss: 4.9472527503967285\n",
      "Epoch3: Discriminator Loss: 0.05793618783354759, Generator Loss: 4.9013824462890625\n",
      "Epoch3: Discriminator Loss: 0.014573778957128525, Generator Loss: 3.8165128231048584\n",
      "Epoch3: Discriminator Loss: 0.0077368104830384254, Generator Loss: 6.033083915710449\n",
      "Epoch3: Discriminator Loss: 0.07466667890548706, Generator Loss: 6.2301554679870605\n",
      "Epoch3: Discriminator Loss: 0.016631772741675377, Generator Loss: 6.8995361328125\n",
      "Epoch3: Discriminator Loss: 0.0007185162976384163, Generator Loss: 6.315093040466309\n",
      "Epoch3: Discriminator Loss: 0.00076787214493379, Generator Loss: 7.177418231964111\n",
      "Epoch3: Discriminator Loss: 0.0008678625454194844, Generator Loss: 6.630863666534424\n",
      "Epoch3: Discriminator Loss: 0.07825625687837601, Generator Loss: 5.845278263092041\n",
      "Epoch3: Discriminator Loss: 0.007654552347958088, Generator Loss: 6.077716827392578\n",
      "Epoch3: Discriminator Loss: 0.014322785660624504, Generator Loss: 3.9505863189697266\n",
      "Epoch3: Discriminator Loss: 0.0029225663747638464, Generator Loss: 5.061089992523193\n",
      "Epoch3: Discriminator Loss: 0.00324012222699821, Generator Loss: 5.067636966705322\n",
      "Epoch3: Discriminator Loss: 0.0007099377107806504, Generator Loss: 7.361611843109131\n",
      "Epoch3: Discriminator Loss: 0.010211189277470112, Generator Loss: 4.347682952880859\n",
      "Epoch3: Discriminator Loss: 0.027663255110383034, Generator Loss: 4.126434326171875\n",
      "Epoch3: Discriminator Loss: 0.0813206136226654, Generator Loss: 6.158929347991943\n",
      "Epoch3: Discriminator Loss: 0.004193511791527271, Generator Loss: 6.467074394226074\n",
      "Epoch3: Discriminator Loss: 0.006303106900304556, Generator Loss: 6.66905403137207\n",
      "Epoch3: Discriminator Loss: 0.007777184247970581, Generator Loss: 6.51489782333374\n",
      "Epoch3: Discriminator Loss: 0.0006795988883823156, Generator Loss: 6.952970027923584\n",
      "Epoch3: Discriminator Loss: 0.0018922366434708238, Generator Loss: 6.26822566986084\n",
      "Epoch3: Discriminator Loss: 0.14441576600074768, Generator Loss: 5.9972004890441895\n",
      "Epoch3: Discriminator Loss: 0.019034389406442642, Generator Loss: 3.3322913646698\n",
      "Epoch3: Discriminator Loss: 0.002856885315850377, Generator Loss: 4.29061222076416\n",
      "Epoch3: Discriminator Loss: 0.030277026817202568, Generator Loss: 6.047896862030029\n",
      "Epoch3: Discriminator Loss: 0.007716821040958166, Generator Loss: 4.329672813415527\n",
      "Epoch3: Discriminator Loss: 0.00993055384606123, Generator Loss: 3.306727409362793\n",
      "Epoch3: Discriminator Loss: 0.006234711967408657, Generator Loss: 4.77959680557251\n",
      "Epoch3: Discriminator Loss: 0.13721062242984772, Generator Loss: 3.0203065872192383\n",
      "Epoch3: Discriminator Loss: 0.031229790300130844, Generator Loss: 2.6074941158294678\n",
      "Epoch3: Discriminator Loss: 0.07060109078884125, Generator Loss: 4.241129398345947\n",
      "Epoch3: Discriminator Loss: 0.0013148158323019743, Generator Loss: 6.013621807098389\n",
      "Epoch3: Discriminator Loss: 0.03042883425951004, Generator Loss: 6.0920915603637695\n",
      "Epoch3: Discriminator Loss: 0.047229938209056854, Generator Loss: 7.726637363433838\n",
      "Epoch3: Discriminator Loss: 0.0071855876594781876, Generator Loss: 4.546187400817871\n",
      "Epoch3: Discriminator Loss: 0.005920472554862499, Generator Loss: 4.946806907653809\n",
      "Epoch3: Discriminator Loss: 0.014843840152025223, Generator Loss: 6.073144912719727\n",
      "Epoch3: Discriminator Loss: 0.06077196076512337, Generator Loss: 7.0378336906433105\n",
      "Epoch3: Discriminator Loss: 0.0006267440039664507, Generator Loss: 5.3576979637146\n",
      "Epoch3: Discriminator Loss: 0.04290022701025009, Generator Loss: 2.362166166305542\n",
      "Epoch3: Discriminator Loss: 0.006820834707468748, Generator Loss: 4.627463340759277\n",
      "Epoch3: Discriminator Loss: 0.0759613960981369, Generator Loss: 2.970456838607788\n",
      "Epoch3: Discriminator Loss: 0.00228400737978518, Generator Loss: 4.185441493988037\n",
      "Epoch3: Discriminator Loss: 0.018919453024864197, Generator Loss: 6.568660736083984\n",
      "Epoch3: Discriminator Loss: 0.056467313319444656, Generator Loss: 3.6936957836151123\n",
      "Epoch3: Discriminator Loss: 0.025354528799653053, Generator Loss: 3.51141357421875\n",
      "Epoch3: Discriminator Loss: 0.014332388527691364, Generator Loss: 3.8483617305755615\n",
      "Epoch3: Discriminator Loss: 0.0009571777773089707, Generator Loss: 6.526951313018799\n",
      "Epoch3: Discriminator Loss: 0.036121565848588943, Generator Loss: 7.698263168334961\n",
      "Epoch3: Discriminator Loss: 0.06290162354707718, Generator Loss: 4.1472320556640625\n",
      "Epoch3: Discriminator Loss: 0.13076895475387573, Generator Loss: 3.8010387420654297\n",
      "Epoch3: Discriminator Loss: 0.05674906447529793, Generator Loss: 6.098884105682373\n",
      "Epoch3: Discriminator Loss: 0.03178118169307709, Generator Loss: 6.6440534591674805\n",
      "Epoch3: Discriminator Loss: 0.02604042738676071, Generator Loss: 4.699204444885254\n",
      "Epoch3: Discriminator Loss: 0.0029835966415703297, Generator Loss: 4.680348873138428\n",
      "Epoch3: Discriminator Loss: 0.02487940341234207, Generator Loss: 5.719346523284912\n",
      "Epoch3: Discriminator Loss: 0.0321902371942997, Generator Loss: 6.50124454498291\n",
      "Epoch3: Discriminator Loss: 0.07494227588176727, Generator Loss: 6.654971122741699\n",
      "Epoch3: Discriminator Loss: 0.00072416354669258, Generator Loss: 6.5502495765686035\n",
      "Epoch3: Discriminator Loss: 0.10542427003383636, Generator Loss: 2.3721206188201904\n",
      "Epoch3: Discriminator Loss: 0.02256348729133606, Generator Loss: 5.189085006713867\n",
      "Epoch3: Discriminator Loss: 0.012108446098864079, Generator Loss: 6.319047451019287\n",
      "Epoch3: Discriminator Loss: 0.0008314821752719581, Generator Loss: 7.203439712524414\n",
      "Epoch3: Discriminator Loss: 0.0004041383508592844, Generator Loss: 5.970026016235352\n",
      "Epoch3: Discriminator Loss: 0.02322157472372055, Generator Loss: 4.273536682128906\n",
      "Epoch3: Discriminator Loss: 0.04394268989562988, Generator Loss: 5.337459087371826\n",
      "Epoch3: Discriminator Loss: 0.09224873781204224, Generator Loss: 6.1188740730285645\n",
      "Epoch3: Discriminator Loss: 0.0011341487988829613, Generator Loss: 6.15926456451416\n",
      "Epoch3: Discriminator Loss: 0.003442050190642476, Generator Loss: 4.3818535804748535\n",
      "Epoch3: Discriminator Loss: 0.013144558295607567, Generator Loss: 5.37565279006958\n",
      "Epoch3: Discriminator Loss: 0.01112116314470768, Generator Loss: 5.826160907745361\n",
      "Epoch3: Discriminator Loss: 0.028186554089188576, Generator Loss: 2.9552676677703857\n",
      "Epoch3: Discriminator Loss: 0.007643803022801876, Generator Loss: 5.78957462310791\n",
      "Epoch3: Discriminator Loss: 0.02874164842069149, Generator Loss: 3.3371593952178955\n",
      "Epoch3: Discriminator Loss: 0.04089662805199623, Generator Loss: 3.036943197250366\n",
      "Epoch3: Discriminator Loss: 0.0021872282959520817, Generator Loss: 2.9909465312957764\n",
      "Epoch3: Discriminator Loss: 0.08544692397117615, Generator Loss: 4.555269241333008\n",
      "Epoch3: Discriminator Loss: 0.0007639740942977369, Generator Loss: 6.982117176055908\n",
      "Epoch3: Discriminator Loss: 0.05214402824640274, Generator Loss: 6.339047908782959\n",
      "Epoch3: Discriminator Loss: 0.001310771214775741, Generator Loss: 3.5198888778686523\n",
      "Epoch3: Discriminator Loss: 0.0034117139875888824, Generator Loss: 4.428923606872559\n",
      "Epoch3: Discriminator Loss: 0.04946080222725868, Generator Loss: 5.322751998901367\n",
      "Epoch3: Discriminator Loss: 0.0009744380367919803, Generator Loss: 6.044492721557617\n",
      "Epoch3: Discriminator Loss: 0.005711303558200598, Generator Loss: 1.6791778802871704\n",
      "Epoch3: Discriminator Loss: 0.005427813157439232, Generator Loss: 5.262604713439941\n",
      "Epoch3: Discriminator Loss: 0.004787709563970566, Generator Loss: 5.118069171905518\n",
      "Epoch3: Discriminator Loss: 0.005901318974792957, Generator Loss: 0.8145996928215027\n",
      "Epoch3: Discriminator Loss: 0.06244060397148132, Generator Loss: 4.9291815757751465\n",
      "Epoch3: Discriminator Loss: 0.015225163660943508, Generator Loss: 4.890673637390137\n",
      "Epoch3: Discriminator Loss: 0.0005980255664326251, Generator Loss: 6.968072414398193\n",
      "Epoch3: Discriminator Loss: 0.020390905439853668, Generator Loss: 2.8720405101776123\n",
      "Epoch3: Discriminator Loss: 1.1866945028305054, Generator Loss: 1.1258983612060547\n",
      "Epoch3: Discriminator Loss: 0.002580275060608983, Generator Loss: 7.6515913009643555\n",
      "Epoch3: Discriminator Loss: 0.008872785605490208, Generator Loss: 6.8920817375183105\n",
      "Epoch3: Discriminator Loss: 0.1818353831768036, Generator Loss: 7.522639751434326\n",
      "Epoch3: Discriminator Loss: 0.1262873262166977, Generator Loss: 8.657509803771973\n",
      "Epoch3: Discriminator Loss: 0.0014289357932284474, Generator Loss: 10.241439819335938\n",
      "Epoch3: Discriminator Loss: 0.19852188229560852, Generator Loss: 9.63459587097168\n",
      "Epoch3: Discriminator Loss: 0.19872958958148956, Generator Loss: 10.001992225646973\n",
      "Epoch3: Discriminator Loss: 0.45349302887916565, Generator Loss: 10.923868179321289\n",
      "Epoch3: Discriminator Loss: 0.20488929748535156, Generator Loss: 11.89802360534668\n",
      "Epoch3: Discriminator Loss: 0.06467919051647186, Generator Loss: 10.889399528503418\n",
      "Epoch3: Discriminator Loss: 0.18864691257476807, Generator Loss: 8.759482383728027\n",
      "Epoch3: Discriminator Loss: 0.49491629004478455, Generator Loss: 9.155945777893066\n",
      "Epoch3: Discriminator Loss: 0.0833439975976944, Generator Loss: 7.14361047744751\n",
      "Epoch3: Discriminator Loss: 0.3762321174144745, Generator Loss: 10.283288955688477\n",
      "Epoch3: Discriminator Loss: 0.15360628068447113, Generator Loss: 8.880105972290039\n",
      "Epoch3: Discriminator Loss: 0.00017580544226802886, Generator Loss: 10.834504127502441\n",
      "Epoch3: Discriminator Loss: 0.11245281994342804, Generator Loss: 8.85692310333252\n",
      "Epoch3: Discriminator Loss: 0.00024695240426808596, Generator Loss: 8.83788776397705\n",
      "Epoch3: Discriminator Loss: 0.00019283471920061857, Generator Loss: 7.849280834197998\n",
      "Epoch3: Discriminator Loss: 0.013079982250928879, Generator Loss: 6.3086838722229\n",
      "Epoch3: Discriminator Loss: 0.001078564440831542, Generator Loss: 6.025142192840576\n",
      "Epoch3: Discriminator Loss: 0.023609498515725136, Generator Loss: 4.694773197174072\n",
      "Epoch3: Discriminator Loss: 0.08545925468206406, Generator Loss: 2.0606963634490967\n",
      "Epoch3: Discriminator Loss: 0.04590858146548271, Generator Loss: 2.825336456298828\n",
      "Epoch3: Discriminator Loss: 0.12838095426559448, Generator Loss: 1.817941665649414\n",
      "Epoch3: Discriminator Loss: 0.016319449990987778, Generator Loss: 4.499491214752197\n",
      "Epoch3: Discriminator Loss: 0.018472591415047646, Generator Loss: 3.330554962158203\n",
      "Epoch3: Discriminator Loss: 0.07197967171669006, Generator Loss: 6.946139335632324\n",
      "Epoch3: Discriminator Loss: 0.038256093859672546, Generator Loss: 5.162165641784668\n",
      "Epoch3: Discriminator Loss: 0.02800295315682888, Generator Loss: 3.4508557319641113\n",
      "Epoch3: Discriminator Loss: 0.015132245607674122, Generator Loss: 4.150843620300293\n",
      "Epoch3: Discriminator Loss: 0.01248961128294468, Generator Loss: 6.407083034515381\n",
      "Epoch3: Discriminator Loss: 0.0009473050013184547, Generator Loss: 6.299820423126221\n",
      "Epoch3: Discriminator Loss: 0.061431560665369034, Generator Loss: 6.210666179656982\n",
      "Epoch3: Discriminator Loss: 0.005293766036629677, Generator Loss: 8.267040252685547\n",
      "Epoch3: Discriminator Loss: 0.001688983291387558, Generator Loss: 5.155980587005615\n",
      "Epoch3: Discriminator Loss: 0.0013135882327333093, Generator Loss: 5.428646564483643\n",
      "Epoch3: Discriminator Loss: 0.062461189925670624, Generator Loss: 7.048701763153076\n",
      "Epoch3: Discriminator Loss: 0.001805862644687295, Generator Loss: 6.780258655548096\n",
      "Epoch3: Discriminator Loss: 0.038065098226070404, Generator Loss: 2.818204402923584\n",
      "Epoch4: Discriminator Loss: 0.013856274075806141, Generator Loss: 7.3299174308776855\n",
      "Epoch4: Discriminator Loss: 0.03965660557150841, Generator Loss: 7.757320404052734\n",
      "Epoch4: Discriminator Loss: 0.036179158836603165, Generator Loss: 8.798160552978516\n",
      "Epoch4: Discriminator Loss: 0.0013500831555575132, Generator Loss: 6.558006286621094\n",
      "Epoch4: Discriminator Loss: 0.008325861766934395, Generator Loss: 6.030281066894531\n",
      "Epoch4: Discriminator Loss: 0.010290046222507954, Generator Loss: 6.531703472137451\n",
      "Epoch4: Discriminator Loss: 0.007376591209322214, Generator Loss: 5.828123569488525\n",
      "Epoch4: Discriminator Loss: 0.01440590713173151, Generator Loss: 4.59250020980835\n",
      "Epoch4: Discriminator Loss: 0.10532726347446442, Generator Loss: 2.125605583190918\n",
      "Epoch4: Discriminator Loss: 0.12248560786247253, Generator Loss: 3.5512850284576416\n",
      "Epoch4: Discriminator Loss: 0.07334958016872406, Generator Loss: 6.821763038635254\n",
      "Epoch4: Discriminator Loss: 0.007630181033164263, Generator Loss: 5.082983016967773\n",
      "Epoch4: Discriminator Loss: 0.08695580810308456, Generator Loss: 5.363659858703613\n",
      "Epoch4: Discriminator Loss: 7.93797371443361e-05, Generator Loss: 7.323793411254883\n",
      "Epoch4: Discriminator Loss: 0.01301013957709074, Generator Loss: 6.369945526123047\n",
      "Epoch4: Discriminator Loss: 0.017795685678720474, Generator Loss: 5.899654865264893\n",
      "Epoch4: Discriminator Loss: 0.005184821784496307, Generator Loss: 8.64453411102295\n",
      "Epoch4: Discriminator Loss: 0.007369884755462408, Generator Loss: 7.122198104858398\n",
      "Epoch4: Discriminator Loss: 0.0008069775067269802, Generator Loss: 7.024789810180664\n",
      "Epoch4: Discriminator Loss: 0.02008025534451008, Generator Loss: 8.245610237121582\n",
      "Epoch4: Discriminator Loss: 0.19193331897258759, Generator Loss: 5.554257392883301\n",
      "Epoch4: Discriminator Loss: 0.0018621934577822685, Generator Loss: 6.763757228851318\n",
      "Epoch4: Discriminator Loss: 0.06487621366977692, Generator Loss: 5.693871974945068\n",
      "Epoch4: Discriminator Loss: 0.0016207948792725801, Generator Loss: 4.769681930541992\n",
      "Epoch4: Discriminator Loss: 0.03205620497465134, Generator Loss: 4.347466945648193\n",
      "Epoch4: Discriminator Loss: 0.0001585789432283491, Generator Loss: 8.531831741333008\n",
      "Epoch4: Discriminator Loss: 0.001044363365508616, Generator Loss: 8.067794799804688\n",
      "Epoch4: Discriminator Loss: 0.0029655664693564177, Generator Loss: 5.815394878387451\n",
      "Epoch4: Discriminator Loss: 0.021643564105033875, Generator Loss: 2.7513482570648193\n",
      "Epoch4: Discriminator Loss: 0.17176899313926697, Generator Loss: 2.9145150184631348\n",
      "Epoch4: Discriminator Loss: 0.056019626557826996, Generator Loss: 5.927662372589111\n",
      "Epoch4: Discriminator Loss: 0.07327861338853836, Generator Loss: 7.100070953369141\n",
      "Epoch4: Discriminator Loss: 0.05519923195242882, Generator Loss: 9.246726036071777\n",
      "Epoch4: Discriminator Loss: 0.0005331264110282063, Generator Loss: 7.397258281707764\n",
      "Epoch4: Discriminator Loss: 0.0006419611163437366, Generator Loss: 6.841559886932373\n",
      "Epoch4: Discriminator Loss: 0.0004225599695928395, Generator Loss: 7.853148460388184\n",
      "Epoch4: Discriminator Loss: 0.12923604249954224, Generator Loss: 8.714432716369629\n",
      "Epoch4: Discriminator Loss: 0.011522539891302586, Generator Loss: 6.738064289093018\n",
      "Epoch4: Discriminator Loss: 0.13813252747058868, Generator Loss: 7.230508804321289\n",
      "Epoch4: Discriminator Loss: 0.002906014444306493, Generator Loss: 7.031248569488525\n",
      "Epoch4: Discriminator Loss: 0.0004084236570633948, Generator Loss: 6.79232120513916\n",
      "Epoch4: Discriminator Loss: 0.20120328664779663, Generator Loss: 6.068822860717773\n",
      "Epoch4: Discriminator Loss: 0.0009815129451453686, Generator Loss: 8.566261291503906\n",
      "Epoch4: Discriminator Loss: 0.0001730248477542773, Generator Loss: 8.695566177368164\n",
      "Epoch4: Discriminator Loss: 0.006844666320830584, Generator Loss: 6.51910400390625\n",
      "Epoch4: Discriminator Loss: 0.012051324360072613, Generator Loss: 6.229907035827637\n",
      "Epoch4: Discriminator Loss: 0.0016383862821385264, Generator Loss: 3.3791799545288086\n",
      "Epoch4: Discriminator Loss: 0.2389116883277893, Generator Loss: 2.2991483211517334\n",
      "Epoch4: Discriminator Loss: 0.029942037537693977, Generator Loss: 6.4417405128479\n",
      "Epoch4: Discriminator Loss: 0.004755490925163031, Generator Loss: 4.0732855796813965\n",
      "Epoch4: Discriminator Loss: 0.0006323856650851667, Generator Loss: 6.3365936279296875\n",
      "Epoch4: Discriminator Loss: 0.0006410811329260468, Generator Loss: 5.834083557128906\n",
      "Epoch4: Discriminator Loss: 0.0015083237085491419, Generator Loss: 4.557623386383057\n",
      "Epoch4: Discriminator Loss: 0.00074516620952636, Generator Loss: 6.577530860900879\n",
      "Epoch4: Discriminator Loss: 0.0019608931615948677, Generator Loss: 6.852357864379883\n",
      "Epoch4: Discriminator Loss: 0.1500231772661209, Generator Loss: 6.701749801635742\n",
      "Epoch4: Discriminator Loss: 0.0007434403523802757, Generator Loss: 5.999189853668213\n",
      "Epoch4: Discriminator Loss: 0.04194275289773941, Generator Loss: 5.509876251220703\n",
      "Epoch4: Discriminator Loss: 0.005426362156867981, Generator Loss: 7.099215507507324\n",
      "Epoch4: Discriminator Loss: 0.030684392899274826, Generator Loss: 7.471075534820557\n",
      "Epoch4: Discriminator Loss: 0.011280977167189121, Generator Loss: 3.034245252609253\n",
      "Epoch4: Discriminator Loss: 0.017487360164523125, Generator Loss: 5.881750106811523\n",
      "Epoch4: Discriminator Loss: 0.001022928743623197, Generator Loss: 6.896585941314697\n",
      "Epoch4: Discriminator Loss: 0.0057517471723258495, Generator Loss: 4.979684829711914\n",
      "Epoch4: Discriminator Loss: 0.0007012200658209622, Generator Loss: 6.65037202835083\n",
      "Epoch4: Discriminator Loss: 0.0009313783957622945, Generator Loss: 7.138944149017334\n",
      "Epoch4: Discriminator Loss: 0.0018798820674419403, Generator Loss: 4.836851119995117\n",
      "Epoch4: Discriminator Loss: 0.06985766440629959, Generator Loss: 3.4772706031799316\n",
      "Epoch4: Discriminator Loss: 0.019241593778133392, Generator Loss: 5.943190097808838\n",
      "Epoch4: Discriminator Loss: 0.0027006110176444054, Generator Loss: 5.097400188446045\n",
      "Epoch4: Discriminator Loss: 0.005282348953187466, Generator Loss: 7.30129337310791\n",
      "Epoch4: Discriminator Loss: 0.03614838793873787, Generator Loss: 7.013623237609863\n",
      "Epoch4: Discriminator Loss: 0.000739777460694313, Generator Loss: 6.834197044372559\n",
      "Epoch4: Discriminator Loss: 0.0002450210740789771, Generator Loss: 6.848350524902344\n",
      "Epoch4: Discriminator Loss: 0.05148138850927353, Generator Loss: 4.3206095695495605\n",
      "Epoch4: Discriminator Loss: 0.0012076187413185835, Generator Loss: 7.024900436401367\n",
      "Epoch4: Discriminator Loss: 0.0023090317845344543, Generator Loss: 7.1314873695373535\n",
      "Epoch4: Discriminator Loss: 0.006717926822602749, Generator Loss: 7.0192179679870605\n",
      "Epoch4: Discriminator Loss: 0.010733810253441334, Generator Loss: 8.09210205078125\n",
      "Epoch4: Discriminator Loss: 0.00024277082411572337, Generator Loss: 8.696526527404785\n",
      "Epoch4: Discriminator Loss: 0.001505934982560575, Generator Loss: 5.742654800415039\n",
      "Epoch4: Discriminator Loss: 0.004682740196585655, Generator Loss: 6.567346096038818\n",
      "Epoch4: Discriminator Loss: 0.08827543258666992, Generator Loss: 7.3381853103637695\n",
      "Epoch4: Discriminator Loss: 0.005597820971161127, Generator Loss: 8.954216957092285\n",
      "Epoch4: Discriminator Loss: 0.08395273983478546, Generator Loss: 7.001694202423096\n",
      "Epoch4: Discriminator Loss: 0.0017325285589322448, Generator Loss: 5.825301170349121\n",
      "Epoch4: Discriminator Loss: 0.003353806911036372, Generator Loss: 4.0817413330078125\n",
      "Epoch4: Discriminator Loss: 0.06964494287967682, Generator Loss: 6.277398586273193\n",
      "Epoch4: Discriminator Loss: 0.026153311133384705, Generator Loss: 3.5790531635284424\n",
      "Epoch4: Discriminator Loss: 0.0046055070124566555, Generator Loss: 3.8352954387664795\n",
      "Epoch4: Discriminator Loss: 0.010967952199280262, Generator Loss: 5.206151485443115\n",
      "Epoch4: Discriminator Loss: 0.0006846563192084432, Generator Loss: 6.294230937957764\n",
      "Epoch4: Discriminator Loss: 0.008643790148198605, Generator Loss: 6.635968208312988\n",
      "Epoch4: Discriminator Loss: 0.006554716266691685, Generator Loss: 5.254364967346191\n",
      "Epoch4: Discriminator Loss: 0.009378384798765182, Generator Loss: 6.952332973480225\n",
      "Epoch4: Discriminator Loss: 0.0014083413407206535, Generator Loss: 6.965759754180908\n",
      "Epoch4: Discriminator Loss: 0.0026668328791856766, Generator Loss: 5.125012397766113\n",
      "Epoch4: Discriminator Loss: 0.01258921716362238, Generator Loss: 5.072075843811035\n",
      "Epoch4: Discriminator Loss: 0.0008350594434887171, Generator Loss: 6.68951416015625\n",
      "Epoch4: Discriminator Loss: 0.014535273425281048, Generator Loss: 7.452958583831787\n",
      "Epoch4: Discriminator Loss: 0.006494890432804823, Generator Loss: 4.992000102996826\n",
      "Epoch4: Discriminator Loss: 0.005021959543228149, Generator Loss: 5.201053619384766\n",
      "Epoch4: Discriminator Loss: 0.00048605320625938475, Generator Loss: 6.418351173400879\n",
      "Epoch4: Discriminator Loss: 0.20694872736930847, Generator Loss: 1.3017399311065674\n",
      "Epoch4: Discriminator Loss: 0.020783133804798126, Generator Loss: 2.766218423843384\n",
      "Epoch4: Discriminator Loss: 0.046556778252124786, Generator Loss: 6.258956432342529\n",
      "Epoch4: Discriminator Loss: 0.005334434099495411, Generator Loss: 7.639520645141602\n",
      "Epoch4: Discriminator Loss: 0.011611058376729488, Generator Loss: 7.427726745605469\n",
      "Epoch4: Discriminator Loss: 0.007366269361227751, Generator Loss: 7.4331488609313965\n",
      "Epoch4: Discriminator Loss: 0.061150576919317245, Generator Loss: 6.838466167449951\n",
      "Epoch4: Discriminator Loss: 0.08017539232969284, Generator Loss: 8.447212219238281\n",
      "Epoch4: Discriminator Loss: 0.008354106917977333, Generator Loss: 8.699481964111328\n",
      "Epoch4: Discriminator Loss: 0.0003019394935108721, Generator Loss: 9.851022720336914\n",
      "Epoch4: Discriminator Loss: 0.0005170274525880814, Generator Loss: 6.809693336486816\n",
      "Epoch4: Discriminator Loss: 0.08683726191520691, Generator Loss: 9.00318717956543\n",
      "Epoch4: Discriminator Loss: 0.00010520874639041722, Generator Loss: 10.557255744934082\n",
      "Epoch4: Discriminator Loss: 0.00029445267864502966, Generator Loss: 8.212264060974121\n",
      "Epoch4: Discriminator Loss: 0.032536085695028305, Generator Loss: 8.333311080932617\n",
      "Epoch4: Discriminator Loss: 0.02633054554462433, Generator Loss: 9.609114646911621\n",
      "Epoch4: Discriminator Loss: 0.013088157400488853, Generator Loss: 7.558407783508301\n",
      "Epoch4: Discriminator Loss: 0.0008449162123724818, Generator Loss: 6.779496669769287\n",
      "Epoch4: Discriminator Loss: 0.00036717590410262346, Generator Loss: 8.911335945129395\n",
      "Epoch4: Discriminator Loss: 0.00362721411511302, Generator Loss: 7.0504350662231445\n",
      "Epoch4: Discriminator Loss: 0.0071313027292490005, Generator Loss: 9.650971412658691\n",
      "Epoch4: Discriminator Loss: 0.00018018503033090383, Generator Loss: 7.899568557739258\n",
      "Epoch4: Discriminator Loss: 0.08186639845371246, Generator Loss: 8.261831283569336\n",
      "Epoch4: Discriminator Loss: 0.030056316405534744, Generator Loss: 5.583003520965576\n",
      "Epoch4: Discriminator Loss: 0.00027695376775227487, Generator Loss: 7.102494239807129\n",
      "Epoch4: Discriminator Loss: 0.016724079847335815, Generator Loss: 6.751798152923584\n",
      "Epoch4: Discriminator Loss: 0.0005871710600331426, Generator Loss: 7.588942527770996\n",
      "Epoch4: Discriminator Loss: 0.00011015481140930206, Generator Loss: 9.062037467956543\n",
      "Epoch4: Discriminator Loss: 0.0531955324113369, Generator Loss: 6.469180583953857\n",
      "Epoch4: Discriminator Loss: 0.0074101961217820644, Generator Loss: 7.592254638671875\n",
      "Epoch4: Discriminator Loss: 0.0025770291686058044, Generator Loss: 2.451484441757202\n",
      "Epoch4: Discriminator Loss: 0.02580394223332405, Generator Loss: 3.805082321166992\n",
      "Epoch4: Discriminator Loss: 0.001636074623093009, Generator Loss: 5.874513626098633\n",
      "Epoch4: Discriminator Loss: 0.003746368922293186, Generator Loss: 4.158353805541992\n",
      "Epoch4: Discriminator Loss: 0.011494540609419346, Generator Loss: 5.731370449066162\n",
      "Epoch4: Discriminator Loss: 0.0004399410681799054, Generator Loss: 5.245739936828613\n",
      "Epoch4: Discriminator Loss: 0.00031253675115294755, Generator Loss: 6.4458537101745605\n",
      "Epoch4: Discriminator Loss: 0.002484566066414118, Generator Loss: 4.425022125244141\n",
      "Epoch4: Discriminator Loss: 0.03315473347902298, Generator Loss: 4.299961090087891\n",
      "Epoch4: Discriminator Loss: 0.0031473045237362385, Generator Loss: 3.282130241394043\n",
      "Epoch4: Discriminator Loss: 0.0037697621155530214, Generator Loss: 6.418613433837891\n",
      "Epoch4: Discriminator Loss: 0.0005517136305570602, Generator Loss: 6.808889865875244\n",
      "Epoch4: Discriminator Loss: 0.0009576386073604226, Generator Loss: 6.108740329742432\n",
      "Epoch4: Discriminator Loss: 0.009772785939276218, Generator Loss: 2.427048683166504\n",
      "Epoch4: Discriminator Loss: 0.060063961893320084, Generator Loss: 4.932153224945068\n",
      "Epoch4: Discriminator Loss: 0.00245919288136065, Generator Loss: 6.762555122375488\n",
      "Epoch4: Discriminator Loss: 0.0013906675158068538, Generator Loss: 6.898802757263184\n",
      "Epoch4: Discriminator Loss: 0.007890872657299042, Generator Loss: 5.346649169921875\n",
      "Epoch4: Discriminator Loss: 0.003672288963571191, Generator Loss: 4.562206745147705\n",
      "Epoch4: Discriminator Loss: 0.04444672912359238, Generator Loss: 7.031188011169434\n",
      "Epoch4: Discriminator Loss: 0.014270225539803505, Generator Loss: 4.66880464553833\n",
      "Epoch4: Discriminator Loss: 0.019122788682579994, Generator Loss: 3.443571090698242\n",
      "Epoch4: Discriminator Loss: 0.01141833234578371, Generator Loss: 6.522972583770752\n",
      "Epoch4: Discriminator Loss: 0.03060775063931942, Generator Loss: 3.6115689277648926\n",
      "Epoch4: Discriminator Loss: 0.0012290931772440672, Generator Loss: 7.6903533935546875\n",
      "Epoch4: Discriminator Loss: 0.017546502873301506, Generator Loss: 4.846766948699951\n",
      "Epoch4: Discriminator Loss: 0.0010895992163568735, Generator Loss: 6.683960437774658\n",
      "Epoch4: Discriminator Loss: 0.002532282378524542, Generator Loss: 4.260344505310059\n",
      "Epoch4: Discriminator Loss: 0.0007626423612236977, Generator Loss: 7.4363627433776855\n",
      "Epoch4: Discriminator Loss: 0.02468995936214924, Generator Loss: 1.4933803081512451\n",
      "Epoch4: Discriminator Loss: 0.00247580767609179, Generator Loss: 7.469876289367676\n",
      "Epoch4: Discriminator Loss: 0.00547787407413125, Generator Loss: 7.43574333190918\n",
      "Epoch4: Discriminator Loss: 0.012060023844242096, Generator Loss: 4.796987533569336\n",
      "Epoch4: Discriminator Loss: 0.008585095405578613, Generator Loss: 4.73605489730835\n",
      "Epoch4: Discriminator Loss: 0.28989261388778687, Generator Loss: 1.8474390506744385\n",
      "Epoch4: Discriminator Loss: 0.0024710921570658684, Generator Loss: 4.718296527862549\n",
      "Epoch4: Discriminator Loss: 0.014059407636523247, Generator Loss: 7.890097141265869\n",
      "Epoch4: Discriminator Loss: 0.002559128450229764, Generator Loss: 7.4720683097839355\n",
      "Epoch4: Discriminator Loss: 0.07877407968044281, Generator Loss: 6.204331874847412\n",
      "Epoch4: Discriminator Loss: 0.0015890299109742045, Generator Loss: 9.509085655212402\n",
      "Epoch4: Discriminator Loss: 0.025694498792290688, Generator Loss: 7.934892654418945\n",
      "Epoch4: Discriminator Loss: 0.008502496406435966, Generator Loss: 7.852819442749023\n",
      "Epoch4: Discriminator Loss: 0.006709396373480558, Generator Loss: 10.758258819580078\n",
      "Epoch5: Discriminator Loss: 0.00019111250003334135, Generator Loss: 9.07738971710205\n",
      "Epoch5: Discriminator Loss: 0.15366627275943756, Generator Loss: 9.67856216430664\n",
      "Epoch5: Discriminator Loss: 0.09027227014303207, Generator Loss: 9.335917472839355\n",
      "Epoch5: Discriminator Loss: 0.09134725481271744, Generator Loss: 8.537395477294922\n",
      "Epoch5: Discriminator Loss: 0.0009953937260434031, Generator Loss: 8.822161674499512\n",
      "Epoch5: Discriminator Loss: 0.19488394260406494, Generator Loss: 9.677420616149902\n",
      "Epoch5: Discriminator Loss: 7.904578524176031e-05, Generator Loss: 9.087990760803223\n",
      "Epoch5: Discriminator Loss: 0.09488930553197861, Generator Loss: 9.91964340209961\n",
      "Epoch5: Discriminator Loss: 9.810435585677624e-05, Generator Loss: 9.0754976272583\n",
      "Epoch5: Discriminator Loss: 0.0003219562931917608, Generator Loss: 8.294326782226562\n",
      "Epoch5: Discriminator Loss: 0.00010465057130204514, Generator Loss: 9.309993743896484\n",
      "Epoch5: Discriminator Loss: 0.02066584676504135, Generator Loss: 7.992007255554199\n",
      "Epoch5: Discriminator Loss: 0.00011151008948218077, Generator Loss: 8.79405689239502\n",
      "Epoch5: Discriminator Loss: 0.04338424280285835, Generator Loss: 6.746426582336426\n",
      "Epoch5: Discriminator Loss: 0.0002588743227533996, Generator Loss: 8.275238990783691\n",
      "Epoch5: Discriminator Loss: 0.09573785960674286, Generator Loss: 7.319896221160889\n",
      "Epoch5: Discriminator Loss: 0.0023521913681179285, Generator Loss: 8.257288932800293\n",
      "Epoch5: Discriminator Loss: 0.040479935705661774, Generator Loss: 7.7887983322143555\n",
      "Epoch5: Discriminator Loss: 0.00017191703955177218, Generator Loss: 9.326131820678711\n",
      "Epoch5: Discriminator Loss: 0.0012066490016877651, Generator Loss: 7.484241485595703\n",
      "Epoch5: Discriminator Loss: 0.0457562617957592, Generator Loss: 7.043024063110352\n",
      "Epoch5: Discriminator Loss: 9.9781813332811e-05, Generator Loss: 8.813390731811523\n",
      "Epoch5: Discriminator Loss: 0.0023552589118480682, Generator Loss: 5.7053704261779785\n",
      "Epoch5: Discriminator Loss: 0.0016232281923294067, Generator Loss: 5.2084126472473145\n",
      "Epoch5: Discriminator Loss: 0.0021576588042080402, Generator Loss: 5.791210651397705\n",
      "Epoch5: Discriminator Loss: 0.04897265508770943, Generator Loss: 5.0561347007751465\n",
      "Epoch5: Discriminator Loss: 0.0031131114810705185, Generator Loss: 7.773748397827148\n",
      "Epoch5: Discriminator Loss: 0.006990404333919287, Generator Loss: 2.1136202812194824\n",
      "Epoch5: Discriminator Loss: 0.0027405726723372936, Generator Loss: 6.405511856079102\n",
      "Epoch5: Discriminator Loss: 0.020897522568702698, Generator Loss: 7.125187873840332\n",
      "Epoch5: Discriminator Loss: 0.0011660201707854867, Generator Loss: 5.634161472320557\n",
      "Epoch5: Discriminator Loss: 0.0033160136081278324, Generator Loss: 6.2080230712890625\n",
      "Epoch5: Discriminator Loss: 0.0007332941750064492, Generator Loss: 7.29915189743042\n",
      "Epoch5: Discriminator Loss: 0.04897254705429077, Generator Loss: 2.786022186279297\n",
      "Epoch5: Discriminator Loss: 0.0015901855658739805, Generator Loss: 7.104371070861816\n",
      "Epoch5: Discriminator Loss: 0.02518252283334732, Generator Loss: 1.8961684703826904\n",
      "Epoch5: Discriminator Loss: 0.009050225839018822, Generator Loss: 5.797754287719727\n",
      "Epoch5: Discriminator Loss: 0.00106902071274817, Generator Loss: 6.545010566711426\n",
      "Epoch5: Discriminator Loss: 0.10813684016466141, Generator Loss: 2.9069278240203857\n",
      "Epoch5: Discriminator Loss: 0.001932400045916438, Generator Loss: 4.8127312660217285\n",
      "Epoch5: Discriminator Loss: 0.004760871175676584, Generator Loss: 6.616978645324707\n",
      "Epoch5: Discriminator Loss: 0.00010110089351655915, Generator Loss: 7.90788459777832\n",
      "Epoch5: Discriminator Loss: 0.004759741015732288, Generator Loss: 7.399697303771973\n",
      "Epoch5: Discriminator Loss: 0.0010642481502145529, Generator Loss: 5.8971076011657715\n",
      "Epoch5: Discriminator Loss: 0.08660668879747391, Generator Loss: 8.94870376586914\n",
      "Epoch5: Discriminator Loss: 0.019709762185811996, Generator Loss: 7.455045700073242\n",
      "Epoch5: Discriminator Loss: 0.0022766373585909605, Generator Loss: 5.8656511306762695\n",
      "Epoch5: Discriminator Loss: 0.08359768986701965, Generator Loss: 6.536000728607178\n",
      "Epoch5: Discriminator Loss: 0.005770913325250149, Generator Loss: 6.499301433563232\n",
      "Epoch5: Discriminator Loss: 0.00016718704137019813, Generator Loss: 9.136529922485352\n",
      "Epoch5: Discriminator Loss: 0.0018924573669210076, Generator Loss: 5.832889556884766\n",
      "Epoch5: Discriminator Loss: 0.0047181216068565845, Generator Loss: 6.55596399307251\n",
      "Epoch5: Discriminator Loss: 0.08563005924224854, Generator Loss: 7.774092674255371\n",
      "Epoch5: Discriminator Loss: 0.00031879081507213414, Generator Loss: 7.69096040725708\n",
      "Epoch5: Discriminator Loss: 6.611310527659953e-05, Generator Loss: 9.48908805847168\n",
      "Epoch5: Discriminator Loss: 4.226073360769078e-05, Generator Loss: 9.131831169128418\n",
      "Epoch5: Discriminator Loss: 0.0001586028083693236, Generator Loss: 8.069245338439941\n",
      "Epoch5: Discriminator Loss: 0.001054315478540957, Generator Loss: 6.285702705383301\n",
      "Epoch5: Discriminator Loss: 0.014838744886219501, Generator Loss: 8.893428802490234\n",
      "Epoch5: Discriminator Loss: 0.0016090082935988903, Generator Loss: 8.391806602478027\n",
      "Epoch5: Discriminator Loss: 0.0006092829280532897, Generator Loss: 6.723428726196289\n",
      "Epoch5: Discriminator Loss: 0.0026022233068943024, Generator Loss: 4.761127948760986\n",
      "Epoch5: Discriminator Loss: 0.007404010742902756, Generator Loss: 7.485742568969727\n",
      "Epoch5: Discriminator Loss: 0.007641531527042389, Generator Loss: 10.675289154052734\n",
      "Epoch5: Discriminator Loss: 0.005938365124166012, Generator Loss: 7.194056510925293\n",
      "Epoch5: Discriminator Loss: 0.011022975668311119, Generator Loss: 4.34333610534668\n",
      "Epoch5: Discriminator Loss: 0.041309937834739685, Generator Loss: 7.891733646392822\n",
      "Epoch5: Discriminator Loss: 0.022002555429935455, Generator Loss: 4.323943138122559\n",
      "Epoch5: Discriminator Loss: 0.011305665597319603, Generator Loss: 5.461071968078613\n",
      "Epoch5: Discriminator Loss: 0.008262666873633862, Generator Loss: 5.917273044586182\n",
      "Epoch5: Discriminator Loss: 0.004925054498016834, Generator Loss: 5.723959445953369\n",
      "Epoch5: Discriminator Loss: 0.0032867216505110264, Generator Loss: 5.3457465171813965\n",
      "Epoch5: Discriminator Loss: 5.739953485317528e-05, Generator Loss: 7.625382423400879\n",
      "Epoch5: Discriminator Loss: 0.04278670623898506, Generator Loss: 6.40863561630249\n",
      "Epoch5: Discriminator Loss: 0.0013113359455019236, Generator Loss: 6.009429931640625\n",
      "Epoch5: Discriminator Loss: 0.007623032201081514, Generator Loss: 5.398984909057617\n",
      "Epoch5: Discriminator Loss: 0.0004041241481900215, Generator Loss: 6.947699069976807\n",
      "Epoch5: Discriminator Loss: 0.0010997075587511063, Generator Loss: 4.066429138183594\n",
      "Epoch5: Discriminator Loss: 0.008523033000528812, Generator Loss: 6.989038467407227\n",
      "Epoch5: Discriminator Loss: 0.0020693079568445683, Generator Loss: 5.990039348602295\n",
      "Epoch5: Discriminator Loss: 0.04612211883068085, Generator Loss: 4.40031099319458\n",
      "Epoch5: Discriminator Loss: 0.0008932403870858252, Generator Loss: 5.361618518829346\n",
      "Epoch5: Discriminator Loss: 0.01621708832681179, Generator Loss: 3.728649377822876\n",
      "Epoch5: Discriminator Loss: 0.0003202448133379221, Generator Loss: 6.546761512756348\n",
      "Epoch5: Discriminator Loss: 0.0025614136829972267, Generator Loss: 5.055009365081787\n",
      "Epoch5: Discriminator Loss: 0.0011694435961544514, Generator Loss: 7.083484649658203\n",
      "Epoch5: Discriminator Loss: 0.014982552267611027, Generator Loss: 9.455818176269531\n",
      "Epoch5: Discriminator Loss: 0.00358073809184134, Generator Loss: 3.5043463706970215\n",
      "Epoch5: Discriminator Loss: 0.0012745450949296355, Generator Loss: 5.88737154006958\n",
      "Epoch5: Discriminator Loss: 0.001695913844741881, Generator Loss: 4.8588104248046875\n",
      "Epoch5: Discriminator Loss: 0.0008778724004514515, Generator Loss: 6.525163173675537\n",
      "Epoch5: Discriminator Loss: 0.0038793517742305994, Generator Loss: 6.216947555541992\n",
      "Epoch5: Discriminator Loss: 0.0017208494246006012, Generator Loss: 6.823473930358887\n",
      "Epoch5: Discriminator Loss: 0.00029432441806420684, Generator Loss: 7.644621849060059\n",
      "Epoch5: Discriminator Loss: 0.0028469706885516644, Generator Loss: 7.914386749267578\n",
      "Epoch5: Discriminator Loss: 0.014474419876933098, Generator Loss: 6.9045729637146\n",
      "Epoch5: Discriminator Loss: 0.0017980432603508234, Generator Loss: 5.241502285003662\n",
      "Epoch5: Discriminator Loss: 0.00038506992859765887, Generator Loss: 7.8914103507995605\n",
      "Epoch5: Discriminator Loss: 0.0007948990678414702, Generator Loss: 7.576838970184326\n",
      "Epoch5: Discriminator Loss: 0.0016529407585039735, Generator Loss: 8.598390579223633\n",
      "Epoch5: Discriminator Loss: 0.008472241461277008, Generator Loss: 7.325313568115234\n",
      "Epoch5: Discriminator Loss: 0.03619714081287384, Generator Loss: 2.9873604774475098\n",
      "Epoch5: Discriminator Loss: 0.0001817804732127115, Generator Loss: 7.511012077331543\n",
      "Epoch5: Discriminator Loss: 0.055413953959941864, Generator Loss: 5.853241443634033\n",
      "Epoch5: Discriminator Loss: 0.022443681955337524, Generator Loss: 4.16438627243042\n",
      "Epoch5: Discriminator Loss: 0.00018533976981416345, Generator Loss: 8.26248550415039\n",
      "Epoch5: Discriminator Loss: 0.0009304482373408973, Generator Loss: 5.288195610046387\n",
      "Epoch5: Discriminator Loss: 0.0016034813597798347, Generator Loss: 4.660619735717773\n",
      "Epoch5: Discriminator Loss: 0.0440155491232872, Generator Loss: 5.0590386390686035\n",
      "Epoch5: Discriminator Loss: 0.010644577443599701, Generator Loss: 4.421630859375\n",
      "Epoch5: Discriminator Loss: 0.019268231466412544, Generator Loss: 4.162323474884033\n",
      "Epoch5: Discriminator Loss: 0.02592596784234047, Generator Loss: 5.575567245483398\n",
      "Epoch5: Discriminator Loss: 0.0037239680532366037, Generator Loss: 3.9044387340545654\n",
      "Epoch5: Discriminator Loss: 0.005237169098109007, Generator Loss: 4.7615861892700195\n",
      "Epoch5: Discriminator Loss: 0.04573957994580269, Generator Loss: 3.105795383453369\n",
      "Epoch5: Discriminator Loss: 0.000855089514516294, Generator Loss: 5.113308429718018\n",
      "Epoch5: Discriminator Loss: 0.18574011325836182, Generator Loss: 2.7104623317718506\n",
      "Epoch5: Discriminator Loss: 0.010306451469659805, Generator Loss: 4.811845779418945\n",
      "Epoch5: Discriminator Loss: 0.007895678281784058, Generator Loss: 2.862326145172119\n",
      "Epoch5: Discriminator Loss: 0.0001513976021669805, Generator Loss: 8.589731216430664\n",
      "Epoch5: Discriminator Loss: 0.00021335139172151685, Generator Loss: 8.126094818115234\n",
      "Epoch5: Discriminator Loss: 0.006358519662171602, Generator Loss: 8.778266906738281\n",
      "Epoch5: Discriminator Loss: 0.0005190832307562232, Generator Loss: 7.814843654632568\n",
      "Epoch5: Discriminator Loss: 3.7336332752602175e-05, Generator Loss: 9.70446491241455\n",
      "Epoch5: Discriminator Loss: 0.06222054734826088, Generator Loss: 9.214020729064941\n",
      "Epoch5: Discriminator Loss: 0.0002068316243821755, Generator Loss: 8.62656307220459\n",
      "Epoch5: Discriminator Loss: 0.09079662710428238, Generator Loss: 8.248847961425781\n",
      "Epoch5: Discriminator Loss: 0.0001647599710850045, Generator Loss: 8.487587928771973\n",
      "Epoch5: Discriminator Loss: 0.11744601279497147, Generator Loss: 11.538261413574219\n",
      "Epoch5: Discriminator Loss: 0.0004689173656515777, Generator Loss: 10.543415069580078\n",
      "Epoch5: Discriminator Loss: 0.002940184436738491, Generator Loss: 9.029228210449219\n",
      "Epoch5: Discriminator Loss: 0.09100468456745148, Generator Loss: 10.031808853149414\n",
      "Epoch5: Discriminator Loss: 0.13847871124744415, Generator Loss: 8.7893705368042\n",
      "Epoch5: Discriminator Loss: 7.82745482865721e-05, Generator Loss: 9.969968795776367\n",
      "Epoch5: Discriminator Loss: 7.429506513290107e-05, Generator Loss: 10.025444984436035\n",
      "Epoch5: Discriminator Loss: 0.0004066531255375594, Generator Loss: 10.150350570678711\n",
      "Epoch5: Discriminator Loss: 0.03776264935731888, Generator Loss: 10.02079963684082\n",
      "Epoch5: Discriminator Loss: 0.08941911906003952, Generator Loss: 8.610517501831055\n",
      "Epoch5: Discriminator Loss: 0.00026691320817917585, Generator Loss: 8.11706256866455\n",
      "Epoch5: Discriminator Loss: 0.01680096425116062, Generator Loss: 10.30907154083252\n",
      "Epoch5: Discriminator Loss: 0.01162854116410017, Generator Loss: 7.830974102020264\n",
      "Epoch5: Discriminator Loss: 0.10405172407627106, Generator Loss: 8.324056625366211\n",
      "Epoch5: Discriminator Loss: 7.39338283892721e-05, Generator Loss: 7.920882225036621\n",
      "Epoch5: Discriminator Loss: 0.0003517870791256428, Generator Loss: 7.399290084838867\n",
      "Epoch5: Discriminator Loss: 0.0007917166221886873, Generator Loss: 6.928508281707764\n",
      "Epoch5: Discriminator Loss: 0.00012187541869934648, Generator Loss: 8.440293312072754\n",
      "Epoch5: Discriminator Loss: 0.002958081429824233, Generator Loss: 6.538113117218018\n",
      "Epoch5: Discriminator Loss: 0.00043635902693495154, Generator Loss: 6.111188888549805\n",
      "Epoch5: Discriminator Loss: 0.0008163921302184463, Generator Loss: 7.164272308349609\n",
      "Epoch5: Discriminator Loss: 0.15685905516147614, Generator Loss: 2.2142767906188965\n",
      "Epoch5: Discriminator Loss: 0.0046171024441719055, Generator Loss: 5.484493732452393\n",
      "Epoch5: Discriminator Loss: 0.009131034836173058, Generator Loss: 4.382843494415283\n",
      "Epoch5: Discriminator Loss: 0.0016505582025274634, Generator Loss: 5.558437824249268\n",
      "Epoch5: Discriminator Loss: 0.0006737548974342644, Generator Loss: 6.833848476409912\n",
      "Epoch5: Discriminator Loss: 0.017710883170366287, Generator Loss: 8.8606595993042\n",
      "Epoch5: Discriminator Loss: 0.0005495997029356658, Generator Loss: 7.05875825881958\n",
      "Epoch5: Discriminator Loss: 0.0003660324728116393, Generator Loss: 9.034969329833984\n",
      "Epoch5: Discriminator Loss: 0.030718892812728882, Generator Loss: 6.788204193115234\n",
      "Epoch5: Discriminator Loss: 0.002445544581860304, Generator Loss: 7.251721382141113\n",
      "Epoch5: Discriminator Loss: 0.0007028075633570552, Generator Loss: 7.693967342376709\n",
      "Epoch5: Discriminator Loss: 0.00455580186098814, Generator Loss: 7.69455623626709\n",
      "Epoch5: Discriminator Loss: 0.00025654654018580914, Generator Loss: 7.674363136291504\n",
      "Epoch5: Discriminator Loss: 0.03556405007839203, Generator Loss: 6.956176280975342\n",
      "Epoch5: Discriminator Loss: 0.035068999975919724, Generator Loss: 6.329671859741211\n",
      "Epoch5: Discriminator Loss: 0.003950783517211676, Generator Loss: 5.253458499908447\n",
      "Epoch5: Discriminator Loss: 0.034770749509334564, Generator Loss: 3.558448553085327\n",
      "Epoch5: Discriminator Loss: 0.006479330360889435, Generator Loss: 6.143152713775635\n",
      "Epoch5: Discriminator Loss: 0.00046010888763703406, Generator Loss: 7.516941070556641\n",
      "Epoch5: Discriminator Loss: 0.0010752677917480469, Generator Loss: 6.253674030303955\n",
      "Epoch5: Discriminator Loss: 0.0007714171661064029, Generator Loss: 6.490274906158447\n",
      "Epoch5: Discriminator Loss: 0.0002809333091136068, Generator Loss: 6.7077860832214355\n",
      "Epoch5: Discriminator Loss: 0.0022292642388492823, Generator Loss: 5.5527024269104\n",
      "Epoch5: Discriminator Loss: 0.00026534273638390005, Generator Loss: 7.681661128997803\n",
      "Epoch5: Discriminator Loss: 0.006805251352488995, Generator Loss: 3.2077605724334717\n",
      "Epoch5: Discriminator Loss: 0.0011869458248838782, Generator Loss: 5.759434700012207\n",
      "Epoch5: Discriminator Loss: 0.0077213202603161335, Generator Loss: 8.005012512207031\n",
      "Epoch6: Discriminator Loss: 0.0001766575442161411, Generator Loss: 8.366508483886719\n",
      "Epoch6: Discriminator Loss: 0.0008771992870606482, Generator Loss: 6.699666976928711\n",
      "Epoch6: Discriminator Loss: 0.0019372084643691778, Generator Loss: 5.504771709442139\n",
      "Epoch6: Discriminator Loss: 0.002825419418513775, Generator Loss: 3.3479859828948975\n",
      "Epoch6: Discriminator Loss: 0.0009106993675231934, Generator Loss: 5.400152206420898\n",
      "Epoch6: Discriminator Loss: 0.0009880830766633153, Generator Loss: 6.270522594451904\n",
      "Epoch6: Discriminator Loss: 0.0011220192536711693, Generator Loss: 6.3642706871032715\n",
      "Epoch6: Discriminator Loss: 0.009039928205311298, Generator Loss: 4.106115818023682\n",
      "Epoch6: Discriminator Loss: 0.001863921177573502, Generator Loss: 2.187664031982422\n",
      "Epoch6: Discriminator Loss: 0.006399637088179588, Generator Loss: 4.6186203956604\n",
      "Epoch6: Discriminator Loss: 0.0004257019027136266, Generator Loss: 6.507833957672119\n",
      "Epoch6: Discriminator Loss: 0.0038156122900545597, Generator Loss: 2.885880708694458\n",
      "Epoch6: Discriminator Loss: 0.004409827757626772, Generator Loss: 5.075942039489746\n",
      "Epoch6: Discriminator Loss: 0.015109650790691376, Generator Loss: 5.822845935821533\n",
      "Epoch6: Discriminator Loss: 0.0031383922323584557, Generator Loss: 7.038150787353516\n",
      "Epoch6: Discriminator Loss: 0.002050701528787613, Generator Loss: 6.538664817810059\n",
      "Epoch6: Discriminator Loss: 0.0010368924122303724, Generator Loss: 4.949042320251465\n",
      "Epoch6: Discriminator Loss: 0.00032599325641058385, Generator Loss: 6.683888912200928\n",
      "Epoch6: Discriminator Loss: 0.0061279525980353355, Generator Loss: 4.156478404998779\n",
      "Epoch6: Discriminator Loss: 0.0042834109626710415, Generator Loss: 5.724929332733154\n",
      "Epoch6: Discriminator Loss: 0.0005329925916157663, Generator Loss: 7.530176639556885\n",
      "Epoch6: Discriminator Loss: 0.0006662302766926587, Generator Loss: 7.390314102172852\n",
      "Epoch6: Discriminator Loss: 0.0014040912501513958, Generator Loss: 6.68914794921875\n",
      "Epoch6: Discriminator Loss: 0.00043886477942578495, Generator Loss: 6.710875988006592\n",
      "Epoch6: Discriminator Loss: 0.0003510298556648195, Generator Loss: 6.948556900024414\n",
      "Epoch6: Discriminator Loss: 0.000272443110588938, Generator Loss: 6.9382781982421875\n",
      "Epoch6: Discriminator Loss: 0.007946268655359745, Generator Loss: 6.125324249267578\n",
      "Epoch6: Discriminator Loss: 0.00013306700566317886, Generator Loss: 7.834548473358154\n",
      "Epoch6: Discriminator Loss: 0.08541952818632126, Generator Loss: 6.856833457946777\n",
      "Epoch6: Discriminator Loss: 0.0006493160035461187, Generator Loss: 6.7171711921691895\n",
      "Epoch6: Discriminator Loss: 0.00022536233882419765, Generator Loss: 6.585949897766113\n",
      "Epoch6: Discriminator Loss: 0.1285012811422348, Generator Loss: 8.861026763916016\n",
      "Epoch6: Discriminator Loss: 0.0014918121742084622, Generator Loss: 6.2835187911987305\n",
      "Epoch6: Discriminator Loss: 0.001907947938889265, Generator Loss: 7.122411251068115\n",
      "Epoch6: Discriminator Loss: 0.001032443018630147, Generator Loss: 8.035036087036133\n",
      "Epoch6: Discriminator Loss: 0.002768511651083827, Generator Loss: 4.043680191040039\n",
      "Epoch6: Discriminator Loss: 0.0013706767931580544, Generator Loss: 3.4314560890197754\n",
      "Epoch6: Discriminator Loss: 0.01156589575111866, Generator Loss: 5.638237476348877\n",
      "Epoch6: Discriminator Loss: 0.01898740418255329, Generator Loss: 5.548663139343262\n",
      "Epoch6: Discriminator Loss: 0.021504636853933334, Generator Loss: 6.369665622711182\n",
      "Epoch6: Discriminator Loss: 0.000849487551022321, Generator Loss: 6.656350135803223\n",
      "Epoch6: Discriminator Loss: 0.0005690680118277669, Generator Loss: 7.1866960525512695\n",
      "Epoch6: Discriminator Loss: 0.001034319051541388, Generator Loss: 7.596418380737305\n",
      "Epoch6: Discriminator Loss: 0.00043895957060158253, Generator Loss: 9.491965293884277\n",
      "Epoch6: Discriminator Loss: 0.003191788913682103, Generator Loss: 4.491933822631836\n",
      "Epoch6: Discriminator Loss: 0.0012415413511916995, Generator Loss: 4.009743690490723\n",
      "Epoch6: Discriminator Loss: 0.0006133037386462092, Generator Loss: 6.209055423736572\n",
      "Epoch6: Discriminator Loss: 0.0008378319907933474, Generator Loss: 6.707691669464111\n",
      "Epoch6: Discriminator Loss: 0.00018611601262819022, Generator Loss: 7.885721206665039\n",
      "Epoch6: Discriminator Loss: 0.0035400453489273787, Generator Loss: 8.483351707458496\n",
      "Epoch6: Discriminator Loss: 0.0025047664530575275, Generator Loss: 5.802232265472412\n",
      "Epoch6: Discriminator Loss: 0.000263227237155661, Generator Loss: 7.897379398345947\n",
      "Epoch6: Discriminator Loss: 0.003127902280539274, Generator Loss: 5.74036169052124\n",
      "Epoch6: Discriminator Loss: 0.005239573307335377, Generator Loss: 5.610751152038574\n",
      "Epoch6: Discriminator Loss: 0.04011547565460205, Generator Loss: 5.126033782958984\n",
      "Epoch6: Discriminator Loss: 0.05884044989943504, Generator Loss: 6.557519435882568\n",
      "Epoch6: Discriminator Loss: 0.0035489615984261036, Generator Loss: 6.1298956871032715\n",
      "Epoch6: Discriminator Loss: 0.006200144067406654, Generator Loss: 4.78347110748291\n",
      "Epoch6: Discriminator Loss: 0.004808085970580578, Generator Loss: 6.622913837432861\n",
      "Epoch6: Discriminator Loss: 0.0009133685380220413, Generator Loss: 5.855218410491943\n",
      "Epoch6: Discriminator Loss: 0.0003412316436879337, Generator Loss: 7.779855251312256\n",
      "Epoch6: Discriminator Loss: 0.011724450625479221, Generator Loss: 5.912759780883789\n",
      "Epoch6: Discriminator Loss: 0.004298674874007702, Generator Loss: 2.658033609390259\n",
      "Epoch6: Discriminator Loss: 0.002803805284202099, Generator Loss: 6.79845666885376\n",
      "Epoch6: Discriminator Loss: 0.007372507359832525, Generator Loss: 4.889291286468506\n",
      "Epoch6: Discriminator Loss: 0.0018336151260882616, Generator Loss: 3.3992042541503906\n",
      "Epoch6: Discriminator Loss: 0.0001935418404173106, Generator Loss: 8.228490829467773\n",
      "Epoch6: Discriminator Loss: 0.011314131319522858, Generator Loss: 6.652211666107178\n",
      "Epoch6: Discriminator Loss: 0.015925690531730652, Generator Loss: 4.167626857757568\n",
      "Epoch6: Discriminator Loss: 0.005249117501080036, Generator Loss: 4.841249465942383\n",
      "Epoch6: Discriminator Loss: 0.003839230863377452, Generator Loss: 5.6115593910217285\n",
      "Epoch6: Discriminator Loss: 0.03305776044726372, Generator Loss: 6.386552333831787\n",
      "Epoch6: Discriminator Loss: 0.002005982445552945, Generator Loss: 6.365109920501709\n",
      "Epoch6: Discriminator Loss: 0.00129815808031708, Generator Loss: 5.587646007537842\n",
      "Epoch6: Discriminator Loss: 0.0032794997096061707, Generator Loss: 8.713335037231445\n",
      "Epoch6: Discriminator Loss: 0.008588653989136219, Generator Loss: 4.713165760040283\n",
      "Epoch6: Discriminator Loss: 0.003287920029833913, Generator Loss: 4.393791198730469\n",
      "Epoch6: Discriminator Loss: 0.017318112775683403, Generator Loss: 3.3157851696014404\n",
      "Epoch6: Discriminator Loss: 0.00020675202540587634, Generator Loss: 7.639057636260986\n",
      "Epoch6: Discriminator Loss: 0.036959268152713776, Generator Loss: 5.760611057281494\n",
      "Epoch6: Discriminator Loss: 0.004364626482129097, Generator Loss: 4.259286880493164\n",
      "Epoch6: Discriminator Loss: 0.0036351182498037815, Generator Loss: 6.872469902038574\n",
      "Epoch6: Discriminator Loss: 0.0004046944377478212, Generator Loss: 6.956302165985107\n",
      "Epoch6: Discriminator Loss: 0.07818550616502762, Generator Loss: 6.38037109375\n",
      "Epoch6: Discriminator Loss: 0.018593164160847664, Generator Loss: 5.792668342590332\n",
      "Epoch6: Discriminator Loss: 0.007109169848263264, Generator Loss: 6.847427845001221\n",
      "Epoch6: Discriminator Loss: 0.033380936831235886, Generator Loss: 9.22118091583252\n",
      "Epoch6: Discriminator Loss: 0.001478663645684719, Generator Loss: 7.034622669219971\n",
      "Epoch6: Discriminator Loss: 0.0006457782001234591, Generator Loss: 6.8571977615356445\n",
      "Epoch6: Discriminator Loss: 0.00432988116517663, Generator Loss: 6.15645694732666\n",
      "Epoch6: Discriminator Loss: 0.0002444823912810534, Generator Loss: 6.927380084991455\n",
      "Epoch6: Discriminator Loss: 0.0005121286958456039, Generator Loss: 5.411818504333496\n",
      "Epoch6: Discriminator Loss: 0.02922702208161354, Generator Loss: 5.604612827301025\n",
      "Epoch6: Discriminator Loss: 0.0006476958515122533, Generator Loss: 6.092536926269531\n",
      "Epoch6: Discriminator Loss: 0.0008790298015810549, Generator Loss: 8.496970176696777\n",
      "Epoch6: Discriminator Loss: 0.06255867332220078, Generator Loss: 7.707417011260986\n",
      "Epoch6: Discriminator Loss: 0.0006581696798093617, Generator Loss: 7.198118209838867\n",
      "Epoch6: Discriminator Loss: 0.0025698428507894278, Generator Loss: 5.308573246002197\n",
      "Epoch6: Discriminator Loss: 0.0059528895653784275, Generator Loss: 6.346404552459717\n",
      "Epoch6: Discriminator Loss: 0.0015942431055009365, Generator Loss: 6.61907958984375\n",
      "Epoch6: Discriminator Loss: 0.02140752412378788, Generator Loss: 6.250337600708008\n",
      "Epoch6: Discriminator Loss: 0.0014794467715546489, Generator Loss: 5.136288166046143\n",
      "Epoch6: Discriminator Loss: 0.0017954905051738024, Generator Loss: 5.449314117431641\n",
      "Epoch6: Discriminator Loss: 0.004187446553260088, Generator Loss: 4.077643871307373\n",
      "Epoch6: Discriminator Loss: 0.0006721775280311704, Generator Loss: 6.463301181793213\n",
      "Epoch6: Discriminator Loss: 0.03622595593333244, Generator Loss: 5.1997175216674805\n",
      "Epoch6: Discriminator Loss: 0.0005107094766572118, Generator Loss: 6.683567523956299\n",
      "Epoch6: Discriminator Loss: 0.0005258258897811174, Generator Loss: 6.092724800109863\n",
      "Epoch6: Discriminator Loss: 0.0054308753460645676, Generator Loss: 3.8084864616394043\n",
      "Epoch6: Discriminator Loss: 0.0001318728900514543, Generator Loss: 9.814264297485352\n",
      "Epoch6: Discriminator Loss: 0.10840208828449249, Generator Loss: 4.379467964172363\n",
      "Epoch6: Discriminator Loss: 0.001804010127671063, Generator Loss: 4.867398262023926\n",
      "Epoch6: Discriminator Loss: 0.09174435585737228, Generator Loss: 7.333878993988037\n",
      "Epoch6: Discriminator Loss: 0.010437672957777977, Generator Loss: 7.101200103759766\n",
      "Epoch6: Discriminator Loss: 0.015438194386661053, Generator Loss: 7.042426586151123\n",
      "Epoch6: Discriminator Loss: 0.008972352370619774, Generator Loss: 7.546823978424072\n",
      "Epoch6: Discriminator Loss: 0.01249948050826788, Generator Loss: 8.020394325256348\n",
      "Epoch6: Discriminator Loss: 0.08393844217061996, Generator Loss: 10.016907691955566\n",
      "Epoch6: Discriminator Loss: 0.049260154366493225, Generator Loss: 8.02413272857666\n",
      "Epoch6: Discriminator Loss: 2.0699088054243475e-05, Generator Loss: 9.438819885253906\n",
      "Epoch6: Discriminator Loss: 0.05557507649064064, Generator Loss: 7.929058074951172\n",
      "Epoch6: Discriminator Loss: 0.00011175124382134527, Generator Loss: 9.541723251342773\n",
      "Epoch6: Discriminator Loss: 4.873851503361948e-05, Generator Loss: 8.555249214172363\n",
      "Epoch6: Discriminator Loss: 0.00012407777830958366, Generator Loss: 9.234315872192383\n",
      "Epoch6: Discriminator Loss: 0.00037052767584100366, Generator Loss: 7.850524425506592\n",
      "Epoch6: Discriminator Loss: 0.19009941816329956, Generator Loss: 8.475442886352539\n",
      "Epoch6: Discriminator Loss: 0.00030272372532635927, Generator Loss: 6.270369052886963\n",
      "Epoch6: Discriminator Loss: 0.06968410313129425, Generator Loss: 7.814495086669922\n",
      "Epoch6: Discriminator Loss: 0.08062544465065002, Generator Loss: 7.580789566040039\n",
      "Epoch6: Discriminator Loss: 0.0006295221974141896, Generator Loss: 7.2978034019470215\n",
      "Epoch6: Discriminator Loss: 0.0011130014900118113, Generator Loss: 7.966571807861328\n",
      "Epoch6: Discriminator Loss: 0.012449304573237896, Generator Loss: 8.736288070678711\n",
      "Epoch6: Discriminator Loss: 0.0001264894672203809, Generator Loss: 8.154342651367188\n",
      "Epoch6: Discriminator Loss: 0.0467698872089386, Generator Loss: 8.133625030517578\n",
      "Epoch6: Discriminator Loss: 0.006263093091547489, Generator Loss: 3.239069700241089\n",
      "Epoch6: Discriminator Loss: 0.0006543985218741, Generator Loss: 6.287785053253174\n",
      "Epoch6: Discriminator Loss: 0.0007136375643312931, Generator Loss: 6.058818817138672\n",
      "Epoch6: Discriminator Loss: 0.004276502877473831, Generator Loss: 6.36358642578125\n",
      "Epoch6: Discriminator Loss: 0.039697665721178055, Generator Loss: 6.19423770904541\n",
      "Epoch6: Discriminator Loss: 0.00046648026909679174, Generator Loss: 6.874561309814453\n",
      "Epoch6: Discriminator Loss: 0.000862524495460093, Generator Loss: 7.037642478942871\n",
      "Epoch6: Discriminator Loss: 0.0030974873807281256, Generator Loss: 4.984669208526611\n",
      "Epoch6: Discriminator Loss: 0.001218093209899962, Generator Loss: 4.291296482086182\n",
      "Epoch6: Discriminator Loss: 0.003555419621989131, Generator Loss: 4.565613269805908\n",
      "Epoch6: Discriminator Loss: 0.0026171975769102573, Generator Loss: 7.046391010284424\n",
      "Epoch6: Discriminator Loss: 0.005053863860666752, Generator Loss: 5.394748210906982\n",
      "Epoch6: Discriminator Loss: 0.015394057147204876, Generator Loss: 6.290620803833008\n",
      "Epoch6: Discriminator Loss: 0.012288511730730534, Generator Loss: 0.4505138099193573\n",
      "Epoch6: Discriminator Loss: 0.0002913136559072882, Generator Loss: 6.85606575012207\n",
      "Epoch6: Discriminator Loss: 0.0002458610979374498, Generator Loss: 5.202186107635498\n",
      "Epoch6: Discriminator Loss: 0.022189829498529434, Generator Loss: 3.5727789402008057\n",
      "Epoch6: Discriminator Loss: 0.0004467168473638594, Generator Loss: 8.338202476501465\n",
      "Epoch6: Discriminator Loss: 0.003963611554354429, Generator Loss: 6.496048450469971\n",
      "Epoch6: Discriminator Loss: 0.07186594605445862, Generator Loss: 6.744755268096924\n",
      "Epoch6: Discriminator Loss: 0.0004080856451764703, Generator Loss: 5.562347888946533\n",
      "Epoch6: Discriminator Loss: 0.0007064882665872574, Generator Loss: 6.7967448234558105\n",
      "Epoch6: Discriminator Loss: 0.0817333236336708, Generator Loss: 5.781432628631592\n",
      "Epoch6: Discriminator Loss: 0.0002701852354221046, Generator Loss: 8.10542106628418\n",
      "Epoch6: Discriminator Loss: 0.0009839488193392754, Generator Loss: 6.600969314575195\n",
      "Epoch6: Discriminator Loss: 0.0007080622599460185, Generator Loss: 5.993089199066162\n",
      "Epoch6: Discriminator Loss: 0.036360278725624084, Generator Loss: 7.363705158233643\n",
      "Epoch6: Discriminator Loss: 0.00039240712067112327, Generator Loss: 8.873353004455566\n",
      "Epoch6: Discriminator Loss: 0.00018932600505650043, Generator Loss: 8.77318000793457\n",
      "Epoch6: Discriminator Loss: 0.0006695648771710694, Generator Loss: 7.116054534912109\n",
      "Epoch6: Discriminator Loss: 0.00141543906647712, Generator Loss: 5.438307762145996\n",
      "Epoch6: Discriminator Loss: 0.008068072609603405, Generator Loss: 5.607068061828613\n",
      "Epoch6: Discriminator Loss: 0.00041501049418002367, Generator Loss: 5.824562072753906\n",
      "Epoch6: Discriminator Loss: 0.011011439375579357, Generator Loss: 5.815238952636719\n",
      "Epoch6: Discriminator Loss: 0.0005215386627241969, Generator Loss: 5.93693733215332\n",
      "Epoch6: Discriminator Loss: 0.001258104806765914, Generator Loss: 6.9612908363342285\n",
      "Epoch6: Discriminator Loss: 0.011827356182038784, Generator Loss: 5.598996162414551\n",
      "Epoch6: Discriminator Loss: 0.00018804681894835085, Generator Loss: 5.756675720214844\n",
      "Epoch6: Discriminator Loss: 0.01153349969536066, Generator Loss: 9.182607650756836\n",
      "Epoch6: Discriminator Loss: 0.0009843134321272373, Generator Loss: 7.78864049911499\n",
      "Epoch6: Discriminator Loss: 0.0007848158129490912, Generator Loss: 7.047306537628174\n",
      "Epoch6: Discriminator Loss: 0.00038186722667887807, Generator Loss: 4.668408393859863\n",
      "Epoch7: Discriminator Loss: 0.020365402102470398, Generator Loss: 4.303526878356934\n",
      "Epoch7: Discriminator Loss: 0.0013972688466310501, Generator Loss: 5.778806686401367\n",
      "Epoch7: Discriminator Loss: 0.0007708683260716498, Generator Loss: 5.463270664215088\n",
      "Epoch7: Discriminator Loss: 0.002072364091873169, Generator Loss: 5.338312149047852\n",
      "Epoch7: Discriminator Loss: 0.002064417814835906, Generator Loss: 6.732576847076416\n",
      "Epoch7: Discriminator Loss: 0.026433074846863747, Generator Loss: 3.9397971630096436\n",
      "Epoch7: Discriminator Loss: 0.0002695934090297669, Generator Loss: 8.47860336303711\n",
      "Epoch7: Discriminator Loss: 0.003810825292021036, Generator Loss: 5.06447696685791\n",
      "Epoch7: Discriminator Loss: 0.01282077468931675, Generator Loss: 4.76359224319458\n",
      "Epoch7: Discriminator Loss: 0.0004538814537227154, Generator Loss: 7.750677108764648\n",
      "Epoch7: Discriminator Loss: 0.0003223810053896159, Generator Loss: 8.236287117004395\n",
      "Epoch7: Discriminator Loss: 0.00138576771132648, Generator Loss: 5.822793483734131\n",
      "Epoch7: Discriminator Loss: 0.00013910849520470947, Generator Loss: 9.31259536743164\n",
      "Epoch7: Discriminator Loss: 0.00018059321155305952, Generator Loss: 6.484687328338623\n",
      "Epoch7: Discriminator Loss: 0.0035546058788895607, Generator Loss: 2.8475935459136963\n",
      "Epoch7: Discriminator Loss: 0.0781431645154953, Generator Loss: 7.448770523071289\n",
      "Epoch7: Discriminator Loss: 0.006299023982137442, Generator Loss: 8.57127857208252\n",
      "Epoch7: Discriminator Loss: 0.00020011101150885224, Generator Loss: 6.248391151428223\n",
      "Epoch7: Discriminator Loss: 0.0010365137131884694, Generator Loss: 7.813930034637451\n",
      "Epoch7: Discriminator Loss: 0.0020247972570359707, Generator Loss: 5.719070911407471\n",
      "Epoch7: Discriminator Loss: 0.0314728282392025, Generator Loss: 7.831546306610107\n",
      "Epoch7: Discriminator Loss: 9.688809223007411e-05, Generator Loss: 10.195512771606445\n",
      "Epoch7: Discriminator Loss: 0.00010705171007430181, Generator Loss: 10.597208976745605\n",
      "Epoch7: Discriminator Loss: 0.000991792418062687, Generator Loss: 4.429443359375\n",
      "Epoch7: Discriminator Loss: 5.7937493693316355e-05, Generator Loss: 7.913301467895508\n",
      "Epoch7: Discriminator Loss: 0.0804302990436554, Generator Loss: 4.541147708892822\n",
      "Epoch7: Discriminator Loss: 0.0002494034997653216, Generator Loss: 7.7838826179504395\n",
      "Epoch7: Discriminator Loss: 0.00042655383003875613, Generator Loss: 5.8893890380859375\n",
      "Epoch7: Discriminator Loss: 0.0002184020122513175, Generator Loss: 8.87419605255127\n",
      "Epoch7: Discriminator Loss: 0.0008886466384865344, Generator Loss: 9.208205223083496\n",
      "Epoch7: Discriminator Loss: 0.006469456013292074, Generator Loss: 6.0975775718688965\n",
      "Epoch7: Discriminator Loss: 0.0013118834467604756, Generator Loss: 5.176516532897949\n",
      "Epoch7: Discriminator Loss: 9.20859383768402e-05, Generator Loss: 9.722745895385742\n",
      "Epoch7: Discriminator Loss: 0.00025515424204058945, Generator Loss: 7.469633102416992\n",
      "Epoch7: Discriminator Loss: 0.0003619820054154843, Generator Loss: 7.025589942932129\n",
      "Epoch7: Discriminator Loss: 0.0012913888785988092, Generator Loss: 6.490694522857666\n",
      "Epoch7: Discriminator Loss: 0.003941690549254417, Generator Loss: 2.7864201068878174\n",
      "Epoch7: Discriminator Loss: 0.0003420257125981152, Generator Loss: 7.5133538246154785\n",
      "Epoch7: Discriminator Loss: 0.00016726061585359275, Generator Loss: 8.17025089263916\n",
      "Epoch7: Discriminator Loss: 6.281907553784549e-05, Generator Loss: 8.141702651977539\n",
      "Epoch7: Discriminator Loss: 0.013102162629365921, Generator Loss: 9.121817588806152\n",
      "Epoch7: Discriminator Loss: 0.09805265069007874, Generator Loss: 9.653087615966797\n",
      "Epoch7: Discriminator Loss: 0.01485950592905283, Generator Loss: 7.252551078796387\n",
      "Epoch7: Discriminator Loss: 0.00020609074272215366, Generator Loss: 9.002713203430176\n",
      "Epoch7: Discriminator Loss: 0.0002361409569857642, Generator Loss: 7.95427131652832\n",
      "Epoch7: Discriminator Loss: 0.007059963420033455, Generator Loss: 5.238386154174805\n",
      "Epoch7: Discriminator Loss: 0.008457424119114876, Generator Loss: 9.451895713806152\n",
      "Epoch7: Discriminator Loss: 0.0017423382960259914, Generator Loss: 7.406452655792236\n",
      "Epoch7: Discriminator Loss: 0.0004982910468243062, Generator Loss: 6.60839319229126\n",
      "Epoch7: Discriminator Loss: 0.004226849414408207, Generator Loss: 3.810229539871216\n",
      "Epoch7: Discriminator Loss: 0.03638894483447075, Generator Loss: 4.6577959060668945\n",
      "Epoch7: Discriminator Loss: 0.0024368353188037872, Generator Loss: 5.17183780670166\n",
      "Epoch7: Discriminator Loss: 0.0008386037079617381, Generator Loss: 7.071446418762207\n",
      "Epoch7: Discriminator Loss: 0.02702232263982296, Generator Loss: 4.9944586753845215\n",
      "Epoch7: Discriminator Loss: 0.06663313508033752, Generator Loss: 2.0165443420410156\n",
      "Epoch7: Discriminator Loss: 0.002432988490909338, Generator Loss: 7.61285924911499\n",
      "Epoch7: Discriminator Loss: 0.02491845190525055, Generator Loss: 4.388429641723633\n",
      "Epoch7: Discriminator Loss: 0.0006155804148875177, Generator Loss: 8.719276428222656\n",
      "Epoch7: Discriminator Loss: 0.04155738651752472, Generator Loss: 3.942843437194824\n",
      "Epoch7: Discriminator Loss: 0.09164700657129288, Generator Loss: 8.1153564453125\n",
      "Epoch7: Discriminator Loss: 0.00014530186308547854, Generator Loss: 8.277193069458008\n",
      "Epoch7: Discriminator Loss: 0.0026119560934603214, Generator Loss: 6.795724868774414\n",
      "Epoch7: Discriminator Loss: 0.0006181338103488088, Generator Loss: 7.822722434997559\n",
      "Epoch7: Discriminator Loss: 0.0003152349090669304, Generator Loss: 7.977621078491211\n",
      "Epoch7: Discriminator Loss: 0.06763362884521484, Generator Loss: 10.960271835327148\n",
      "Epoch7: Discriminator Loss: 0.000573315192013979, Generator Loss: 6.347823143005371\n",
      "Epoch7: Discriminator Loss: 0.00016421217878814787, Generator Loss: 8.0169677734375\n",
      "Epoch7: Discriminator Loss: 3.0257895559770986e-05, Generator Loss: 9.208316802978516\n",
      "Epoch7: Discriminator Loss: 3.794802978518419e-05, Generator Loss: 10.363521575927734\n",
      "Epoch7: Discriminator Loss: 3.0819289804639993e-06, Generator Loss: 12.559431076049805\n",
      "Epoch7: Discriminator Loss: 0.014526834711432457, Generator Loss: 9.896897315979004\n",
      "Epoch7: Discriminator Loss: 8.92416646820493e-05, Generator Loss: 8.205159187316895\n",
      "Epoch7: Discriminator Loss: 2.7800449970527552e-05, Generator Loss: 10.666482925415039\n",
      "Epoch7: Discriminator Loss: 8.723748032934964e-05, Generator Loss: 9.323301315307617\n",
      "Epoch7: Discriminator Loss: 0.1189069077372551, Generator Loss: 8.465001106262207\n",
      "Epoch7: Discriminator Loss: 0.025283560156822205, Generator Loss: 9.157767295837402\n",
      "Epoch7: Discriminator Loss: 0.004596265032887459, Generator Loss: 12.346720695495605\n",
      "Epoch7: Discriminator Loss: 0.0023036932107061148, Generator Loss: 7.641199588775635\n",
      "Epoch7: Discriminator Loss: 0.008364909328520298, Generator Loss: 5.236697196960449\n",
      "Epoch7: Discriminator Loss: 0.001196850324049592, Generator Loss: 8.888141632080078\n",
      "Epoch7: Discriminator Loss: 8.374526078114286e-05, Generator Loss: 8.448966026306152\n",
      "Epoch7: Discriminator Loss: 0.0001907052646856755, Generator Loss: 8.9862699508667\n",
      "Epoch7: Discriminator Loss: 0.08880490809679031, Generator Loss: 8.093488693237305\n",
      "Epoch7: Discriminator Loss: 0.00010222411947324872, Generator Loss: 8.624884605407715\n",
      "Epoch7: Discriminator Loss: 0.0012623355723917484, Generator Loss: 8.526076316833496\n",
      "Epoch7: Discriminator Loss: 0.024033593013882637, Generator Loss: 5.7628326416015625\n",
      "Epoch7: Discriminator Loss: 0.0011619450524449348, Generator Loss: 4.182031154632568\n",
      "Epoch7: Discriminator Loss: 0.0002506662567611784, Generator Loss: 5.812706470489502\n",
      "Epoch7: Discriminator Loss: 0.0003883734461851418, Generator Loss: 7.114739894866943\n",
      "Epoch7: Discriminator Loss: 0.0005891547189094126, Generator Loss: 5.339334964752197\n",
      "Epoch7: Discriminator Loss: 0.007951105944812298, Generator Loss: 3.290201187133789\n",
      "Epoch7: Discriminator Loss: 0.00021475704852491617, Generator Loss: 7.7397966384887695\n",
      "Epoch7: Discriminator Loss: 0.0006088958471082151, Generator Loss: 7.802151679992676\n",
      "Epoch7: Discriminator Loss: 0.002566314535215497, Generator Loss: 4.345271110534668\n",
      "Epoch7: Discriminator Loss: 0.0009648293489590287, Generator Loss: 6.825996398925781\n",
      "Epoch7: Discriminator Loss: 0.1779375821352005, Generator Loss: 0.3791136145591736\n",
      "Epoch7: Discriminator Loss: 4.3813115553348325e-06, Generator Loss: 11.223058700561523\n",
      "Epoch7: Discriminator Loss: 0.01344264391809702, Generator Loss: 6.592367649078369\n",
      "Epoch7: Discriminator Loss: 0.001876695896498859, Generator Loss: 5.931016445159912\n",
      "Epoch7: Discriminator Loss: 0.0001538614887977019, Generator Loss: 9.705116271972656\n",
      "Epoch7: Discriminator Loss: 2.7795218557002954e-05, Generator Loss: 8.75733470916748\n",
      "Epoch7: Discriminator Loss: 0.00015902065206319094, Generator Loss: 10.987650871276855\n",
      "Epoch7: Discriminator Loss: 0.00864967331290245, Generator Loss: 12.607175827026367\n",
      "Epoch7: Discriminator Loss: 0.01453210785984993, Generator Loss: 9.616593360900879\n",
      "Epoch7: Discriminator Loss: 0.051718760281801224, Generator Loss: 11.931563377380371\n",
      "Epoch7: Discriminator Loss: 0.06088077276945114, Generator Loss: 15.101051330566406\n",
      "Epoch7: Discriminator Loss: 3.4089957807736937e-06, Generator Loss: 11.906591415405273\n",
      "Epoch7: Discriminator Loss: 0.03564772009849548, Generator Loss: 10.969999313354492\n",
      "Epoch7: Discriminator Loss: 0.004722511395812035, Generator Loss: 10.612671852111816\n",
      "Epoch7: Discriminator Loss: 0.012759074568748474, Generator Loss: 10.69789981842041\n",
      "Epoch7: Discriminator Loss: 0.00021949682559352368, Generator Loss: 8.749744415283203\n",
      "Epoch7: Discriminator Loss: 0.0002387372951488942, Generator Loss: 11.559370040893555\n",
      "Epoch7: Discriminator Loss: 9.50731828197604e-06, Generator Loss: 9.747766494750977\n",
      "Epoch7: Discriminator Loss: 0.08401267230510712, Generator Loss: 9.219980239868164\n",
      "Epoch7: Discriminator Loss: 8.669712406117469e-05, Generator Loss: 8.565387725830078\n",
      "Epoch7: Discriminator Loss: 0.00010102600208483636, Generator Loss: 10.06612777709961\n",
      "Epoch7: Discriminator Loss: 0.0004093521856702864, Generator Loss: 10.879509925842285\n",
      "Epoch7: Discriminator Loss: 0.022617731243371964, Generator Loss: 8.127300262451172\n",
      "Epoch7: Discriminator Loss: 6.0287435189820826e-05, Generator Loss: 11.107562065124512\n",
      "Epoch7: Discriminator Loss: 0.029163029044866562, Generator Loss: 10.61720085144043\n",
      "Epoch7: Discriminator Loss: 5.73962606722489e-05, Generator Loss: 10.391383171081543\n",
      "Epoch7: Discriminator Loss: 8.291337144328281e-05, Generator Loss: 9.206024169921875\n",
      "Epoch7: Discriminator Loss: 0.011701244860887527, Generator Loss: 5.125542163848877\n",
      "Epoch7: Discriminator Loss: 0.0007067087572067976, Generator Loss: 8.380358695983887\n",
      "Epoch7: Discriminator Loss: 5.8069163060281426e-05, Generator Loss: 9.148233413696289\n",
      "Epoch7: Discriminator Loss: 0.013603610917925835, Generator Loss: 4.468445301055908\n",
      "Epoch7: Discriminator Loss: 0.0005964842275716364, Generator Loss: 9.16987419128418\n",
      "Epoch7: Discriminator Loss: 0.00036727223778143525, Generator Loss: 8.950010299682617\n",
      "Epoch7: Discriminator Loss: 0.01879851333796978, Generator Loss: 4.658148765563965\n",
      "Epoch7: Discriminator Loss: 0.0005124997114762664, Generator Loss: 7.668172836303711\n",
      "Epoch7: Discriminator Loss: 0.0003756566729862243, Generator Loss: 6.16170597076416\n",
      "Epoch7: Discriminator Loss: 0.00031026991200633347, Generator Loss: 7.161249160766602\n",
      "Epoch7: Discriminator Loss: 0.00023220629373099655, Generator Loss: 6.76932430267334\n",
      "Epoch7: Discriminator Loss: 0.06687773764133453, Generator Loss: 5.834208965301514\n",
      "Epoch7: Discriminator Loss: 0.0018523884937167168, Generator Loss: 7.230952739715576\n",
      "Epoch7: Discriminator Loss: 0.00011067606101278216, Generator Loss: 8.842484474182129\n",
      "Epoch7: Discriminator Loss: 0.022869370877742767, Generator Loss: 9.153882026672363\n",
      "Epoch7: Discriminator Loss: 0.001418167958036065, Generator Loss: 8.547647476196289\n",
      "Epoch7: Discriminator Loss: 0.0002073992509394884, Generator Loss: 7.259915351867676\n",
      "Epoch7: Discriminator Loss: 0.0015367548912763596, Generator Loss: 5.781153678894043\n",
      "Epoch7: Discriminator Loss: 0.004961822647601366, Generator Loss: 6.8175950050354\n",
      "Epoch7: Discriminator Loss: 0.03613389655947685, Generator Loss: 9.380290031433105\n",
      "Epoch7: Discriminator Loss: 0.041824180632829666, Generator Loss: 7.821135520935059\n",
      "Epoch7: Discriminator Loss: 4.5225310714158695e-06, Generator Loss: 11.501580238342285\n",
      "Epoch7: Discriminator Loss: 9.128545934800059e-05, Generator Loss: 8.8671236038208\n",
      "Epoch7: Discriminator Loss: 0.006975200027227402, Generator Loss: 8.539361953735352\n",
      "Epoch7: Discriminator Loss: 0.0023314503487199545, Generator Loss: 6.535487651824951\n",
      "Epoch7: Discriminator Loss: 0.0013832311378791928, Generator Loss: 5.795412540435791\n",
      "Epoch7: Discriminator Loss: 5.561940270126797e-05, Generator Loss: 9.734454154968262\n",
      "Epoch7: Discriminator Loss: 0.026862623170018196, Generator Loss: 2.666372776031494\n",
      "Epoch7: Discriminator Loss: 0.02265833504498005, Generator Loss: 5.996288299560547\n",
      "Epoch7: Discriminator Loss: 0.0005014545167796314, Generator Loss: 4.966090679168701\n",
      "Epoch7: Discriminator Loss: 0.02743312157690525, Generator Loss: 6.788327693939209\n",
      "Epoch7: Discriminator Loss: 0.0005556757678277791, Generator Loss: 6.4441447257995605\n",
      "Epoch7: Discriminator Loss: 0.00021989765809848905, Generator Loss: 9.201274871826172\n",
      "Epoch7: Discriminator Loss: 0.004031370393931866, Generator Loss: 5.304388999938965\n",
      "Epoch7: Discriminator Loss: 0.021469227969646454, Generator Loss: 7.164407730102539\n",
      "Epoch7: Discriminator Loss: 0.0007007620297372341, Generator Loss: 6.685708522796631\n",
      "Epoch7: Discriminator Loss: 0.0016027884557843208, Generator Loss: 6.30524206161499\n",
      "Epoch7: Discriminator Loss: 0.0015857561957091093, Generator Loss: 9.189708709716797\n",
      "Epoch7: Discriminator Loss: 0.0008268543751910329, Generator Loss: 6.439894676208496\n",
      "Epoch7: Discriminator Loss: 0.0001684624730842188, Generator Loss: 7.948864459991455\n",
      "Epoch7: Discriminator Loss: 0.0005618393770419061, Generator Loss: 8.578752517700195\n",
      "Epoch7: Discriminator Loss: 0.1047636866569519, Generator Loss: 3.650841236114502\n",
      "Epoch7: Discriminator Loss: 9.555767610436305e-05, Generator Loss: 8.600898742675781\n",
      "Epoch7: Discriminator Loss: 2.479982140357606e-05, Generator Loss: 12.656763076782227\n",
      "Epoch7: Discriminator Loss: 0.0003356651577632874, Generator Loss: 3.6583433151245117\n",
      "Epoch7: Discriminator Loss: 0.04266448691487312, Generator Loss: 9.769364356994629\n",
      "Epoch7: Discriminator Loss: 1.9029670511372387e-05, Generator Loss: 10.025094985961914\n",
      "Epoch7: Discriminator Loss: 0.00046788612962700427, Generator Loss: 6.824223041534424\n",
      "Epoch7: Discriminator Loss: 0.0579666867852211, Generator Loss: 9.874634742736816\n",
      "Epoch7: Discriminator Loss: 0.012528564780950546, Generator Loss: 8.157090187072754\n",
      "Epoch7: Discriminator Loss: 2.0051329556736164e-05, Generator Loss: 11.126923561096191\n",
      "Epoch7: Discriminator Loss: 4.7015866584843025e-05, Generator Loss: 8.342561721801758\n",
      "Epoch7: Discriminator Loss: 0.004565095063298941, Generator Loss: 8.998424530029297\n",
      "Epoch7: Discriminator Loss: 5.945618340774672e-06, Generator Loss: 10.869976043701172\n",
      "Epoch8: Discriminator Loss: 0.0003411495708860457, Generator Loss: 7.780705451965332\n",
      "Epoch8: Discriminator Loss: 0.004073474556207657, Generator Loss: 12.385189056396484\n",
      "Epoch8: Discriminator Loss: 0.01209769956767559, Generator Loss: 8.040287971496582\n",
      "Epoch8: Discriminator Loss: 0.0001780081365723163, Generator Loss: 7.595283508300781\n",
      "Epoch8: Discriminator Loss: 0.013560594990849495, Generator Loss: 8.599442481994629\n",
      "Epoch8: Discriminator Loss: 0.003941909875720739, Generator Loss: 7.773653984069824\n",
      "Epoch8: Discriminator Loss: 0.015425575897097588, Generator Loss: 10.26278018951416\n",
      "Epoch8: Discriminator Loss: 0.006115383002907038, Generator Loss: 3.145665168762207\n",
      "Epoch8: Discriminator Loss: 0.00039636538713239133, Generator Loss: 5.228537559509277\n",
      "Epoch8: Discriminator Loss: 5.166976188775152e-05, Generator Loss: 8.883816719055176\n",
      "Epoch8: Discriminator Loss: 0.006344384513795376, Generator Loss: 8.563754081726074\n",
      "Epoch8: Discriminator Loss: 0.00026546535082161427, Generator Loss: 10.481954574584961\n",
      "Epoch8: Discriminator Loss: 0.00026077564689330757, Generator Loss: 7.180958271026611\n",
      "Epoch8: Discriminator Loss: 0.00031511607812717557, Generator Loss: 7.356078147888184\n",
      "Epoch8: Discriminator Loss: 0.03594822809100151, Generator Loss: 2.4667820930480957\n",
      "Epoch8: Discriminator Loss: 0.00017515907529741526, Generator Loss: 7.164378643035889\n",
      "Epoch8: Discriminator Loss: 0.0016511792782694101, Generator Loss: 6.348732948303223\n",
      "Epoch8: Discriminator Loss: 0.0004136387724429369, Generator Loss: 7.4947333335876465\n",
      "Epoch8: Discriminator Loss: 0.030413078144192696, Generator Loss: 2.5467429161071777\n",
      "Epoch8: Discriminator Loss: 2.3805441742297262e-05, Generator Loss: 11.468083381652832\n",
      "Epoch8: Discriminator Loss: 4.51079404228949e-06, Generator Loss: 10.823919296264648\n",
      "Epoch8: Discriminator Loss: 0.000501170870848, Generator Loss: 7.686309814453125\n",
      "Epoch8: Discriminator Loss: 0.0008075057994574308, Generator Loss: 8.45884895324707\n",
      "Epoch8: Discriminator Loss: 0.0002666922810021788, Generator Loss: 7.7302398681640625\n",
      "Epoch8: Discriminator Loss: 0.0006277264328673482, Generator Loss: 5.750161647796631\n",
      "Epoch8: Discriminator Loss: 8.228937804233283e-05, Generator Loss: 8.318523406982422\n",
      "Epoch8: Discriminator Loss: 0.0020547620952129364, Generator Loss: 7.0880913734436035\n",
      "Epoch8: Discriminator Loss: 0.0003751032054424286, Generator Loss: 9.593396186828613\n",
      "Epoch8: Discriminator Loss: 0.0012702661333605647, Generator Loss: 4.220087051391602\n",
      "Epoch8: Discriminator Loss: 0.07916578650474548, Generator Loss: 9.47276782989502\n",
      "Epoch8: Discriminator Loss: 0.09159374982118607, Generator Loss: 8.052093505859375\n",
      "Epoch8: Discriminator Loss: 0.02508252114057541, Generator Loss: 10.507559776306152\n",
      "Epoch8: Discriminator Loss: 5.4999902204144746e-05, Generator Loss: 12.629243850708008\n",
      "Epoch8: Discriminator Loss: 5.518546822713688e-05, Generator Loss: 12.409688949584961\n",
      "Epoch8: Discriminator Loss: 0.00010026743257185444, Generator Loss: 12.309712409973145\n",
      "Epoch8: Discriminator Loss: 0.0008392276940867305, Generator Loss: 8.541072845458984\n",
      "Epoch8: Discriminator Loss: 0.00015947953215800226, Generator Loss: 8.876834869384766\n",
      "Epoch8: Discriminator Loss: 0.032541632652282715, Generator Loss: 10.899070739746094\n",
      "Epoch8: Discriminator Loss: 7.541712875536177e-06, Generator Loss: 10.547822952270508\n",
      "Epoch8: Discriminator Loss: 0.051695387810468674, Generator Loss: 12.76653003692627\n",
      "Epoch8: Discriminator Loss: 0.0015753319021314383, Generator Loss: 8.920137405395508\n",
      "Epoch8: Discriminator Loss: 0.00102752516977489, Generator Loss: 8.266390800476074\n",
      "Epoch8: Discriminator Loss: 0.08890591561794281, Generator Loss: 9.212236404418945\n",
      "Epoch8: Discriminator Loss: 6.961728649912402e-05, Generator Loss: 7.788483619689941\n",
      "Epoch8: Discriminator Loss: 0.0007790722884237766, Generator Loss: 5.005012035369873\n",
      "Epoch8: Discriminator Loss: 0.00026619594427756965, Generator Loss: 7.176382541656494\n",
      "Epoch8: Discriminator Loss: 0.00022456869191955775, Generator Loss: 7.650981426239014\n",
      "Epoch8: Discriminator Loss: 0.00012116487778257579, Generator Loss: 7.884043216705322\n",
      "Epoch8: Discriminator Loss: 0.09452022612094879, Generator Loss: 1.0378764867782593\n",
      "Epoch8: Discriminator Loss: 0.0001465784152969718, Generator Loss: 9.125235557556152\n",
      "Epoch8: Discriminator Loss: 0.004650029353797436, Generator Loss: 10.426207542419434\n",
      "Epoch8: Discriminator Loss: 7.437493331963196e-05, Generator Loss: 9.184805870056152\n",
      "Epoch8: Discriminator Loss: 8.873680053511634e-05, Generator Loss: 9.804631233215332\n",
      "Epoch8: Discriminator Loss: 1.486802375438856e-05, Generator Loss: 9.398965835571289\n",
      "Epoch8: Discriminator Loss: 0.0027152816765010357, Generator Loss: 7.311651706695557\n",
      "Epoch8: Discriminator Loss: 0.0011373101733624935, Generator Loss: 4.35009241104126\n",
      "Epoch8: Discriminator Loss: 0.00042027494055218995, Generator Loss: 7.396953582763672\n",
      "Epoch8: Discriminator Loss: 0.00055008998606354, Generator Loss: 7.658815383911133\n",
      "Epoch8: Discriminator Loss: 0.09726303070783615, Generator Loss: 10.836421012878418\n",
      "Epoch8: Discriminator Loss: 6.86269486322999e-05, Generator Loss: 8.328485488891602\n",
      "Epoch8: Discriminator Loss: 0.0002780036593321711, Generator Loss: 10.246603012084961\n",
      "Epoch8: Discriminator Loss: 0.00011281861952738836, Generator Loss: 7.83724308013916\n",
      "Epoch8: Discriminator Loss: 1.3830766874889378e-05, Generator Loss: 9.982230186462402\n",
      "Epoch8: Discriminator Loss: 0.013246403075754642, Generator Loss: 8.291271209716797\n",
      "Epoch8: Discriminator Loss: 0.00010855761502170935, Generator Loss: 10.423362731933594\n",
      "Epoch8: Discriminator Loss: 0.0007158788503147662, Generator Loss: 6.9004130363464355\n",
      "Epoch8: Discriminator Loss: 0.0006074006087146699, Generator Loss: 8.982897758483887\n",
      "Epoch8: Discriminator Loss: 0.00035401294007897377, Generator Loss: 10.300055503845215\n",
      "Epoch8: Discriminator Loss: 0.0002621843887027353, Generator Loss: 8.261247634887695\n",
      "Epoch8: Discriminator Loss: 0.017413146793842316, Generator Loss: 8.643889427185059\n",
      "Epoch8: Discriminator Loss: 0.00025255035143345594, Generator Loss: 8.449131965637207\n",
      "Epoch8: Discriminator Loss: 0.0041338917799293995, Generator Loss: 7.0342559814453125\n",
      "Epoch8: Discriminator Loss: 0.0028268166352063417, Generator Loss: 5.47003698348999\n",
      "Epoch8: Discriminator Loss: 0.00016049208352342248, Generator Loss: 7.577931880950928\n",
      "Epoch8: Discriminator Loss: 0.0008573507657274604, Generator Loss: 6.538050174713135\n",
      "Epoch8: Discriminator Loss: 4.6476976422127336e-05, Generator Loss: 10.260871887207031\n",
      "Epoch8: Discriminator Loss: 0.009298177435994148, Generator Loss: 10.569039344787598\n",
      "Epoch8: Discriminator Loss: 0.009925976395606995, Generator Loss: 9.650223731994629\n",
      "Epoch8: Discriminator Loss: 0.0008326579700224102, Generator Loss: 10.509385108947754\n",
      "Epoch8: Discriminator Loss: 0.011860755272209644, Generator Loss: 11.302948951721191\n",
      "Epoch8: Discriminator Loss: 0.0004211320774629712, Generator Loss: 7.124424934387207\n",
      "Epoch8: Discriminator Loss: 0.0002513210638426244, Generator Loss: 10.30968189239502\n",
      "Epoch8: Discriminator Loss: 6.864152965135872e-05, Generator Loss: 9.221665382385254\n",
      "Epoch8: Discriminator Loss: 0.0005195108824409544, Generator Loss: 11.550349235534668\n",
      "Epoch8: Discriminator Loss: 6.441830919357017e-05, Generator Loss: 9.073797225952148\n",
      "Epoch8: Discriminator Loss: 0.007004417013376951, Generator Loss: 9.869913101196289\n",
      "Epoch8: Discriminator Loss: 0.002753100823611021, Generator Loss: 6.55742883682251\n",
      "Epoch8: Discriminator Loss: 0.0001176608056994155, Generator Loss: 8.44422435760498\n",
      "Epoch8: Discriminator Loss: 0.002982535632327199, Generator Loss: 3.7847673892974854\n",
      "Epoch8: Discriminator Loss: 0.04533582925796509, Generator Loss: 5.619778156280518\n",
      "Epoch8: Discriminator Loss: 0.00011752815044019371, Generator Loss: 9.834113121032715\n",
      "Epoch8: Discriminator Loss: 0.004404828883707523, Generator Loss: 9.581424713134766\n",
      "Epoch8: Discriminator Loss: 0.00014323511277325451, Generator Loss: 8.068703651428223\n",
      "Epoch8: Discriminator Loss: 0.005144533701241016, Generator Loss: 3.911525249481201\n",
      "Epoch8: Discriminator Loss: 0.0001890667190309614, Generator Loss: 7.758721351623535\n",
      "Epoch8: Discriminator Loss: 3.6813353290199302e-06, Generator Loss: 11.210918426513672\n",
      "Epoch8: Discriminator Loss: 0.008572649210691452, Generator Loss: 4.419589042663574\n",
      "Epoch8: Discriminator Loss: 0.00017761610797606409, Generator Loss: 8.569632530212402\n",
      "Epoch8: Discriminator Loss: 0.0001396134466631338, Generator Loss: 9.302932739257812\n",
      "Epoch8: Discriminator Loss: 0.020202860236167908, Generator Loss: 9.460372924804688\n",
      "Epoch8: Discriminator Loss: 0.00022053490101825446, Generator Loss: 8.365581512451172\n",
      "Epoch8: Discriminator Loss: 0.00596897816285491, Generator Loss: 6.65848970413208\n",
      "Epoch8: Discriminator Loss: 0.00033436910598538816, Generator Loss: 11.249861717224121\n",
      "Epoch8: Discriminator Loss: 1.2726909517368767e-05, Generator Loss: 10.342606544494629\n",
      "Epoch8: Discriminator Loss: 0.0070664784871041775, Generator Loss: 9.439778327941895\n",
      "Epoch8: Discriminator Loss: 3.285803541075438e-05, Generator Loss: 11.003377914428711\n",
      "Epoch8: Discriminator Loss: 8.961154526332393e-05, Generator Loss: 8.192997932434082\n",
      "Epoch8: Discriminator Loss: 0.0004489613347686827, Generator Loss: 8.618537902832031\n",
      "Epoch8: Discriminator Loss: 0.00020684897026512772, Generator Loss: 6.904923439025879\n",
      "Epoch8: Discriminator Loss: 2.0396897525643e-05, Generator Loss: 9.282516479492188\n",
      "Epoch8: Discriminator Loss: 2.370578295085579e-05, Generator Loss: 9.979909896850586\n",
      "Epoch8: Discriminator Loss: 4.641913255909458e-05, Generator Loss: 9.337170600891113\n",
      "Epoch8: Discriminator Loss: 0.00019269282347522676, Generator Loss: 9.087541580200195\n",
      "Epoch8: Discriminator Loss: 0.0180070623755455, Generator Loss: 10.819332122802734\n",
      "Epoch8: Discriminator Loss: 0.00041593590867705643, Generator Loss: 8.829092025756836\n",
      "Epoch8: Discriminator Loss: 0.05148475244641304, Generator Loss: 6.3559889793396\n",
      "Epoch8: Discriminator Loss: 0.009559080004692078, Generator Loss: 7.622650623321533\n",
      "Epoch8: Discriminator Loss: 0.0005828808061778545, Generator Loss: 7.006502151489258\n",
      "Epoch8: Discriminator Loss: 0.00013710618077311665, Generator Loss: 8.79592227935791\n",
      "Epoch8: Discriminator Loss: 5.2104944188613445e-05, Generator Loss: 8.661653518676758\n",
      "Epoch8: Discriminator Loss: 4.2016316001536325e-05, Generator Loss: 9.36008358001709\n",
      "Epoch8: Discriminator Loss: 0.012632554396986961, Generator Loss: 7.795270919799805\n",
      "Epoch8: Discriminator Loss: 0.0051015811040997505, Generator Loss: 8.47152042388916\n",
      "Epoch8: Discriminator Loss: 0.004451138433068991, Generator Loss: 5.667052745819092\n",
      "Epoch8: Discriminator Loss: 0.00012103872722946107, Generator Loss: 10.13701343536377\n",
      "Epoch8: Discriminator Loss: 0.0016799627337604761, Generator Loss: 5.301225662231445\n",
      "Epoch8: Discriminator Loss: 5.757073449785821e-05, Generator Loss: 7.822010517120361\n",
      "Epoch8: Discriminator Loss: 0.00032145302975550294, Generator Loss: 7.128498077392578\n",
      "Epoch8: Discriminator Loss: 0.003323765005916357, Generator Loss: 6.366114616394043\n",
      "Epoch8: Discriminator Loss: 0.0008691653492860496, Generator Loss: 5.854787349700928\n",
      "Epoch8: Discriminator Loss: 0.0016442190390080214, Generator Loss: 4.792218208312988\n",
      "Epoch8: Discriminator Loss: 0.00044204204459674656, Generator Loss: 7.090800762176514\n",
      "Epoch8: Discriminator Loss: 0.000171748484717682, Generator Loss: 7.968593120574951\n",
      "Epoch8: Discriminator Loss: 0.11006607860326767, Generator Loss: 4.4744720458984375\n",
      "Epoch8: Discriminator Loss: 0.2156379222869873, Generator Loss: 4.013945579528809\n",
      "Epoch8: Discriminator Loss: 1.2707374480669387e-05, Generator Loss: 10.290432929992676\n",
      "Epoch8: Discriminator Loss: 0.0836140364408493, Generator Loss: 6.260726451873779\n",
      "Epoch8: Discriminator Loss: 0.08987578004598618, Generator Loss: 11.584609985351562\n",
      "Epoch8: Discriminator Loss: 0.03350108489394188, Generator Loss: 10.69550895690918\n",
      "Epoch8: Discriminator Loss: 0.002641480416059494, Generator Loss: 9.515525817871094\n",
      "Epoch8: Discriminator Loss: 0.18634824454784393, Generator Loss: 12.809853553771973\n",
      "Epoch8: Discriminator Loss: 0.009420666843652725, Generator Loss: 13.659869194030762\n",
      "Epoch8: Discriminator Loss: 0.08179104328155518, Generator Loss: 13.927959442138672\n",
      "Epoch8: Discriminator Loss: 8.525998055119999e-06, Generator Loss: 11.057199478149414\n",
      "Epoch8: Discriminator Loss: 1.932706800289452e-05, Generator Loss: 12.703404426574707\n",
      "Epoch8: Discriminator Loss: 0.15745078027248383, Generator Loss: 12.13525390625\n",
      "Epoch8: Discriminator Loss: 0.00043827365152537823, Generator Loss: 11.543800354003906\n",
      "Epoch8: Discriminator Loss: 2.0508111902017845e-06, Generator Loss: 14.12012004852295\n",
      "Epoch8: Discriminator Loss: 0.0639299750328064, Generator Loss: 10.927712440490723\n",
      "Epoch8: Discriminator Loss: 0.0006974773132242262, Generator Loss: 11.005105972290039\n",
      "Epoch8: Discriminator Loss: 2.445759491820354e-06, Generator Loss: 13.008516311645508\n",
      "Epoch8: Discriminator Loss: 0.00724899023771286, Generator Loss: 12.638057708740234\n",
      "Epoch8: Discriminator Loss: 0.09044881165027618, Generator Loss: 9.047475814819336\n",
      "Epoch8: Discriminator Loss: 0.06758394092321396, Generator Loss: 13.11018180847168\n",
      "Epoch8: Discriminator Loss: 0.020172130316495895, Generator Loss: 8.748407363891602\n",
      "Epoch8: Discriminator Loss: 0.0004897646140307188, Generator Loss: 10.928450584411621\n",
      "Epoch8: Discriminator Loss: 1.612124833627604e-06, Generator Loss: 14.568140029907227\n",
      "Epoch8: Discriminator Loss: 1.7764419681043364e-05, Generator Loss: 11.31555461883545\n",
      "Epoch8: Discriminator Loss: 2.4105936972773634e-05, Generator Loss: 9.916154861450195\n",
      "Epoch8: Discriminator Loss: 0.00012335670180618763, Generator Loss: 9.603326797485352\n",
      "Epoch8: Discriminator Loss: 0.00032248813658952713, Generator Loss: 8.966863632202148\n",
      "Epoch8: Discriminator Loss: 0.0004977112403139472, Generator Loss: 9.489126205444336\n",
      "Epoch8: Discriminator Loss: 0.08138560503721237, Generator Loss: 8.18736743927002\n",
      "Epoch8: Discriminator Loss: 0.00021761759126093239, Generator Loss: 10.42920970916748\n",
      "Epoch8: Discriminator Loss: 0.00014347264368552715, Generator Loss: 9.18442153930664\n",
      "Epoch8: Discriminator Loss: 0.00020002920064143836, Generator Loss: 7.314682483673096\n",
      "Epoch8: Discriminator Loss: 2.903065069403965e-05, Generator Loss: 9.359368324279785\n",
      "Epoch8: Discriminator Loss: 0.0216112919151783, Generator Loss: 4.770496845245361\n",
      "Epoch8: Discriminator Loss: 0.00011935684597119689, Generator Loss: 9.753174781799316\n",
      "Epoch8: Discriminator Loss: 0.0002339083730475977, Generator Loss: 8.69008731842041\n",
      "Epoch8: Discriminator Loss: 0.016596032306551933, Generator Loss: 10.032723426818848\n",
      "Epoch8: Discriminator Loss: 0.0604146309196949, Generator Loss: 5.2953596115112305\n",
      "Epoch8: Discriminator Loss: 0.007999543100595474, Generator Loss: 8.96694278717041\n",
      "Epoch8: Discriminator Loss: 0.03443342074751854, Generator Loss: 11.462072372436523\n",
      "Epoch8: Discriminator Loss: 7.057060429360718e-05, Generator Loss: 8.637704849243164\n",
      "Epoch8: Discriminator Loss: 0.00013133919856045395, Generator Loss: 7.702171802520752\n",
      "Epoch9: Discriminator Loss: 0.0021016753744333982, Generator Loss: 6.290396690368652\n",
      "Epoch9: Discriminator Loss: 0.0009200308122672141, Generator Loss: 6.285810470581055\n",
      "Epoch9: Discriminator Loss: 0.0011662057368084788, Generator Loss: 6.728260517120361\n",
      "Epoch9: Discriminator Loss: 2.356804361625109e-05, Generator Loss: 9.838068962097168\n",
      "Epoch9: Discriminator Loss: 0.0011045520659536123, Generator Loss: 8.070961952209473\n",
      "Epoch9: Discriminator Loss: 0.0150957265868783, Generator Loss: 2.689070463180542\n",
      "Epoch9: Discriminator Loss: 0.0006818913388997316, Generator Loss: 6.835442066192627\n",
      "Epoch9: Discriminator Loss: 0.0020007831044495106, Generator Loss: 4.9112114906311035\n",
      "Epoch9: Discriminator Loss: 0.0005726577364839613, Generator Loss: 5.1236395835876465\n",
      "Epoch9: Discriminator Loss: 0.06269094347953796, Generator Loss: 1.4321988821029663\n",
      "Epoch9: Discriminator Loss: 0.0015784730203449726, Generator Loss: 4.594630241394043\n",
      "Epoch9: Discriminator Loss: 0.26740899682044983, Generator Loss: 1.873467206954956\n",
      "Epoch9: Discriminator Loss: 0.00021506808116100729, Generator Loss: 7.970179557800293\n",
      "Epoch9: Discriminator Loss: 5.2279956435086206e-05, Generator Loss: 10.328202247619629\n",
      "Epoch9: Discriminator Loss: 0.0920790359377861, Generator Loss: 11.822667121887207\n",
      "Epoch9: Discriminator Loss: 1.1317721146042459e-05, Generator Loss: 11.471128463745117\n",
      "Epoch9: Discriminator Loss: 0.045590102672576904, Generator Loss: 13.259758949279785\n",
      "Epoch9: Discriminator Loss: 1.1362055374775082e-05, Generator Loss: 13.123528480529785\n",
      "Epoch9: Discriminator Loss: 0.19113430380821228, Generator Loss: 15.908892631530762\n",
      "Epoch9: Discriminator Loss: 0.09052808582782745, Generator Loss: 15.275115966796875\n",
      "Epoch9: Discriminator Loss: 0.09073386341333389, Generator Loss: 16.763986587524414\n",
      "Epoch9: Discriminator Loss: 1.0821669093274977e-05, Generator Loss: 13.16073226928711\n",
      "Epoch9: Discriminator Loss: 0.09071434289216995, Generator Loss: 13.821149826049805\n",
      "Epoch9: Discriminator Loss: 0.057997480034828186, Generator Loss: 12.19892406463623\n",
      "Epoch9: Discriminator Loss: 0.2101021558046341, Generator Loss: 14.612939834594727\n",
      "Epoch9: Discriminator Loss: 0.18071258068084717, Generator Loss: 14.335883140563965\n",
      "Epoch9: Discriminator Loss: 5.119885099702515e-05, Generator Loss: 15.53075885772705\n",
      "Epoch9: Discriminator Loss: 0.03859799727797508, Generator Loss: 14.208405494689941\n",
      "Epoch9: Discriminator Loss: 0.1362873613834381, Generator Loss: 13.202261924743652\n",
      "Epoch9: Discriminator Loss: 0.09127252548933029, Generator Loss: 14.375561714172363\n",
      "Epoch9: Discriminator Loss: 0.08671127259731293, Generator Loss: 13.510963439941406\n",
      "Epoch9: Discriminator Loss: 0.02255142480134964, Generator Loss: 9.6466646194458\n",
      "Epoch9: Discriminator Loss: 0.0006440597935579717, Generator Loss: 14.446925163269043\n",
      "Epoch9: Discriminator Loss: 0.011472008191049099, Generator Loss: 11.366314888000488\n",
      "Epoch9: Discriminator Loss: 6.379139085765928e-05, Generator Loss: 13.242103576660156\n",
      "Epoch9: Discriminator Loss: 3.698641376104206e-05, Generator Loss: 9.729598999023438\n",
      "Epoch9: Discriminator Loss: 9.228489034285303e-06, Generator Loss: 9.785897254943848\n",
      "Epoch9: Discriminator Loss: 2.0097929791518254e-06, Generator Loss: 12.924707412719727\n",
      "Epoch9: Discriminator Loss: 0.03785797581076622, Generator Loss: 9.716883659362793\n",
      "Epoch9: Discriminator Loss: 0.004037656355649233, Generator Loss: 8.735642433166504\n",
      "Epoch9: Discriminator Loss: 0.05090460181236267, Generator Loss: 12.406119346618652\n",
      "Epoch9: Discriminator Loss: 0.018701734021306038, Generator Loss: 7.944512367248535\n",
      "Epoch9: Discriminator Loss: 8.232386608142406e-05, Generator Loss: 7.3521952629089355\n",
      "Epoch9: Discriminator Loss: 0.0001816041040001437, Generator Loss: 8.747340202331543\n",
      "Epoch9: Discriminator Loss: 0.0006069154478609562, Generator Loss: 6.461994171142578\n",
      "Epoch9: Discriminator Loss: 0.0005778708728030324, Generator Loss: 7.472052574157715\n",
      "Epoch9: Discriminator Loss: 0.00017652065434958786, Generator Loss: 7.192034721374512\n",
      "Epoch9: Discriminator Loss: 1.907673322421033e-05, Generator Loss: 10.337973594665527\n",
      "Epoch9: Discriminator Loss: 0.0011260751634836197, Generator Loss: 6.873908042907715\n",
      "Epoch9: Discriminator Loss: 0.0009099876042455435, Generator Loss: 4.6810221672058105\n",
      "Epoch9: Discriminator Loss: 0.0036186447832733393, Generator Loss: 6.069514274597168\n",
      "Epoch9: Discriminator Loss: 0.0004075674805790186, Generator Loss: 7.167562484741211\n",
      "Epoch9: Discriminator Loss: 0.0009926125640049577, Generator Loss: 6.349743366241455\n",
      "Epoch9: Discriminator Loss: 0.09109656512737274, Generator Loss: 8.542695999145508\n",
      "Epoch9: Discriminator Loss: 0.0019457447342574596, Generator Loss: 3.695300579071045\n",
      "Epoch9: Discriminator Loss: 0.012311061844229698, Generator Loss: 5.394425868988037\n",
      "Epoch9: Discriminator Loss: 0.05248306691646576, Generator Loss: 4.142586708068848\n",
      "Epoch9: Discriminator Loss: 0.00045039504766464233, Generator Loss: 7.948153972625732\n",
      "Epoch9: Discriminator Loss: 0.0006969838286750019, Generator Loss: 5.604549884796143\n",
      "Epoch9: Discriminator Loss: 0.0003348536847624928, Generator Loss: 7.0915985107421875\n",
      "Epoch9: Discriminator Loss: 0.0006480072624981403, Generator Loss: 6.465483665466309\n",
      "Epoch9: Discriminator Loss: 0.0004071297007612884, Generator Loss: 7.6282267570495605\n",
      "Epoch9: Discriminator Loss: 0.03423202037811279, Generator Loss: 4.784078598022461\n",
      "Epoch9: Discriminator Loss: 0.0002177694987040013, Generator Loss: 10.410072326660156\n",
      "Epoch9: Discriminator Loss: 0.0007173241465352476, Generator Loss: 5.767975807189941\n",
      "Epoch9: Discriminator Loss: 0.0006966228247620165, Generator Loss: 7.022839546203613\n",
      "Epoch9: Discriminator Loss: 0.0008253908017650247, Generator Loss: 4.967731952667236\n",
      "Epoch9: Discriminator Loss: 0.0007666497840546072, Generator Loss: 8.349964141845703\n",
      "Epoch9: Discriminator Loss: 8.764166705077514e-05, Generator Loss: 9.181811332702637\n",
      "Epoch9: Discriminator Loss: 0.00016322403098456562, Generator Loss: 8.002681732177734\n",
      "Epoch9: Discriminator Loss: 2.594405486888718e-05, Generator Loss: 7.57908821105957\n",
      "Epoch9: Discriminator Loss: 0.00031257254886440933, Generator Loss: 7.7780561447143555\n",
      "Epoch9: Discriminator Loss: 7.371260289801285e-05, Generator Loss: 9.250624656677246\n",
      "Epoch9: Discriminator Loss: 0.001708082389086485, Generator Loss: 5.568016052246094\n",
      "Epoch9: Discriminator Loss: 0.0006891616503708065, Generator Loss: 8.01982307434082\n",
      "Epoch9: Discriminator Loss: 0.001552409608848393, Generator Loss: 6.153598785400391\n",
      "Epoch9: Discriminator Loss: 0.0030367067083716393, Generator Loss: 6.622674942016602\n",
      "Epoch9: Discriminator Loss: 3.8921636587474495e-05, Generator Loss: 10.167318344116211\n",
      "Epoch9: Discriminator Loss: 0.01681671105325222, Generator Loss: 6.607106685638428\n",
      "Epoch9: Discriminator Loss: 0.0008969936170615256, Generator Loss: 9.659003257751465\n",
      "Epoch9: Discriminator Loss: 0.0007397185545414686, Generator Loss: 6.800310134887695\n",
      "Epoch9: Discriminator Loss: 0.00025832952815108, Generator Loss: 7.5190110206604\n",
      "Epoch9: Discriminator Loss: 0.00043352352804504335, Generator Loss: 6.028422832489014\n",
      "Epoch9: Discriminator Loss: 0.003673642873764038, Generator Loss: 6.679531574249268\n",
      "Epoch9: Discriminator Loss: 2.475477049301844e-05, Generator Loss: 8.226102828979492\n",
      "Epoch9: Discriminator Loss: 0.05421452596783638, Generator Loss: 7.042300224304199\n",
      "Epoch9: Discriminator Loss: 0.0007378114387392998, Generator Loss: 6.475321292877197\n",
      "Epoch9: Discriminator Loss: 0.0004310761869419366, Generator Loss: 7.976454257965088\n",
      "Epoch9: Discriminator Loss: 0.0009147011442109942, Generator Loss: 8.750516891479492\n",
      "Epoch9: Discriminator Loss: 0.0010711794020608068, Generator Loss: 8.072967529296875\n",
      "Epoch9: Discriminator Loss: 0.009277074597775936, Generator Loss: 6.448347568511963\n",
      "Epoch9: Discriminator Loss: 0.0010310474317520857, Generator Loss: 7.2643818855285645\n",
      "Epoch9: Discriminator Loss: 0.0011024691630154848, Generator Loss: 6.905228137969971\n",
      "Epoch9: Discriminator Loss: 0.08754465728998184, Generator Loss: 3.4777238368988037\n",
      "Epoch9: Discriminator Loss: 0.01322901714593172, Generator Loss: 1.3800241947174072\n",
      "Epoch9: Discriminator Loss: 0.00019808112119790167, Generator Loss: 9.954246520996094\n",
      "Epoch9: Discriminator Loss: 0.053155988454818726, Generator Loss: 2.3838136196136475\n",
      "Epoch9: Discriminator Loss: 2.313464028702583e-05, Generator Loss: 9.627509117126465\n",
      "Epoch9: Discriminator Loss: 0.0005717853200621903, Generator Loss: 6.767488479614258\n",
      "Epoch9: Discriminator Loss: 0.0001971523743122816, Generator Loss: 8.51708698272705\n",
      "Epoch9: Discriminator Loss: 1.1142398761876393e-05, Generator Loss: 12.412132263183594\n",
      "Epoch9: Discriminator Loss: 0.0005950903869234025, Generator Loss: 6.275941371917725\n",
      "Epoch9: Discriminator Loss: 0.0040563247166574, Generator Loss: 9.549428939819336\n",
      "Epoch9: Discriminator Loss: 0.00019035495643038303, Generator Loss: 10.8184814453125\n",
      "Epoch9: Discriminator Loss: 0.0003875298716593534, Generator Loss: 13.131433486938477\n",
      "Epoch9: Discriminator Loss: 1.2356210390862543e-05, Generator Loss: 11.680572509765625\n",
      "Epoch9: Discriminator Loss: 0.09117472916841507, Generator Loss: 12.907776832580566\n",
      "Epoch9: Discriminator Loss: 7.926167745608836e-05, Generator Loss: 11.434614181518555\n",
      "Epoch9: Discriminator Loss: 3.391929203644395e-05, Generator Loss: 14.300273895263672\n",
      "Epoch9: Discriminator Loss: 2.1727602870669216e-05, Generator Loss: 13.060264587402344\n",
      "Epoch9: Discriminator Loss: 7.432189158862457e-05, Generator Loss: 10.390811920166016\n",
      "Epoch9: Discriminator Loss: 0.08359093219041824, Generator Loss: 11.833516120910645\n",
      "Epoch9: Discriminator Loss: 4.979631739843171e-06, Generator Loss: 13.974987030029297\n",
      "Epoch9: Discriminator Loss: 0.1755022555589676, Generator Loss: 11.69892692565918\n",
      "Epoch9: Discriminator Loss: 0.0020363847725093365, Generator Loss: 14.161942481994629\n",
      "Epoch9: Discriminator Loss: 5.4432339311460964e-06, Generator Loss: 11.696643829345703\n",
      "Epoch9: Discriminator Loss: 0.08795877546072006, Generator Loss: 11.875397682189941\n",
      "Epoch9: Discriminator Loss: 0.0001748418144416064, Generator Loss: 12.184706687927246\n",
      "Epoch9: Discriminator Loss: 0.056443411856889725, Generator Loss: 12.240801811218262\n",
      "Epoch9: Discriminator Loss: 0.0024292089510709047, Generator Loss: 11.422618865966797\n",
      "Epoch9: Discriminator Loss: 0.08778209984302521, Generator Loss: 11.525686264038086\n",
      "Epoch9: Discriminator Loss: 0.00046577100874856114, Generator Loss: 8.879388809204102\n",
      "Epoch9: Discriminator Loss: 0.00622683996334672, Generator Loss: 12.296272277832031\n",
      "Epoch9: Discriminator Loss: 2.3894630430731922e-05, Generator Loss: 10.008363723754883\n",
      "Epoch9: Discriminator Loss: 0.005327589809894562, Generator Loss: 4.9494829177856445\n",
      "Epoch9: Discriminator Loss: 4.7552588512189686e-05, Generator Loss: 9.951460838317871\n",
      "Epoch9: Discriminator Loss: 6.723817205056548e-05, Generator Loss: 11.272229194641113\n",
      "Epoch9: Discriminator Loss: 0.0910094827413559, Generator Loss: 9.894758224487305\n",
      "Epoch9: Discriminator Loss: 5.807996421935968e-05, Generator Loss: 10.222285270690918\n",
      "Epoch9: Discriminator Loss: 6.424068124033511e-05, Generator Loss: 10.54615592956543\n",
      "Epoch9: Discriminator Loss: 1.4468028894043528e-05, Generator Loss: 11.948420524597168\n",
      "Epoch9: Discriminator Loss: 5.1272269047331065e-05, Generator Loss: 8.741209983825684\n",
      "Epoch9: Discriminator Loss: 5.3888066759100184e-05, Generator Loss: 8.4898042678833\n",
      "Epoch9: Discriminator Loss: 3.088536686846055e-05, Generator Loss: 8.598752975463867\n",
      "Epoch9: Discriminator Loss: 2.035114448517561e-05, Generator Loss: 9.495320320129395\n",
      "Epoch9: Discriminator Loss: 0.0008276826119981706, Generator Loss: 11.291471481323242\n",
      "Epoch9: Discriminator Loss: 3.388255208847113e-05, Generator Loss: 10.60427474975586\n",
      "Epoch9: Discriminator Loss: 0.00018186759552918375, Generator Loss: 8.502755165100098\n",
      "Epoch9: Discriminator Loss: 0.00011263464693911374, Generator Loss: 9.626502990722656\n",
      "Epoch9: Discriminator Loss: 3.838132033706643e-05, Generator Loss: 9.329668998718262\n",
      "Epoch9: Discriminator Loss: 0.0014750950504094362, Generator Loss: 8.35232162475586\n",
      "Epoch9: Discriminator Loss: 0.00015293582691811025, Generator Loss: 9.94745922088623\n",
      "Epoch9: Discriminator Loss: 0.00030396977672353387, Generator Loss: 8.860125541687012\n",
      "Epoch9: Discriminator Loss: 0.00039894008659757674, Generator Loss: 8.323199272155762\n",
      "Epoch9: Discriminator Loss: 0.0011822594096884131, Generator Loss: 10.733177185058594\n",
      "Epoch9: Discriminator Loss: 0.0022614665795117617, Generator Loss: 10.314842224121094\n",
      "Epoch9: Discriminator Loss: 0.0026279257144778967, Generator Loss: 8.84409236907959\n",
      "Epoch9: Discriminator Loss: 0.06309060752391815, Generator Loss: 7.621556758880615\n",
      "Epoch9: Discriminator Loss: 4.159927266300656e-05, Generator Loss: 7.988367080688477\n",
      "Epoch9: Discriminator Loss: 0.0011435754131525755, Generator Loss: 7.502429485321045\n",
      "Epoch9: Discriminator Loss: 0.00015754654305055737, Generator Loss: 8.047760963439941\n",
      "Epoch9: Discriminator Loss: 0.05617143213748932, Generator Loss: 11.0376558303833\n",
      "Epoch9: Discriminator Loss: 4.699346027337015e-05, Generator Loss: 9.221056938171387\n",
      "Epoch9: Discriminator Loss: 0.0045770443975925446, Generator Loss: 4.721780300140381\n",
      "Epoch9: Discriminator Loss: 0.00010670793562894687, Generator Loss: 9.326316833496094\n",
      "Epoch9: Discriminator Loss: 0.0012378442334011197, Generator Loss: 6.520998477935791\n",
      "Epoch9: Discriminator Loss: 0.00018728908617049456, Generator Loss: 7.954545497894287\n",
      "Epoch9: Discriminator Loss: 0.004059493541717529, Generator Loss: 2.989321231842041\n",
      "Epoch9: Discriminator Loss: 0.00015523824549745768, Generator Loss: 8.833423614501953\n",
      "Epoch9: Discriminator Loss: 0.00028774916427209973, Generator Loss: 9.380447387695312\n",
      "Epoch9: Discriminator Loss: 0.0021770887542515993, Generator Loss: 4.975091457366943\n",
      "Epoch9: Discriminator Loss: 0.00017251860117539763, Generator Loss: 7.845826625823975\n",
      "Epoch9: Discriminator Loss: 0.00014872653991915286, Generator Loss: 6.713538646697998\n",
      "Epoch9: Discriminator Loss: 0.0001660223351791501, Generator Loss: 7.704376697540283\n",
      "Epoch9: Discriminator Loss: 8.005306153791025e-05, Generator Loss: 8.231420516967773\n",
      "Epoch9: Discriminator Loss: 0.01701042428612709, Generator Loss: 4.523001670837402\n",
      "Epoch9: Discriminator Loss: 0.000625421351287514, Generator Loss: 6.098260879516602\n",
      "Epoch9: Discriminator Loss: 0.0022570232395082712, Generator Loss: 5.181169033050537\n",
      "Epoch9: Discriminator Loss: 0.0005487896269187331, Generator Loss: 7.179455280303955\n",
      "Epoch9: Discriminator Loss: 0.0005714280414395034, Generator Loss: 6.826241970062256\n",
      "Epoch9: Discriminator Loss: 1.8152357370126992e-05, Generator Loss: 8.938095092773438\n",
      "Epoch9: Discriminator Loss: 0.00046295023639686406, Generator Loss: 7.826202392578125\n",
      "Epoch9: Discriminator Loss: 0.0010825850768014789, Generator Loss: 7.397331714630127\n",
      "Epoch9: Discriminator Loss: 0.0015261772787198424, Generator Loss: 5.9879045486450195\n",
      "Epoch9: Discriminator Loss: 0.00024865317391231656, Generator Loss: 8.128683090209961\n",
      "Epoch9: Discriminator Loss: 0.0015841068234294653, Generator Loss: 6.124847888946533\n",
      "Epoch10: Discriminator Loss: 0.0015771613689139485, Generator Loss: 6.663968563079834\n",
      "Epoch10: Discriminator Loss: 0.014354649931192398, Generator Loss: 6.093268871307373\n",
      "Epoch10: Discriminator Loss: 6.354608194669709e-05, Generator Loss: 8.41204833984375\n",
      "Epoch10: Discriminator Loss: 0.021182462573051453, Generator Loss: 6.505741596221924\n",
      "Epoch10: Discriminator Loss: 0.0013565539848059416, Generator Loss: 8.25467300415039\n",
      "Epoch10: Discriminator Loss: 0.0005114953382872045, Generator Loss: 10.373494148254395\n",
      "Epoch10: Discriminator Loss: 0.00014161784201860428, Generator Loss: 5.996097564697266\n",
      "Epoch10: Discriminator Loss: 0.00028162822127342224, Generator Loss: 6.32937479019165\n",
      "Epoch10: Discriminator Loss: 0.0007108378922566772, Generator Loss: 8.823479652404785\n",
      "Epoch10: Discriminator Loss: 0.00015530888049397618, Generator Loss: 6.440841197967529\n",
      "Epoch10: Discriminator Loss: 5.866867286385968e-05, Generator Loss: 11.25043773651123\n",
      "Epoch10: Discriminator Loss: 0.024586545303463936, Generator Loss: 8.595192909240723\n",
      "Epoch10: Discriminator Loss: 0.0005084696458652616, Generator Loss: 7.81951904296875\n",
      "Epoch10: Discriminator Loss: 3.17834310408216e-05, Generator Loss: 10.633740425109863\n",
      "Epoch10: Discriminator Loss: 0.0002487758465576917, Generator Loss: 7.252350807189941\n",
      "Epoch10: Discriminator Loss: 0.001595226931385696, Generator Loss: 7.316112518310547\n",
      "Epoch10: Discriminator Loss: 0.00019734508532565087, Generator Loss: 7.124354362487793\n",
      "Epoch10: Discriminator Loss: 0.08704790472984314, Generator Loss: 8.960763931274414\n",
      "Epoch10: Discriminator Loss: 0.0007646441226825118, Generator Loss: 7.4452314376831055\n",
      "Epoch10: Discriminator Loss: 0.0002810110745485872, Generator Loss: 8.24157428741455\n",
      "Epoch10: Discriminator Loss: 0.0005238339654169977, Generator Loss: 6.198668956756592\n",
      "Epoch10: Discriminator Loss: 0.020466133952140808, Generator Loss: 6.875524044036865\n",
      "Epoch10: Discriminator Loss: 0.0008825854165479541, Generator Loss: 7.2022271156311035\n",
      "Epoch10: Discriminator Loss: 0.000781437149271369, Generator Loss: 7.678822994232178\n",
      "Epoch10: Discriminator Loss: 0.0002469204773660749, Generator Loss: 7.937714099884033\n",
      "Epoch10: Discriminator Loss: 3.5571185435401276e-05, Generator Loss: 8.271737098693848\n",
      "Epoch10: Discriminator Loss: 6.274635234149173e-05, Generator Loss: 9.595683097839355\n",
      "Epoch10: Discriminator Loss: 0.00014201884914655238, Generator Loss: 9.265057563781738\n",
      "Epoch10: Discriminator Loss: 0.00017548871983308345, Generator Loss: 7.928754806518555\n",
      "Epoch10: Discriminator Loss: 0.0002074414660455659, Generator Loss: 7.275941371917725\n",
      "Epoch10: Discriminator Loss: 0.0004151883185841143, Generator Loss: 4.772158145904541\n",
      "Epoch10: Discriminator Loss: 5.62026871193666e-05, Generator Loss: 8.858292579650879\n",
      "Epoch10: Discriminator Loss: 0.00025510796695016325, Generator Loss: 7.097776889801025\n",
      "Epoch10: Discriminator Loss: 0.0001901544601423666, Generator Loss: 7.612576007843018\n",
      "Epoch10: Discriminator Loss: 0.0013593124458566308, Generator Loss: 5.718708515167236\n",
      "Epoch10: Discriminator Loss: 0.00021328817820176482, Generator Loss: 7.539211273193359\n",
      "Epoch10: Discriminator Loss: 0.001257806085050106, Generator Loss: 8.04140567779541\n",
      "Epoch10: Discriminator Loss: 0.00020935497013852, Generator Loss: 9.406094551086426\n",
      "Epoch10: Discriminator Loss: 0.0006148206302896142, Generator Loss: 8.105030059814453\n",
      "Epoch10: Discriminator Loss: 9.501174645265564e-05, Generator Loss: 7.871130466461182\n",
      "Epoch10: Discriminator Loss: 0.14958001673221588, Generator Loss: 1.1672126054763794\n",
      "Epoch10: Discriminator Loss: 0.00018890088540501893, Generator Loss: 8.542243003845215\n",
      "Epoch10: Discriminator Loss: 7.197487138910219e-05, Generator Loss: 10.318066596984863\n",
      "Epoch10: Discriminator Loss: 0.00017855881014838815, Generator Loss: 9.30988883972168\n",
      "Epoch10: Discriminator Loss: 1.4895836102368776e-05, Generator Loss: 11.439863204956055\n",
      "Epoch10: Discriminator Loss: 0.0005602390738204122, Generator Loss: 10.43518352508545\n",
      "Epoch10: Discriminator Loss: 2.0902858523186296e-05, Generator Loss: 12.685846328735352\n",
      "Epoch10: Discriminator Loss: 1.588121335771575e-06, Generator Loss: 12.521186828613281\n",
      "Epoch10: Discriminator Loss: 8.446333595202304e-06, Generator Loss: 11.241508483886719\n",
      "Epoch10: Discriminator Loss: 0.007637766655534506, Generator Loss: 11.056575775146484\n",
      "Epoch10: Discriminator Loss: 5.9403013437986374e-05, Generator Loss: 11.875822067260742\n",
      "Epoch10: Discriminator Loss: 0.00017983425641432405, Generator Loss: 13.06386661529541\n",
      "Epoch10: Discriminator Loss: 0.0002156514092348516, Generator Loss: 14.191086769104004\n",
      "Epoch10: Discriminator Loss: 2.2004500351613387e-05, Generator Loss: 12.066253662109375\n",
      "Epoch10: Discriminator Loss: 0.02518542855978012, Generator Loss: 13.42445182800293\n",
      "Epoch10: Discriminator Loss: 0.00308480067178607, Generator Loss: 11.768896102905273\n",
      "Epoch10: Discriminator Loss: 7.002051279414445e-05, Generator Loss: 11.832257270812988\n",
      "Epoch10: Discriminator Loss: 1.1146615861434839e-06, Generator Loss: 14.183306694030762\n",
      "Epoch10: Discriminator Loss: 2.579659667389933e-05, Generator Loss: 13.95055866241455\n",
      "Epoch10: Discriminator Loss: 0.11317320913076401, Generator Loss: 14.090202331542969\n",
      "Epoch10: Discriminator Loss: 0.08050931245088577, Generator Loss: 12.779438972473145\n",
      "Epoch10: Discriminator Loss: 0.01856367662549019, Generator Loss: 13.088735580444336\n",
      "Epoch10: Discriminator Loss: 0.028869060799479485, Generator Loss: 10.716090202331543\n",
      "Epoch10: Discriminator Loss: 0.09103181958198547, Generator Loss: 11.599348068237305\n",
      "Epoch10: Discriminator Loss: 0.08248209953308105, Generator Loss: 11.03950309753418\n",
      "Epoch10: Discriminator Loss: 0.002832716563716531, Generator Loss: 10.568882942199707\n",
      "Epoch10: Discriminator Loss: 0.018581731244921684, Generator Loss: 11.126172065734863\n",
      "Epoch10: Discriminator Loss: 0.036613743752241135, Generator Loss: 12.340575218200684\n",
      "Epoch10: Discriminator Loss: 1.5678633644711226e-05, Generator Loss: 10.17977237701416\n",
      "Epoch10: Discriminator Loss: 7.660283881705254e-05, Generator Loss: 7.886847019195557\n",
      "Epoch10: Discriminator Loss: 4.2053754441440105e-05, Generator Loss: 9.761698722839355\n",
      "Epoch10: Discriminator Loss: 0.02641427516937256, Generator Loss: 8.401823043823242\n",
      "Epoch10: Discriminator Loss: 0.0002416877105133608, Generator Loss: 7.717538833618164\n",
      "Epoch10: Discriminator Loss: 0.0001244146260432899, Generator Loss: 6.822048187255859\n",
      "Epoch10: Discriminator Loss: 0.00021419183758553118, Generator Loss: 9.171463966369629\n",
      "Epoch10: Discriminator Loss: 0.0020619428250938654, Generator Loss: 5.525484561920166\n",
      "Epoch10: Discriminator Loss: 0.003274481976404786, Generator Loss: 0.6457306146621704\n",
      "Epoch10: Discriminator Loss: 0.0014471138129010797, Generator Loss: 6.074279308319092\n",
      "Epoch10: Discriminator Loss: 0.0009268212597817183, Generator Loss: 6.72437858581543\n",
      "Epoch10: Discriminator Loss: 0.000510948128066957, Generator Loss: 6.85524845123291\n",
      "Epoch10: Discriminator Loss: 0.0013746365439146757, Generator Loss: 7.689413070678711\n",
      "Epoch10: Discriminator Loss: 0.00012130119284847751, Generator Loss: 7.373340129852295\n",
      "Epoch10: Discriminator Loss: 0.11045095324516296, Generator Loss: 4.973207950592041\n",
      "Epoch10: Discriminator Loss: 0.001460433704778552, Generator Loss: 6.3173980712890625\n",
      "Epoch10: Discriminator Loss: 0.00016839485033415258, Generator Loss: 8.626956939697266\n",
      "Epoch10: Discriminator Loss: 0.00069211091613397, Generator Loss: 6.15564489364624\n",
      "Epoch10: Discriminator Loss: 0.00024225491506513208, Generator Loss: 7.706086158752441\n",
      "Epoch10: Discriminator Loss: 0.0002383219252806157, Generator Loss: 7.6306023597717285\n",
      "Epoch10: Discriminator Loss: 7.715256288065575e-06, Generator Loss: 10.889302253723145\n",
      "Epoch10: Discriminator Loss: 3.558102253009565e-05, Generator Loss: 9.486584663391113\n",
      "Epoch10: Discriminator Loss: 2.325939931324683e-05, Generator Loss: 9.676326751708984\n",
      "Epoch10: Discriminator Loss: 0.0016902018105611205, Generator Loss: 3.1123721599578857\n",
      "Epoch10: Discriminator Loss: 1.2349875760264695e-05, Generator Loss: 11.794041633605957\n",
      "Epoch10: Discriminator Loss: 0.0006831589853391051, Generator Loss: 9.297367095947266\n",
      "Epoch10: Discriminator Loss: 0.00016663229325786233, Generator Loss: 10.717639923095703\n",
      "Epoch10: Discriminator Loss: 0.0002519135596230626, Generator Loss: 8.43453311920166\n",
      "Epoch10: Discriminator Loss: 8.161754522006959e-05, Generator Loss: 10.086938858032227\n",
      "Epoch10: Discriminator Loss: 5.970134225208312e-06, Generator Loss: 10.639561653137207\n",
      "Epoch10: Discriminator Loss: 0.00025905357324518263, Generator Loss: 11.948081016540527\n",
      "Epoch10: Discriminator Loss: 0.00010470340203028172, Generator Loss: 9.56153678894043\n",
      "Epoch10: Discriminator Loss: 0.006468750070780516, Generator Loss: 11.391605377197266\n",
      "Epoch10: Discriminator Loss: 2.306167152710259e-05, Generator Loss: 10.492270469665527\n",
      "Epoch10: Discriminator Loss: 1.199199596157996e-05, Generator Loss: 9.63371467590332\n",
      "Epoch10: Discriminator Loss: 1.0386224857938942e-05, Generator Loss: 10.465309143066406\n",
      "Epoch10: Discriminator Loss: 0.00020402728114277124, Generator Loss: 8.453887939453125\n",
      "Epoch10: Discriminator Loss: 6.3347200921271e-05, Generator Loss: 8.674293518066406\n",
      "Epoch10: Discriminator Loss: 0.06842262297868729, Generator Loss: 8.75358772277832\n",
      "Epoch10: Discriminator Loss: 0.0394151546061039, Generator Loss: 11.210576057434082\n",
      "Epoch10: Discriminator Loss: 0.0704004094004631, Generator Loss: 8.244109153747559\n",
      "Epoch10: Discriminator Loss: 0.08063103258609772, Generator Loss: 10.434333801269531\n",
      "Epoch10: Discriminator Loss: 0.00015987121150828898, Generator Loss: 8.081469535827637\n",
      "Epoch10: Discriminator Loss: 9.48807064560242e-05, Generator Loss: 10.07190990447998\n",
      "Epoch10: Discriminator Loss: 0.00026654114481061697, Generator Loss: 7.197889804840088\n",
      "Epoch10: Discriminator Loss: 0.000347325811162591, Generator Loss: 10.450104713439941\n",
      "Epoch10: Discriminator Loss: 0.0008135602110996842, Generator Loss: 7.9859185218811035\n",
      "Epoch10: Discriminator Loss: 0.0012116717407479882, Generator Loss: 6.793908596038818\n",
      "Epoch10: Discriminator Loss: 0.002645600587129593, Generator Loss: 3.187321186065674\n",
      "Epoch10: Discriminator Loss: 0.00037595274625346065, Generator Loss: 7.454287052154541\n",
      "Epoch10: Discriminator Loss: 0.00017625378677621484, Generator Loss: 6.276150703430176\n",
      "Epoch10: Discriminator Loss: 0.0006918876897543669, Generator Loss: 6.825345993041992\n",
      "Epoch10: Discriminator Loss: 0.0003131497069261968, Generator Loss: 6.079226970672607\n",
      "Epoch10: Discriminator Loss: 2.941682396340184e-05, Generator Loss: 9.935976028442383\n",
      "Epoch10: Discriminator Loss: 0.0007196586229838431, Generator Loss: 7.146856307983398\n",
      "Epoch10: Discriminator Loss: 0.024368343874812126, Generator Loss: 5.518467426300049\n",
      "Epoch10: Discriminator Loss: 0.0003489769878797233, Generator Loss: 6.012369155883789\n",
      "Epoch10: Discriminator Loss: 0.0023981849662959576, Generator Loss: 7.643249034881592\n",
      "Epoch10: Discriminator Loss: 0.023033099249005318, Generator Loss: 3.398831367492676\n",
      "Epoch10: Discriminator Loss: 0.0005392874591052532, Generator Loss: 7.375679016113281\n",
      "Epoch10: Discriminator Loss: 0.0009178010514006019, Generator Loss: 7.285528659820557\n",
      "Epoch10: Discriminator Loss: 0.0015155586879700422, Generator Loss: 4.223206520080566\n",
      "Epoch10: Discriminator Loss: 0.0006687316345050931, Generator Loss: 6.810914039611816\n",
      "Epoch10: Discriminator Loss: 0.008459149859845638, Generator Loss: 6.843988418579102\n",
      "Epoch10: Discriminator Loss: 0.0015366586158052087, Generator Loss: 2.5114357471466064\n",
      "Epoch10: Discriminator Loss: 0.0054441411048173904, Generator Loss: 4.254035472869873\n",
      "Epoch10: Discriminator Loss: 0.0002098124532494694, Generator Loss: 7.653172969818115\n",
      "Epoch10: Discriminator Loss: 0.00019169945153407753, Generator Loss: 7.152598857879639\n",
      "Epoch10: Discriminator Loss: 0.007144226226955652, Generator Loss: 3.741288185119629\n",
      "Epoch10: Discriminator Loss: 0.0716046541929245, Generator Loss: 1.758178472518921\n",
      "Epoch10: Discriminator Loss: 0.0054177893325686455, Generator Loss: 6.590030670166016\n",
      "Epoch10: Discriminator Loss: 0.0002987594052683562, Generator Loss: 6.650795936584473\n",
      "Epoch10: Discriminator Loss: 0.0026732366532087326, Generator Loss: 7.794764518737793\n",
      "Epoch10: Discriminator Loss: 0.00013652420602738857, Generator Loss: 7.96317720413208\n",
      "Epoch10: Discriminator Loss: 0.00011505057045724243, Generator Loss: 8.486756324768066\n",
      "Epoch10: Discriminator Loss: 7.331319920922397e-06, Generator Loss: 14.250954627990723\n",
      "Epoch10: Discriminator Loss: 2.0968484022887424e-05, Generator Loss: 10.95051383972168\n",
      "Epoch10: Discriminator Loss: 9.984397183870897e-05, Generator Loss: 11.139423370361328\n",
      "Epoch10: Discriminator Loss: 0.021870292723178864, Generator Loss: 10.419746398925781\n",
      "Epoch10: Discriminator Loss: 0.0037227084394544363, Generator Loss: 1.5024762153625488\n",
      "Epoch10: Discriminator Loss: 0.08570889383554459, Generator Loss: 10.179266929626465\n",
      "Epoch10: Discriminator Loss: 0.012411356903612614, Generator Loss: 10.00318431854248\n",
      "Epoch10: Discriminator Loss: 2.0944626157870516e-06, Generator Loss: 13.259712219238281\n",
      "Epoch10: Discriminator Loss: 0.00011164785246364772, Generator Loss: 9.03830337524414\n",
      "Epoch10: Discriminator Loss: 1.9190449165762402e-05, Generator Loss: 11.222089767456055\n",
      "Epoch10: Discriminator Loss: 2.7455169401946478e-05, Generator Loss: 10.195728302001953\n",
      "Epoch10: Discriminator Loss: 0.00039214896969497204, Generator Loss: 7.376989364624023\n",
      "Epoch10: Discriminator Loss: 0.004395288415253162, Generator Loss: 9.531831741333008\n",
      "Epoch10: Discriminator Loss: 8.290015830425546e-05, Generator Loss: 11.3924560546875\n",
      "Epoch10: Discriminator Loss: 0.09118016064167023, Generator Loss: 10.922141075134277\n",
      "Epoch10: Discriminator Loss: 2.556447907409165e-05, Generator Loss: 8.57677936553955\n",
      "Epoch10: Discriminator Loss: 0.18194663524627686, Generator Loss: 10.337114334106445\n",
      "Epoch10: Discriminator Loss: 1.809389141271822e-05, Generator Loss: 10.175827026367188\n",
      "Epoch10: Discriminator Loss: 0.005293733906000853, Generator Loss: 11.025103569030762\n",
      "Epoch10: Discriminator Loss: 1.6457690435345285e-05, Generator Loss: 9.503776550292969\n",
      "Epoch10: Discriminator Loss: 3.970098987338133e-06, Generator Loss: 10.87350845336914\n",
      "Epoch10: Discriminator Loss: 0.0007056677713990211, Generator Loss: 7.026435375213623\n",
      "Epoch10: Discriminator Loss: 0.004546234384179115, Generator Loss: 8.261618614196777\n",
      "Epoch10: Discriminator Loss: 0.0031071938574314117, Generator Loss: 10.466235160827637\n",
      "Epoch10: Discriminator Loss: 0.07249496877193451, Generator Loss: 7.668087959289551\n",
      "Epoch10: Discriminator Loss: 5.238581252342556e-06, Generator Loss: 12.642359733581543\n",
      "Epoch10: Discriminator Loss: 0.00028125071548856795, Generator Loss: 8.768959045410156\n",
      "Epoch10: Discriminator Loss: 0.00018728050054050982, Generator Loss: 8.956151962280273\n",
      "Epoch10: Discriminator Loss: 7.885578088462353e-05, Generator Loss: 9.638815879821777\n",
      "Epoch10: Discriminator Loss: 0.0002911020128522068, Generator Loss: 8.803576469421387\n",
      "Epoch10: Discriminator Loss: 0.0003708591975737363, Generator Loss: 6.931726932525635\n",
      "Epoch10: Discriminator Loss: 0.02046947367489338, Generator Loss: 5.83271598815918\n",
      "Epoch10: Discriminator Loss: 3.3465847081970423e-05, Generator Loss: 15.562480926513672\n",
      "Epoch11: Discriminator Loss: 0.00016986178525257856, Generator Loss: 6.629796981811523\n",
      "Epoch11: Discriminator Loss: 7.969226862769574e-05, Generator Loss: 9.237029075622559\n",
      "Epoch11: Discriminator Loss: 0.00025529268896207213, Generator Loss: 8.44875431060791\n",
      "Epoch11: Discriminator Loss: 4.218964750180021e-05, Generator Loss: 8.53039264678955\n",
      "Epoch11: Discriminator Loss: 0.0002487963647581637, Generator Loss: 7.851892948150635\n",
      "Epoch11: Discriminator Loss: 0.00012704274558927864, Generator Loss: 10.206501007080078\n",
      "Epoch11: Discriminator Loss: 0.0007736808038316667, Generator Loss: 7.739439487457275\n",
      "Epoch11: Discriminator Loss: 0.00018456105317454785, Generator Loss: 7.80015754699707\n",
      "Epoch11: Discriminator Loss: 0.0012941784225404263, Generator Loss: 9.01140022277832\n",
      "Epoch11: Discriminator Loss: 1.4095720871409867e-05, Generator Loss: 10.4498291015625\n",
      "Epoch11: Discriminator Loss: 1.7010592273436487e-05, Generator Loss: 9.570305824279785\n",
      "Epoch11: Discriminator Loss: 4.3879881559405476e-05, Generator Loss: 9.57101058959961\n",
      "Epoch11: Discriminator Loss: 7.15136484359391e-05, Generator Loss: 8.156599998474121\n",
      "Epoch11: Discriminator Loss: 2.6613377485773526e-05, Generator Loss: 11.027965545654297\n",
      "Epoch11: Discriminator Loss: 0.00013941249926574528, Generator Loss: 8.077598571777344\n",
      "Epoch11: Discriminator Loss: 0.00016612977196928114, Generator Loss: 9.092247009277344\n",
      "Epoch11: Discriminator Loss: 0.00018378511595074087, Generator Loss: 8.543791770935059\n",
      "Epoch11: Discriminator Loss: 0.08900284022092819, Generator Loss: 8.199044227600098\n",
      "Epoch11: Discriminator Loss: 0.0023989106994122267, Generator Loss: 6.970613479614258\n",
      "Epoch11: Discriminator Loss: 0.00023876468185335398, Generator Loss: 6.722531318664551\n",
      "Epoch11: Discriminator Loss: 1.684548806224484e-05, Generator Loss: 9.608453750610352\n",
      "Epoch11: Discriminator Loss: 0.006082434207201004, Generator Loss: 7.825553894042969\n",
      "Epoch11: Discriminator Loss: 0.0008992118528112769, Generator Loss: 5.268176078796387\n",
      "Epoch11: Discriminator Loss: 5.573454836849123e-05, Generator Loss: 9.556163787841797\n",
      "Epoch11: Discriminator Loss: 0.0001489456044510007, Generator Loss: 7.608841896057129\n",
      "Epoch11: Discriminator Loss: 0.00026042346144095063, Generator Loss: 8.392550468444824\n",
      "Epoch11: Discriminator Loss: 0.00019823998445644975, Generator Loss: 7.644977569580078\n",
      "Epoch11: Discriminator Loss: 0.0002521710121072829, Generator Loss: 7.063466548919678\n",
      "Epoch11: Discriminator Loss: 0.00828893668949604, Generator Loss: 6.444746971130371\n",
      "Epoch11: Discriminator Loss: 0.0001635032967897132, Generator Loss: 7.881877899169922\n",
      "Epoch11: Discriminator Loss: 0.0005664493655785918, Generator Loss: 7.003866195678711\n",
      "Epoch11: Discriminator Loss: 0.00015502578753512353, Generator Loss: 10.145393371582031\n",
      "Epoch11: Discriminator Loss: 5.1722829084610566e-05, Generator Loss: 9.58199405670166\n",
      "Epoch11: Discriminator Loss: 0.0027182893827557564, Generator Loss: 4.461650848388672\n",
      "Epoch11: Discriminator Loss: 0.05216651037335396, Generator Loss: 9.449666976928711\n",
      "Epoch11: Discriminator Loss: 0.026240231469273567, Generator Loss: 7.438256740570068\n",
      "Epoch11: Discriminator Loss: 4.435824666870758e-05, Generator Loss: 10.118644714355469\n",
      "Epoch11: Discriminator Loss: 0.01491539180278778, Generator Loss: 6.382016658782959\n",
      "Epoch11: Discriminator Loss: 0.008070649579167366, Generator Loss: 7.371220588684082\n",
      "Epoch11: Discriminator Loss: 0.008937961421906948, Generator Loss: 6.286163806915283\n",
      "Epoch11: Discriminator Loss: 0.0001366195356240496, Generator Loss: 7.767112731933594\n",
      "Epoch11: Discriminator Loss: 0.00011848694703076035, Generator Loss: 7.923205375671387\n",
      "Epoch11: Discriminator Loss: 0.000239897271967493, Generator Loss: 7.102280139923096\n",
      "Epoch11: Discriminator Loss: 0.03282589837908745, Generator Loss: 0.7281943559646606\n",
      "Epoch11: Discriminator Loss: 0.0002571194781921804, Generator Loss: 3.2733442783355713\n",
      "Epoch11: Discriminator Loss: 0.00020073779160156846, Generator Loss: 8.460830688476562\n",
      "Epoch11: Discriminator Loss: 0.0022737907711416483, Generator Loss: 5.86971378326416\n",
      "Epoch11: Discriminator Loss: 2.5935614758054726e-05, Generator Loss: 10.093551635742188\n",
      "Epoch11: Discriminator Loss: 0.0005668375524692237, Generator Loss: 7.664222240447998\n",
      "Epoch11: Discriminator Loss: 0.00031044133356772363, Generator Loss: 8.744179725646973\n",
      "Epoch11: Discriminator Loss: 0.00011184680624864995, Generator Loss: 7.81500768661499\n",
      "Epoch11: Discriminator Loss: 6.040321750333533e-05, Generator Loss: 10.649604797363281\n",
      "Epoch11: Discriminator Loss: 7.557480421382934e-05, Generator Loss: 8.739129066467285\n",
      "Epoch11: Discriminator Loss: 9.147488162852824e-05, Generator Loss: 8.611446380615234\n",
      "Epoch11: Discriminator Loss: 5.941549898125231e-05, Generator Loss: 10.381606101989746\n",
      "Epoch11: Discriminator Loss: 0.0007557051721960306, Generator Loss: 7.952841281890869\n",
      "Epoch11: Discriminator Loss: 0.001254020375199616, Generator Loss: 10.571664810180664\n",
      "Epoch11: Discriminator Loss: 0.024209916591644287, Generator Loss: 8.20279312133789\n",
      "Epoch11: Discriminator Loss: 8.72885575518012e-05, Generator Loss: 6.272661209106445\n",
      "Epoch11: Discriminator Loss: 0.0009466492338106036, Generator Loss: 8.23849105834961\n",
      "Epoch11: Discriminator Loss: 2.2211521354620345e-05, Generator Loss: 9.860092163085938\n",
      "Epoch11: Discriminator Loss: 3.950846348743653e-06, Generator Loss: 10.734750747680664\n",
      "Epoch11: Discriminator Loss: 0.0004613175697159022, Generator Loss: 5.863824367523193\n",
      "Epoch11: Discriminator Loss: 5.239619349595159e-05, Generator Loss: 8.510210990905762\n",
      "Epoch11: Discriminator Loss: 0.0006762375705875456, Generator Loss: 9.476400375366211\n",
      "Epoch11: Discriminator Loss: 0.00032704853219911456, Generator Loss: 8.855574607849121\n",
      "Epoch11: Discriminator Loss: 7.656555681023747e-05, Generator Loss: 9.370735168457031\n",
      "Epoch11: Discriminator Loss: 4.723406891571358e-05, Generator Loss: 10.173624992370605\n",
      "Epoch11: Discriminator Loss: 0.00025847950018942356, Generator Loss: 8.814254760742188\n",
      "Epoch11: Discriminator Loss: 3.097863373113796e-05, Generator Loss: 10.314674377441406\n",
      "Epoch11: Discriminator Loss: 0.00011827983689727262, Generator Loss: 8.742109298706055\n",
      "Epoch11: Discriminator Loss: 9.612975554773584e-05, Generator Loss: 9.217137336730957\n",
      "Epoch11: Discriminator Loss: 0.0002065591252176091, Generator Loss: 7.240909099578857\n",
      "Epoch11: Discriminator Loss: 4.311575321480632e-05, Generator Loss: 9.125309944152832\n",
      "Epoch11: Discriminator Loss: 0.00027401192346587777, Generator Loss: 7.616788387298584\n",
      "Epoch11: Discriminator Loss: 0.00023580770357511938, Generator Loss: 8.0457763671875\n",
      "Epoch11: Discriminator Loss: 9.352710912935436e-05, Generator Loss: 9.227221488952637\n",
      "Epoch11: Discriminator Loss: 0.00018677310436032712, Generator Loss: 9.070107460021973\n",
      "Epoch11: Discriminator Loss: 1.631420491321478e-05, Generator Loss: 9.795894622802734\n",
      "Epoch11: Discriminator Loss: 0.00011473827908048406, Generator Loss: 7.305084228515625\n",
      "Epoch11: Discriminator Loss: 0.00023193626839201897, Generator Loss: 5.990799427032471\n",
      "Epoch11: Discriminator Loss: 0.00012734573101624846, Generator Loss: 7.925138473510742\n",
      "Epoch11: Discriminator Loss: 0.00013113912427797914, Generator Loss: 8.108404159545898\n",
      "Epoch11: Discriminator Loss: 0.00026681841700337827, Generator Loss: 8.31670093536377\n",
      "Epoch11: Discriminator Loss: 7.355222624028102e-05, Generator Loss: 8.292901992797852\n",
      "Epoch11: Discriminator Loss: 0.0003693464968819171, Generator Loss: 6.263735294342041\n",
      "Epoch11: Discriminator Loss: 6.764633144484833e-05, Generator Loss: 8.793395042419434\n",
      "Epoch11: Discriminator Loss: 0.0002364106912864372, Generator Loss: 8.838822364807129\n",
      "Epoch11: Discriminator Loss: 0.09118928760290146, Generator Loss: 10.103160858154297\n",
      "Epoch11: Discriminator Loss: 8.4726169006899e-05, Generator Loss: 10.539992332458496\n",
      "Epoch11: Discriminator Loss: 5.9899695770582184e-05, Generator Loss: 8.28220272064209\n",
      "Epoch11: Discriminator Loss: 0.00292553985491395, Generator Loss: 10.73462200164795\n",
      "Epoch11: Discriminator Loss: 0.00027718875207938254, Generator Loss: 8.201935768127441\n",
      "Epoch11: Discriminator Loss: 0.00027280524955131114, Generator Loss: 6.942867755889893\n",
      "Epoch11: Discriminator Loss: 2.2297354007605463e-05, Generator Loss: 10.875936508178711\n",
      "Epoch11: Discriminator Loss: 0.0017148680053651333, Generator Loss: 5.6626667976379395\n",
      "Epoch11: Discriminator Loss: 4.998867370886728e-05, Generator Loss: 8.923517227172852\n",
      "Epoch11: Discriminator Loss: 6.750429747626185e-06, Generator Loss: 10.334834098815918\n",
      "Epoch11: Discriminator Loss: 0.0026343269273638725, Generator Loss: 8.12308406829834\n",
      "Epoch11: Discriminator Loss: 0.00033110249205492437, Generator Loss: 8.405627250671387\n",
      "Epoch11: Discriminator Loss: 0.0008576482068747282, Generator Loss: 9.540595054626465\n",
      "Epoch11: Discriminator Loss: 5.323628556652693e-06, Generator Loss: 11.019404411315918\n",
      "Epoch11: Discriminator Loss: 6.752470653736964e-06, Generator Loss: 11.17579174041748\n",
      "Epoch11: Discriminator Loss: 0.0004637562087737024, Generator Loss: 7.481263637542725\n",
      "Epoch11: Discriminator Loss: 0.0005572897498495877, Generator Loss: 7.123621463775635\n",
      "Epoch11: Discriminator Loss: 0.00268051540479064, Generator Loss: 7.5235748291015625\n",
      "Epoch11: Discriminator Loss: 0.00015498798165936023, Generator Loss: 6.826624393463135\n",
      "Epoch11: Discriminator Loss: 0.00014221321907825768, Generator Loss: 7.762942790985107\n",
      "Epoch11: Discriminator Loss: 0.0001565552520332858, Generator Loss: 7.382753372192383\n",
      "Epoch11: Discriminator Loss: 3.725387796293944e-05, Generator Loss: 9.973653793334961\n",
      "Epoch11: Discriminator Loss: 0.00012532752589322627, Generator Loss: 9.952079772949219\n",
      "Epoch11: Discriminator Loss: 0.00022906874073669314, Generator Loss: 6.724267482757568\n",
      "Epoch11: Discriminator Loss: 0.08167216926813126, Generator Loss: 7.3675150871276855\n",
      "Epoch11: Discriminator Loss: 0.0003682574024423957, Generator Loss: 8.214117050170898\n",
      "Epoch11: Discriminator Loss: 6.694949843222275e-05, Generator Loss: 9.645611763000488\n",
      "Epoch11: Discriminator Loss: 0.015502113848924637, Generator Loss: 7.610527992248535\n",
      "Epoch11: Discriminator Loss: 0.0027325779665261507, Generator Loss: 6.231575012207031\n",
      "Epoch11: Discriminator Loss: 0.0010724167805165052, Generator Loss: 6.082411289215088\n",
      "Epoch11: Discriminator Loss: 0.001421553548425436, Generator Loss: 5.728394985198975\n",
      "Epoch11: Discriminator Loss: 0.0002295105514349416, Generator Loss: 7.834996223449707\n",
      "Epoch11: Discriminator Loss: 0.002067329827696085, Generator Loss: 6.553412914276123\n",
      "Epoch11: Discriminator Loss: 0.00012343017442617565, Generator Loss: 9.435664176940918\n",
      "Epoch11: Discriminator Loss: 0.0004907172988168895, Generator Loss: 8.265668869018555\n",
      "Epoch11: Discriminator Loss: 0.0028927389066666365, Generator Loss: 5.570219039916992\n",
      "Epoch11: Discriminator Loss: 2.6652189262676984e-05, Generator Loss: 9.828896522521973\n",
      "Epoch11: Discriminator Loss: 0.00010184344864683226, Generator Loss: 9.28038215637207\n",
      "Epoch11: Discriminator Loss: 0.0002810933510772884, Generator Loss: 8.002076148986816\n",
      "Epoch11: Discriminator Loss: 1.3462454262480605e-05, Generator Loss: 9.119648933410645\n",
      "Epoch11: Discriminator Loss: 0.0014251160901039839, Generator Loss: 6.070643901824951\n",
      "Epoch11: Discriminator Loss: 0.00028206396382302046, Generator Loss: 7.795103549957275\n",
      "Epoch11: Discriminator Loss: 0.002748117782175541, Generator Loss: 8.106300354003906\n",
      "Epoch11: Discriminator Loss: 0.00013975163165014237, Generator Loss: 8.031874656677246\n",
      "Epoch11: Discriminator Loss: 8.783728117123246e-05, Generator Loss: 8.000015258789062\n",
      "Epoch11: Discriminator Loss: 0.00030227494426071644, Generator Loss: 7.433573246002197\n",
      "Epoch11: Discriminator Loss: 8.612823876319453e-05, Generator Loss: 7.614188194274902\n",
      "Epoch11: Discriminator Loss: 0.0003538696328178048, Generator Loss: 7.880596160888672\n",
      "Epoch11: Discriminator Loss: 0.0024056918919086456, Generator Loss: 3.8674628734588623\n",
      "Epoch11: Discriminator Loss: 0.00016657088417559862, Generator Loss: 6.816770076751709\n",
      "Epoch11: Discriminator Loss: 0.00033635730505920947, Generator Loss: 7.831271648406982\n",
      "Epoch11: Discriminator Loss: 0.0013334868708625436, Generator Loss: 4.427987575531006\n",
      "Epoch11: Discriminator Loss: 8.821475057629868e-05, Generator Loss: 9.444171905517578\n",
      "Epoch11: Discriminator Loss: 0.0004150309832766652, Generator Loss: 6.8973517417907715\n",
      "Epoch11: Discriminator Loss: 0.00026629926287569106, Generator Loss: 6.530782699584961\n",
      "Epoch11: Discriminator Loss: 0.0007957572233863175, Generator Loss: 7.216642379760742\n",
      "Epoch11: Discriminator Loss: 9.031502122525126e-05, Generator Loss: 9.666210174560547\n",
      "Epoch11: Discriminator Loss: 0.001414126600138843, Generator Loss: 7.989118576049805\n",
      "Epoch11: Discriminator Loss: 0.0002607273927424103, Generator Loss: 7.251309394836426\n",
      "Epoch11: Discriminator Loss: 0.0006954420241527259, Generator Loss: 5.02632474899292\n",
      "Epoch11: Discriminator Loss: 0.00023030987358652055, Generator Loss: 7.669417381286621\n",
      "Epoch11: Discriminator Loss: 0.00027533250977285206, Generator Loss: 6.962362289428711\n",
      "Epoch11: Discriminator Loss: 0.0001454813900636509, Generator Loss: 9.213586807250977\n",
      "Epoch11: Discriminator Loss: 6.910255615366623e-05, Generator Loss: 10.25894546508789\n",
      "Epoch11: Discriminator Loss: 0.0003519015444908291, Generator Loss: 6.29965877532959\n",
      "Epoch11: Discriminator Loss: 0.0005346472607925534, Generator Loss: 7.389753818511963\n",
      "Epoch11: Discriminator Loss: 0.0011976208770647645, Generator Loss: 6.779298782348633\n",
      "Epoch11: Discriminator Loss: 0.00020270304230507463, Generator Loss: 8.260981559753418\n",
      "Epoch11: Discriminator Loss: 0.000193905143532902, Generator Loss: 8.097763061523438\n",
      "Epoch11: Discriminator Loss: 3.123695933027193e-05, Generator Loss: 11.569376945495605\n",
      "Epoch11: Discriminator Loss: 0.0005728917312808335, Generator Loss: 6.286062717437744\n",
      "Epoch11: Discriminator Loss: 0.00018726241250988096, Generator Loss: 6.360496520996094\n",
      "Epoch11: Discriminator Loss: 0.0002456172660458833, Generator Loss: 8.107440948486328\n",
      "Epoch11: Discriminator Loss: 0.0006591149140149355, Generator Loss: 7.003804683685303\n",
      "Epoch11: Discriminator Loss: 0.005523303989320993, Generator Loss: 4.7923264503479\n",
      "Epoch11: Discriminator Loss: 0.0001783229090506211, Generator Loss: 8.019476890563965\n",
      "Epoch11: Discriminator Loss: 0.0005544449668377638, Generator Loss: 6.981037616729736\n",
      "Epoch11: Discriminator Loss: 1.4375518730957992e-05, Generator Loss: 8.560202598571777\n",
      "Epoch11: Discriminator Loss: 0.0007467065006494522, Generator Loss: 7.7111406326293945\n",
      "Epoch11: Discriminator Loss: 0.00017069715249817818, Generator Loss: 7.569539546966553\n",
      "Epoch11: Discriminator Loss: 0.002892507240176201, Generator Loss: 3.296088933944702\n",
      "Epoch11: Discriminator Loss: 5.572178997681476e-05, Generator Loss: 7.993092060089111\n",
      "Epoch11: Discriminator Loss: 6.656574896624079e-06, Generator Loss: 11.346035957336426\n",
      "Epoch11: Discriminator Loss: 1.865666672529187e-05, Generator Loss: 11.365517616271973\n",
      "Epoch11: Discriminator Loss: 8.840353075356688e-06, Generator Loss: 10.18322467803955\n",
      "Epoch11: Discriminator Loss: 0.003408728400245309, Generator Loss: 2.7187886238098145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch11: Discriminator Loss: 0.0003910944506060332, Generator Loss: 8.038490295410156\n",
      "Epoch11: Discriminator Loss: 8.632614481030032e-05, Generator Loss: 8.452141761779785\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch12: Discriminator Loss: 0.00013072816364001483, Generator Loss: 11.010543823242188\n",
      "Epoch12: Discriminator Loss: 1.901666291814763e-05, Generator Loss: 10.673971176147461\n",
      "Epoch12: Discriminator Loss: 0.0025756168179214, Generator Loss: 7.964746952056885\n",
      "Epoch12: Discriminator Loss: 0.00015113562403712422, Generator Loss: 7.268825054168701\n",
      "Epoch12: Discriminator Loss: 4.637638994609006e-05, Generator Loss: 9.000435829162598\n",
      "Epoch12: Discriminator Loss: 0.0037465179339051247, Generator Loss: 8.857315063476562\n",
      "Epoch12: Discriminator Loss: 0.0008505971054546535, Generator Loss: 8.762633323669434\n",
      "Epoch12: Discriminator Loss: 4.769119914271869e-05, Generator Loss: 8.134629249572754\n",
      "Epoch12: Discriminator Loss: 7.873919093981385e-05, Generator Loss: 7.797769069671631\n",
      "Epoch12: Discriminator Loss: 7.835146243451163e-05, Generator Loss: 9.08515453338623\n",
      "Epoch12: Discriminator Loss: 0.002586166840046644, Generator Loss: 7.41374397277832\n",
      "Epoch12: Discriminator Loss: 5.4782496590632945e-05, Generator Loss: 8.092581748962402\n",
      "Epoch12: Discriminator Loss: 0.000277187442407012, Generator Loss: 7.624675273895264\n",
      "Epoch12: Discriminator Loss: 0.0018844890873879194, Generator Loss: 6.750194072723389\n",
      "Epoch12: Discriminator Loss: 0.0001247281179530546, Generator Loss: 9.149941444396973\n",
      "Epoch12: Discriminator Loss: 9.247397974831983e-05, Generator Loss: 9.044195175170898\n",
      "Epoch12: Discriminator Loss: 0.0003615620080381632, Generator Loss: 5.0288543701171875\n",
      "Epoch12: Discriminator Loss: 0.00015386295854113996, Generator Loss: 8.566266059875488\n",
      "Epoch12: Discriminator Loss: 7.79474139562808e-05, Generator Loss: 9.583499908447266\n",
      "Epoch12: Discriminator Loss: 7.02680554240942e-05, Generator Loss: 8.614568710327148\n",
      "Epoch12: Discriminator Loss: 0.00026301146135665476, Generator Loss: 7.482280254364014\n",
      "Epoch12: Discriminator Loss: 4.782875839737244e-05, Generator Loss: 10.00094223022461\n",
      "Epoch12: Discriminator Loss: 0.02767367474734783, Generator Loss: 2.4647653102874756\n",
      "Epoch12: Discriminator Loss: 3.871024455293082e-05, Generator Loss: 8.839582443237305\n",
      "Epoch12: Discriminator Loss: 0.00023434124886989594, Generator Loss: 4.699532508850098\n",
      "Epoch12: Discriminator Loss: 0.00036167301004752517, Generator Loss: 8.150243759155273\n",
      "Epoch12: Discriminator Loss: 0.00012081139720976353, Generator Loss: 7.8391289710998535\n",
      "Epoch12: Discriminator Loss: 1.3086436410958413e-05, Generator Loss: 10.860053062438965\n",
      "Epoch12: Discriminator Loss: 0.00022791395895183086, Generator Loss: 7.9033708572387695\n",
      "Epoch12: Discriminator Loss: 0.008428417146205902, Generator Loss: 11.271050453186035\n",
      "Epoch12: Discriminator Loss: 5.590440196101554e-05, Generator Loss: 11.172830581665039\n",
      "Epoch12: Discriminator Loss: 8.307134703500196e-05, Generator Loss: 11.439330101013184\n",
      "Epoch12: Discriminator Loss: 3.525007559801452e-05, Generator Loss: 8.578889846801758\n",
      "Epoch12: Discriminator Loss: 0.0007204472785815597, Generator Loss: 10.251360893249512\n",
      "Epoch12: Discriminator Loss: 0.00030495112878270447, Generator Loss: 9.511799812316895\n",
      "Epoch12: Discriminator Loss: 0.00015395574155263603, Generator Loss: 7.059966087341309\n",
      "Epoch12: Discriminator Loss: 0.00032841277425177395, Generator Loss: 8.336654663085938\n",
      "Epoch12: Discriminator Loss: 2.0758003302034922e-05, Generator Loss: 8.32365894317627\n",
      "Epoch12: Discriminator Loss: 4.36006739619188e-05, Generator Loss: 9.957789421081543\n",
      "Epoch12: Discriminator Loss: 3.9838796510593966e-05, Generator Loss: 8.68252182006836\n",
      "Epoch12: Discriminator Loss: 1.654292100283783e-05, Generator Loss: 12.01727294921875\n",
      "Epoch12: Discriminator Loss: 0.0905890241265297, Generator Loss: 7.497121810913086\n",
      "Epoch12: Discriminator Loss: 0.08728950470685959, Generator Loss: 8.144430160522461\n",
      "Epoch12: Discriminator Loss: 4.3514417484402657e-05, Generator Loss: 10.922381401062012\n",
      "Epoch12: Discriminator Loss: 0.0028644190169870853, Generator Loss: 7.290456771850586\n",
      "Epoch12: Discriminator Loss: 0.00019950912974309176, Generator Loss: 8.200915336608887\n",
      "Epoch12: Discriminator Loss: 0.052220460027456284, Generator Loss: 11.018791198730469\n",
      "Epoch12: Discriminator Loss: 1.5368510503321886e-05, Generator Loss: 9.30395221710205\n",
      "Epoch12: Discriminator Loss: 0.00030410787439905107, Generator Loss: 7.206010341644287\n",
      "Epoch12: Discriminator Loss: 5.444904672913253e-05, Generator Loss: 8.675956726074219\n",
      "Epoch12: Discriminator Loss: 0.00042557454435154796, Generator Loss: 7.555422782897949\n",
      "Epoch12: Discriminator Loss: 6.788682367186993e-05, Generator Loss: 10.10551929473877\n",
      "Epoch12: Discriminator Loss: 9.663217497291043e-06, Generator Loss: 11.611516952514648\n",
      "Epoch12: Discriminator Loss: 0.0008229697123169899, Generator Loss: 6.765888214111328\n",
      "Epoch12: Discriminator Loss: 0.005397239699959755, Generator Loss: 3.330350875854492\n",
      "Epoch12: Discriminator Loss: 0.00033878255635499954, Generator Loss: 7.489020347595215\n",
      "Epoch12: Discriminator Loss: 0.00211944873444736, Generator Loss: 7.9532694816589355\n",
      "Epoch12: Discriminator Loss: 0.0012446471955627203, Generator Loss: 7.296453952789307\n",
      "Epoch12: Discriminator Loss: 0.00023783009964972734, Generator Loss: 7.142526149749756\n",
      "Epoch12: Discriminator Loss: 0.000187528261449188, Generator Loss: 7.103600978851318\n",
      "Epoch12: Discriminator Loss: 0.00015563030319754034, Generator Loss: 8.014565467834473\n",
      "Epoch12: Discriminator Loss: 0.0009720768430270255, Generator Loss: 8.138887405395508\n",
      "Epoch12: Discriminator Loss: 0.016486262902617455, Generator Loss: 7.308947563171387\n",
      "Epoch12: Discriminator Loss: 1.0998406651197001e-05, Generator Loss: 10.74622917175293\n",
      "Epoch12: Discriminator Loss: 8.636338316136971e-05, Generator Loss: 6.916600704193115\n",
      "Epoch12: Discriminator Loss: 0.0008891062461771071, Generator Loss: 7.425768852233887\n",
      "Epoch12: Discriminator Loss: 0.00893968902528286, Generator Loss: 2.8037116527557373\n",
      "Epoch12: Discriminator Loss: 1.7803746231948026e-05, Generator Loss: 11.319981575012207\n",
      "Epoch12: Discriminator Loss: 0.00010554210166446865, Generator Loss: 7.559709072113037\n",
      "Epoch12: Discriminator Loss: 0.001274206442758441, Generator Loss: 9.731635093688965\n",
      "Epoch12: Discriminator Loss: 0.08351069688796997, Generator Loss: 8.576518058776855\n",
      "Epoch12: Discriminator Loss: 0.00020266641513444483, Generator Loss: 8.473858833312988\n",
      "Epoch12: Discriminator Loss: 1.230543784913607e-05, Generator Loss: 9.92184066772461\n",
      "Epoch12: Discriminator Loss: 0.0002490021288394928, Generator Loss: 9.516359329223633\n",
      "Epoch12: Discriminator Loss: 0.0016744632739573717, Generator Loss: 8.156951904296875\n",
      "Epoch12: Discriminator Loss: 8.975257514975965e-06, Generator Loss: 9.483466148376465\n",
      "Epoch12: Discriminator Loss: 0.09126832336187363, Generator Loss: 7.51337194442749\n",
      "Epoch12: Discriminator Loss: 2.3268230506801046e-05, Generator Loss: 10.258871078491211\n",
      "Epoch12: Discriminator Loss: 0.42283862829208374, Generator Loss: 0.3957069516181946\n",
      "Epoch12: Discriminator Loss: 1.737423190206755e-05, Generator Loss: 13.255919456481934\n",
      "Epoch12: Discriminator Loss: 4.018214895040728e-06, Generator Loss: 13.428778648376465\n",
      "Epoch12: Discriminator Loss: 3.470991214271635e-05, Generator Loss: 12.794096946716309\n",
      "Epoch12: Discriminator Loss: 0.0027898068074136972, Generator Loss: 14.510793685913086\n",
      "Epoch12: Discriminator Loss: 6.188960469444282e-06, Generator Loss: 15.220695495605469\n",
      "Epoch12: Discriminator Loss: 0.11144851893186569, Generator Loss: 14.491961479187012\n",
      "Epoch12: Discriminator Loss: 0.07555527985095978, Generator Loss: 16.782207489013672\n",
      "Epoch12: Discriminator Loss: 0.00026917055947706103, Generator Loss: 17.193445205688477\n",
      "Epoch12: Discriminator Loss: 0.00012628184049390256, Generator Loss: 14.142425537109375\n",
      "Epoch12: Discriminator Loss: 0.0015587087254971266, Generator Loss: 15.677604675292969\n",
      "Epoch12: Discriminator Loss: 0.1922532021999359, Generator Loss: 18.229686737060547\n",
      "Epoch12: Discriminator Loss: 0.09115353971719742, Generator Loss: 18.699907302856445\n",
      "Epoch12: Discriminator Loss: 0.09115757048130035, Generator Loss: 19.2403621673584\n",
      "Epoch12: Discriminator Loss: 0.09115955233573914, Generator Loss: 17.476306915283203\n",
      "Epoch12: Discriminator Loss: 0.09577760100364685, Generator Loss: 18.68670654296875\n",
      "Epoch12: Discriminator Loss: 0.20262740552425385, Generator Loss: 17.962665557861328\n",
      "Epoch12: Discriminator Loss: 0.091020368039608, Generator Loss: 17.850324630737305\n",
      "Epoch12: Discriminator Loss: 0.09115156531333923, Generator Loss: 19.97786521911621\n",
      "Epoch12: Discriminator Loss: 0.039940208196640015, Generator Loss: 17.275894165039062\n",
      "Epoch12: Discriminator Loss: 0.09333847463130951, Generator Loss: 20.809038162231445\n",
      "Epoch12: Discriminator Loss: 0.2027377188205719, Generator Loss: 19.974655151367188\n",
      "Epoch12: Discriminator Loss: 0.16960765421390533, Generator Loss: 18.544452667236328\n",
      "Epoch12: Discriminator Loss: 0.0914313942193985, Generator Loss: 15.119074821472168\n",
      "Epoch12: Discriminator Loss: 0.20218713581562042, Generator Loss: 15.186823844909668\n",
      "Epoch12: Discriminator Loss: 0.021897196769714355, Generator Loss: 17.43136978149414\n",
      "Epoch12: Discriminator Loss: 3.23257404488686e-06, Generator Loss: 14.994891166687012\n",
      "Epoch12: Discriminator Loss: 2.0866372096861596e-07, Generator Loss: 15.892797470092773\n",
      "Epoch12: Discriminator Loss: 0.08758677542209625, Generator Loss: 17.807992935180664\n",
      "Epoch12: Discriminator Loss: 2.7470085115055554e-05, Generator Loss: 15.921135902404785\n",
      "Epoch12: Discriminator Loss: 0.00010728043707786128, Generator Loss: 12.983213424682617\n",
      "Epoch12: Discriminator Loss: 0.00022913629072718322, Generator Loss: 15.698443412780762\n",
      "Epoch12: Discriminator Loss: 0.09191092103719711, Generator Loss: 16.071571350097656\n",
      "Epoch12: Discriminator Loss: 0.0009289717418141663, Generator Loss: 15.751707077026367\n",
      "Epoch12: Discriminator Loss: 1.0494264870430925e-06, Generator Loss: 15.398258209228516\n",
      "Epoch12: Discriminator Loss: 0.0003056307032238692, Generator Loss: 14.606422424316406\n",
      "Epoch12: Discriminator Loss: 0.05447811260819435, Generator Loss: 15.059854507446289\n",
      "Epoch12: Discriminator Loss: 3.026187732757535e-05, Generator Loss: 13.456209182739258\n",
      "Epoch12: Discriminator Loss: 0.12808814644813538, Generator Loss: 11.019597053527832\n",
      "Epoch12: Discriminator Loss: 5.708740354748443e-05, Generator Loss: 14.340660095214844\n",
      "Epoch12: Discriminator Loss: 0.0026411532890051603, Generator Loss: 12.765698432922363\n",
      "Epoch12: Discriminator Loss: 0.001042555901221931, Generator Loss: 17.014328002929688\n",
      "Epoch12: Discriminator Loss: 2.066404249490006e-06, Generator Loss: 12.07868766784668\n",
      "Epoch12: Discriminator Loss: 0.004543661139905453, Generator Loss: 11.428611755371094\n",
      "Epoch12: Discriminator Loss: 0.0002977652766276151, Generator Loss: 9.307350158691406\n",
      "Epoch12: Discriminator Loss: 5.633032196783461e-05, Generator Loss: 10.68236255645752\n",
      "Epoch12: Discriminator Loss: 0.024658409878611565, Generator Loss: 11.302879333496094\n",
      "Epoch12: Discriminator Loss: 0.06085405871272087, Generator Loss: 10.234504699707031\n",
      "Epoch12: Discriminator Loss: 8.433905895799398e-05, Generator Loss: 9.993163108825684\n",
      "Epoch12: Discriminator Loss: 7.900728087406605e-05, Generator Loss: 8.930292129516602\n",
      "Epoch12: Discriminator Loss: 0.05207668989896774, Generator Loss: 11.919539451599121\n",
      "Epoch12: Discriminator Loss: 6.565489456988871e-05, Generator Loss: 9.325901985168457\n",
      "Epoch12: Discriminator Loss: 0.00010322649904992431, Generator Loss: 7.165611267089844\n",
      "Epoch12: Discriminator Loss: 0.0017252289690077305, Generator Loss: 6.159300804138184\n",
      "Epoch12: Discriminator Loss: 0.0001547241408843547, Generator Loss: 9.41458797454834\n",
      "Epoch12: Discriminator Loss: 1.5903306120890193e-05, Generator Loss: 9.884013175964355\n",
      "Epoch12: Discriminator Loss: 2.1063322492409497e-05, Generator Loss: 8.307637214660645\n",
      "Epoch12: Discriminator Loss: 0.0001918698544614017, Generator Loss: 7.8685221672058105\n",
      "Epoch12: Discriminator Loss: 0.008715148083865643, Generator Loss: 5.703286170959473\n",
      "Epoch12: Discriminator Loss: 0.00030777824576944113, Generator Loss: 7.883842945098877\n",
      "Epoch12: Discriminator Loss: 0.00011304084910079837, Generator Loss: 8.587364196777344\n",
      "Epoch12: Discriminator Loss: 0.005671578925102949, Generator Loss: 5.858399391174316\n",
      "Epoch12: Discriminator Loss: 0.0011930619366467, Generator Loss: 6.176496505737305\n",
      "Epoch12: Discriminator Loss: 0.0002193844848079607, Generator Loss: 9.30034351348877\n",
      "Epoch12: Discriminator Loss: 0.004443681798875332, Generator Loss: 1.972465991973877\n",
      "Epoch12: Discriminator Loss: 0.00030088506173342466, Generator Loss: 5.477972030639648\n",
      "Epoch12: Discriminator Loss: 3.426556577323936e-05, Generator Loss: 8.782476425170898\n",
      "Epoch12: Discriminator Loss: 0.02120821550488472, Generator Loss: 3.416290760040283\n",
      "Epoch12: Discriminator Loss: 0.000562806089874357, Generator Loss: 5.41912317276001\n",
      "Epoch12: Discriminator Loss: 8.125529711833224e-05, Generator Loss: 7.418153762817383\n",
      "Epoch12: Discriminator Loss: 0.006267253775149584, Generator Loss: 2.693096160888672\n",
      "Epoch12: Discriminator Loss: 0.006396847311407328, Generator Loss: 5.278420925140381\n",
      "Epoch12: Discriminator Loss: 0.00032679320429451764, Generator Loss: 4.312400817871094\n",
      "Epoch12: Discriminator Loss: 0.00011854395415866747, Generator Loss: 7.51118278503418\n",
      "Epoch12: Discriminator Loss: 0.0028459730092436075, Generator Loss: 6.6484575271606445\n",
      "Epoch12: Discriminator Loss: 0.00044150647590868175, Generator Loss: 7.994846820831299\n",
      "Epoch12: Discriminator Loss: 0.0002501963754184544, Generator Loss: 7.699693202972412\n",
      "Epoch12: Discriminator Loss: 0.0004879338084720075, Generator Loss: 7.36783504486084\n",
      "Epoch12: Discriminator Loss: 0.00025002070469781756, Generator Loss: 5.387969493865967\n",
      "Epoch12: Discriminator Loss: 0.003412509337067604, Generator Loss: 5.768069744110107\n",
      "Epoch12: Discriminator Loss: 1.1864858606713824e-05, Generator Loss: 11.243496894836426\n",
      "Epoch12: Discriminator Loss: 0.0007129854056984186, Generator Loss: 6.377994060516357\n",
      "Epoch12: Discriminator Loss: 2.3968204914126545e-05, Generator Loss: 7.874924182891846\n",
      "Epoch12: Discriminator Loss: 6.878173735458404e-05, Generator Loss: 11.320416450500488\n",
      "Epoch12: Discriminator Loss: 3.330333129270002e-05, Generator Loss: 10.79693603515625\n",
      "Epoch12: Discriminator Loss: 0.003931873477995396, Generator Loss: 6.8462958335876465\n",
      "Epoch12: Discriminator Loss: 4.3600844946922734e-05, Generator Loss: 8.850123405456543\n",
      "Epoch12: Discriminator Loss: 0.00010208846651948988, Generator Loss: 7.877536773681641\n",
      "Epoch12: Discriminator Loss: 1.9825418348773383e-05, Generator Loss: 11.177623748779297\n",
      "Epoch12: Discriminator Loss: 0.00020333706925157458, Generator Loss: 8.527277946472168\n",
      "Epoch12: Discriminator Loss: 0.0002836541389115155, Generator Loss: 8.449241638183594\n",
      "Epoch12: Discriminator Loss: 0.0017169956117868423, Generator Loss: 5.365039348602295\n",
      "Epoch12: Discriminator Loss: 5.9049671108368784e-05, Generator Loss: 9.037166595458984\n",
      "Epoch12: Discriminator Loss: 1.3715476598008536e-05, Generator Loss: 10.034785270690918\n",
      "Epoch12: Discriminator Loss: 1.026706650009146e-05, Generator Loss: 10.808340072631836\n",
      "Epoch12: Discriminator Loss: 9.758755913935602e-05, Generator Loss: 10.075927734375\n",
      "Epoch12: Discriminator Loss: 0.00012344552669674158, Generator Loss: 8.147808074951172\n",
      "Epoch12: Discriminator Loss: 6.732445035595447e-05, Generator Loss: 9.088881492614746\n",
      "Epoch13: Discriminator Loss: 1.4642270798503887e-05, Generator Loss: 10.529093742370605\n",
      "Epoch13: Discriminator Loss: 0.00020527740707620978, Generator Loss: 10.55766487121582\n",
      "Epoch13: Discriminator Loss: 3.612628279370256e-05, Generator Loss: 8.170283317565918\n",
      "Epoch13: Discriminator Loss: 8.557592809665948e-05, Generator Loss: 9.197075843811035\n",
      "Epoch13: Discriminator Loss: 5.313187284627929e-05, Generator Loss: 9.235950469970703\n",
      "Epoch13: Discriminator Loss: 8.246576180681586e-05, Generator Loss: 9.355244636535645\n",
      "Epoch13: Discriminator Loss: 0.027102909982204437, Generator Loss: 12.682387351989746\n",
      "Epoch13: Discriminator Loss: 0.00016673296340741217, Generator Loss: 7.080722808837891\n",
      "Epoch13: Discriminator Loss: 6.289137672865763e-06, Generator Loss: 11.80872917175293\n",
      "Epoch13: Discriminator Loss: 3.1191808375297114e-05, Generator Loss: 10.341667175292969\n",
      "Epoch13: Discriminator Loss: 0.0001559673110023141, Generator Loss: 7.309668064117432\n",
      "Epoch13: Discriminator Loss: 0.0007368059596046805, Generator Loss: 9.923851013183594\n",
      "Epoch13: Discriminator Loss: 2.4488796043442562e-05, Generator Loss: 9.918878555297852\n",
      "Epoch13: Discriminator Loss: 5.485150541062467e-05, Generator Loss: 8.179372787475586\n",
      "Epoch13: Discriminator Loss: 0.00046689968439750373, Generator Loss: 7.603271484375\n",
      "Epoch13: Discriminator Loss: 0.0005713151767849922, Generator Loss: 10.486462593078613\n",
      "Epoch13: Discriminator Loss: 6.277285137912259e-05, Generator Loss: 8.466184616088867\n",
      "Epoch13: Discriminator Loss: 0.022408872842788696, Generator Loss: 8.209827423095703\n",
      "Epoch13: Discriminator Loss: 5.839324785483768e-06, Generator Loss: 10.45760440826416\n",
      "Epoch13: Discriminator Loss: 3.2384679798269644e-05, Generator Loss: 7.623140811920166\n",
      "Epoch13: Discriminator Loss: 0.0012246493715792894, Generator Loss: 6.410697937011719\n",
      "Epoch13: Discriminator Loss: 0.00016243664140347391, Generator Loss: 7.646234035491943\n",
      "Epoch13: Discriminator Loss: 0.00023549406614620239, Generator Loss: 6.421121120452881\n",
      "Epoch13: Discriminator Loss: 0.002370412927120924, Generator Loss: 5.6196794509887695\n",
      "Epoch13: Discriminator Loss: 0.002178417518734932, Generator Loss: 8.510639190673828\n",
      "Epoch13: Discriminator Loss: 0.0006088375230319798, Generator Loss: 6.105704307556152\n",
      "Epoch13: Discriminator Loss: 0.00017350750567857176, Generator Loss: 7.03000545501709\n",
      "Epoch13: Discriminator Loss: 0.0009871863294392824, Generator Loss: 7.399395942687988\n",
      "Epoch13: Discriminator Loss: 0.0008552752551622689, Generator Loss: 6.6461262702941895\n",
      "Epoch13: Discriminator Loss: 0.0003632177831605077, Generator Loss: 8.182849884033203\n",
      "Epoch13: Discriminator Loss: 0.00041798921301960945, Generator Loss: 7.428915500640869\n",
      "Epoch13: Discriminator Loss: 0.0012484360486268997, Generator Loss: 6.26063871383667\n",
      "Epoch13: Discriminator Loss: 0.00012963103654328734, Generator Loss: 6.511950969696045\n",
      "Epoch13: Discriminator Loss: 0.0004289036733098328, Generator Loss: 7.037503242492676\n",
      "Epoch13: Discriminator Loss: 0.00014863978140056133, Generator Loss: 7.237185478210449\n",
      "Epoch13: Discriminator Loss: 0.0006693153409287333, Generator Loss: 8.516919136047363\n",
      "Epoch13: Discriminator Loss: 0.0004236603563185781, Generator Loss: 7.257027626037598\n",
      "Epoch13: Discriminator Loss: 3.355943044880405e-05, Generator Loss: 7.3926496505737305\n",
      "Epoch13: Discriminator Loss: 0.002108154585584998, Generator Loss: 5.809015274047852\n",
      "Epoch13: Discriminator Loss: 8.429939771303907e-05, Generator Loss: 8.704926490783691\n",
      "Epoch13: Discriminator Loss: 0.00013556660269387066, Generator Loss: 9.889813423156738\n",
      "Epoch13: Discriminator Loss: 0.00013267611211631447, Generator Loss: 8.41514778137207\n",
      "Epoch13: Discriminator Loss: 5.36756961082574e-05, Generator Loss: 7.111952304840088\n",
      "Epoch13: Discriminator Loss: 0.00024663322255946696, Generator Loss: 7.917403697967529\n",
      "Epoch13: Discriminator Loss: 0.0005589500069618225, Generator Loss: 6.497222423553467\n",
      "Epoch13: Discriminator Loss: 0.00010500034113647416, Generator Loss: 9.382218360900879\n",
      "Epoch13: Discriminator Loss: 0.0023656210396438837, Generator Loss: 6.224305629730225\n",
      "Epoch13: Discriminator Loss: 0.0012224038364365697, Generator Loss: 5.254571437835693\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m fake_loss \u001b[38;5;241m=\u001b[39m loss_fn(discriminator(fake_img\u001b[38;5;241m.\u001b[39mdetach())\u001b[38;5;241m.\u001b[39msqueeze(), torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     29\u001b[0m real_loss \u001b[38;5;241m=\u001b[39m loss_fn(discriminator(real_img)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39msqueeze(), torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 30\u001b[0m loss_D \u001b[38;5;241m=\u001b[39m (\u001b[43mfake_loss\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mreal_loss\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     31\u001b[0m loss_D\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     32\u001b[0m optimizer_D\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Implementing GANs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "    for real_img, real_label in dl:\n",
    "\n",
    "        # if (real_img.squeeze().float().shape[0] != 16 and real_img.squeeze().float().shape[1] != 3):\n",
    "        #     continue\n",
    "\n",
    "        # print(f\" Real Image shape: {real_img.squeeze().shape}, Fake Image shape: {fake_img.shape}\")\n",
    "        #print(\"Fake image shape: \", fake_img.shape)\n",
    "        #print(f\"Here D: {discriminator(fake_img).squeeze()}: 1: {torch.tensor(1)}\")\n",
    "        #print(f\"Here D: {discriminator(real_img.float()).squeeze()}: 1: {torch.tensor(1)}\")\n",
    "\n",
    "        #Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        noise = torch.randn(1, 256)\n",
    "        fake_img = generator(noise)\n",
    "        fake_label = 0\n",
    "        loss_G = loss_fn(discriminator(fake_img).squeeze(), torch.tensor(1).float())\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "\n",
    "        #Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        fake_loss = loss_fn(discriminator(fake_img.detach()).squeeze(), torch.tensor(0).float())\n",
    "        real_loss = loss_fn(discriminator(real_img).mean().squeeze(), torch.tensor(1).float())\n",
    "        loss_D = (fake_loss+real_loss)/2\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        gen_loss = loss_G.item()\n",
    "        print(f\"Epoch{epoch+1}: Discriminator Loss: {loss_D.item()}, Generator Loss: {gen_loss}\")\n",
    "        \n",
    "        gen_loss = int(gen_loss)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        noise = torch.randn(1, 256)\n",
    "        fake_img = generator(noise)\n",
    "        torchvision.utils.save_image(fake_img, 'generated.jpg')\n",
    "        plt.imshow(fake_img.squeeze().detach().permute(1, 2, 0))\n",
    "        plt.show()\n",
    "        torch.save(generator.state_dict(), 'model.pt')\n",
    "\n",
    "    if gen_loss > 100:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(1, 256)\n",
    "fake_img = generator(noise)\n",
    "print(fake_img.shape)\n",
    "torchvision.utils.save_image(fake_img, 'generated.jpg')\n",
    "fake_img = fake_img.squeeze().detach().permute(1, 2, 0)\n",
    "\n",
    "plt.imshow(fake_img)\n",
    "print(fake_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
